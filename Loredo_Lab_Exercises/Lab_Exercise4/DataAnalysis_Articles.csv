"","Title","Author","Subject","Abstract","Meta"
"1","Can the NANOGrav observations constrain the geometry of the universe?","Matteo Califano, Rocco D'Agostino, Daniele Vernieri","Cosmology and Nongalactic Astrophysics (astro-ph.CO)","The theory of inflation provides an elegant explanation for the nearly flat universe observed today, which represents one of the pillars of the standard cosmological model. However, recent studies have reported some deviations from a flat geometry, arguing that a closed universe would be instead favored by observations. Given its central role played in the cosmological context, this paper revisits the issue of spatial curvature in light of the stochastic gravitational wave background signal recently detected by the NANOGrav collaboration. For this purpose, we investigate the primordial gravitational waves generated during inflation and their propagation in the post-inflationary universe. We propose a new parametrization of the gravitational wave power spectrum, taking into account spatial curvature, the tensor-to-scalar ratio and the spectral index of tensor perturbations. Therefore, we compare the theoretical predictions with NANOGrav data to possibly constrain the geometry of the universe. We find that the choice of the priors has a significant effect on the computed posterior distributions. In particular, using flat uniform priors results in $\Omega_{\mathcal{K},0}= 0.00 \pm 0.67$ at the 68\% confidence level. On the other hand, imposing a Planck prior, we obtain $\Omega_{\mathcal{K},0}= -0.05 \pm 0.17$ at the 68\% confidence level. This result aligns with the analysis of the cosmic microwave background radiation, and no deviations from a flat universe are found.","Fri, 22 Mar 2024 17:52:27 UTC (1,475 KB)"
"2","Closing the Information Gap in Unidentified Anomalous Phenomena (UAP) Studies","Gretchen R. Stahlman","Digital Libraries (cs.DL)","Unidentified Anomalous Phenomena (UAP), also known as Unidentified Flying Objects (UFOs), has shifted from being a stigmatized topic on the fringes of scientific inquiry to a legitimate subject of scientific interest with a need for high quality, curated data, and rigorous scientific investigation. This paper presents a preliminary scoping review and analysis of scholarly literature related to UAP from 1967 until 2023, exploring a diverse range of research areas across disciplines to illustrate scholarly discourse about the topic. The paper focuses on characterizing papers published in recent years and notes that Library & Information Science is unrepresented in the current UAP literature. The paper also discusses how researchers across the iFields can contribute to UAP studies through inherent expertise such as data curation and data science as well as information behavior and information literacy, among others. The paper concludes by emphasizing that UAP Studies offer a rich intellectual realm for information science research, with the iFields well positioned to play a crucial role in supporting and engaging in the study of UAP.","Fri, 22 Mar 2024 17:40:04 UTC (385 KB)"
"3","Energy-dependent Boosted Dark Matter from Diffuse Supernova Neutrino Background","Anirban Das, Tim Herbermann, Manibrata Sen, Volodymyr Takhistov","High Energy Physics - Phenomenology (hep-ph)","Diffuse neutrinos from past supernovae in the Universe present us with a unique opportunity to test dark matter (DM) interactions. These neutrinos can scatter and boost the DM particles in the Milky Way halo to relativistic energies allowing us to detect them in terrestrial laboratories. Focusing on generic models of DM-neutrino and electron interactions, mediated by a vector or a scalar boson, we implement energy-dependent scattering cross-sections and perform detailed numerical analysis of DM attenuation due to electron scattering in-medium while propagating towards terrestrial experiments. We set new limits on DM-neutrino and electron interactions for DM with masses in the range $\sim (0.1, 10^4)~$MeV, using recent data from XENONnT, LUX-ZEPLIN, and PandaX-4T direct detection experiments. We demonstrate that consideration of energy-dependent cross-sections for DM interactions can significantly affect constraints previously derived under the assumption of constant cross-sections, modifying them by multiple orders of magnitude.","Fri, 22 Mar 2024 17:38:44 UTC (2,307 KB)"
"4","Learning Topological Representations for Deep Image Understanding","Xiaoling Hu","Computer Vision and Pattern Recognition (cs.CV)","In many scenarios, especially biomedical applications, the correct delineation of complex fine-scaled structures such as neurons, tissues, and vessels is critical for downstream analysis. Despite the strong predictive power of deep learning methods, they do not provide a satisfactory representation of these structures, thus creating significant barriers in scalable annotation and downstream analysis. In this dissertation, we tackle such challenges by proposing novel representations of these topological structures in a deep learning framework. We leverage the mathematical tools from topological data analysis, i.e., persistent homology and discrete Morse theory, to develop principled methods for better segmentation and uncertainty estimation, which will become powerful tools for scalable annotation.","Fri, 22 Mar 2024 17:23:37 UTC (31,299 KB)"
"5","Neural Plasticity-Inspired Foundation Model for Observing the Earth Crossing Modalities","Zhitong Xiong, Yi Wang, Fahong Zhang, Adam J. Stewart, Joëlle Hanna, Damian Borth, Ioannis Papoutsis, Bertrand Le Saux, Gustau Camps-Valls, Xiao Xiang Zhu","Computer Vision and Pattern Recognition (cs.CV)","The development of foundation models has revolutionized our ability to interpret the Earth's surface using satellite observational data. Traditional models have been siloed, tailored to specific sensors or data types like optical, radar, and hyperspectral, each with its own unique characteristics. This specialization hinders the potential for a holistic analysis that could benefit from the combined strengths of these diverse data sources. Our novel approach introduces the Dynamic One-For-All (DOFA) model, leveraging the concept of neural plasticity in brain science to integrate various data modalities into a single framework adaptively. This dynamic hypernetwork, adjusting to different wavelengths, enables a single versatile Transformer jointly trained on data from five sensors to excel across 12 distinct Earth observation tasks, including sensors never seen during pretraining. DOFA's innovative design offers a promising leap towards more accurate, efficient, and unified Earth observation analysis, showcasing remarkable adaptability and performance in harnessing the potential of multimodal Earth observation data.","Fri, 22 Mar 2024 17:11:47 UTC (35,969 KB)"
"6","Low-Regularity Solutions of the Nonlinear Schrödinger Equation on the Spatial Quarter-Plane","Dionyssios Mantzavinos, Türker Ozsarı","Analysis of PDEs (math.AP)","The Hadamard well-posedness of the nonlinear Schrödinger equation with power nonlinearity formulated on the spatial quarter-plane is established in a low-regularity setting with Sobolev initial data and Dirichlet boundary data in appropriate Bourgain-type spaces. As both of the spatial variables are restricted to the half-line, a different approach is needed than the one previously used for the well-posedness of other initial-boundary value problems. In particular, now the solution of the forced linear initial-boundary problem is estimated \textit{directly}, both in Sobolev spaces and in Strichartz-type spaces, i.e. without a linear decomposition that would require estimates for the associated homogeneous and nonhomogeneous initial value problems. In the process of deriving the linear estimates, the function spaces for the boundary data are identified as the intersections of certain modified Bourgain-type spaces that involve spatial half-line Fourier transforms instead of the usual whole-line Fourier transform found in the definition of the standard Bourgain space associated with the one-dimensional initial value problem. The fact that the quarter-plane has a corner at the origin poses an additional challenge, as it requires one to expand the validity of certain Sobolev extension results to the case of a domain with a non-smooth (Lipschitz) and non-compact boundary.","Fri, 22 Mar 2024 17:02:48 UTC (40 KB)"
"7","Global Analysis of LISA Data with Galactic Binaries and Massive Black Hole Binaries","Stefan H. Strub, Luigi Ferraioli, Cédric Schmelzbach, Simon C. Stähler, Domenico Giardini","General Relativity and Quantum Cosmology (gr-qc)","The Laser Interferometer Space Antenna (LISA) is a planned space-based observatory to measure gravitational waves in the millihertz frequency band. This frequency band is expected to be dominated by signals from millions of Galactic binaries and tens of merging massive black hole binaries. The LISA Data Challenge 2a is focused on the robust signal extraction from a blend of these two types of gravitational wave signals. Here, we introduce a novel high performance and cost-effective global fit pipeline extracting and characterizing galactic binary and massive black hole binary signals and estimate the noise of the residual. We preform the pipeline in a time-evolving weekly analysis starting with and observation time of 1 week until we reach a full year. As expected we detect more galactic binaries and massive black hole binaries bringing the noise estimate of the residual closer to the instrument noise by each week of additional observation time. Furthermore, we present a novel maximum likelihood estimate-based algorithm for extracting multiple massive black hole binaries. Additionally we demonstrate a massive black hole binary signal extraction with a more accurate LISA response, considering higher harmonic modes, in a noisy data set.","Fri, 22 Mar 2024 16:11:53 UTC (4,837 KB)"
"8","A data-driven approach to PDE-constrained optimization in inverse problems","Tristan van Leeuwen, Yunan Yang","Optimization and Control (math.OC)","Inverse problems are ubiquitous in science and engineering. Many of these are naturally formulated as a PDE-constrained optimization problem. These non-linear, large-scale, constrained optimization problems know many challenges, of which the inherent non-linearity of the problem is an important one. As an alternative to this physics-driven approach, data-driven methods have been proposed. These methods come with their own set of challenges, and it appears that, ideally, one would devise hybrid methods that combine the best of both worlds. In this paper, we propose one way of combining PDE-constrained optimization with recently proposed data-driven reduced-order models. Starting from an infinite-dimensional formulation of the inverse problem with discrete data, we propose a general framework for the analysis and discretisation of such problems. The proposed approach is based on a relaxed formulation of the PDE-constrained optimization problem, which reduces to a weighted non-linear least-squares problem. The weight matrix turns out to be the Gram matrix of solutions of the PDE, and it can be estimated directly from the measurements. We provide a number of representative case studies and numerical examples.","Fri, 22 Mar 2024 15:40:09 UTC (1,115 KB)"
"9","A data-informed mathematical model of microglial cell dynamics during ischemic stroke in the middle cerebral artery","Sara Amato, Andrea Arnold","Cell Behavior (q-bio.CB)","Neuroinflammation immediately follows the onset of ischemic stroke in the middle cerebral artery. During this process, microglial cells are activated in and recruited to the penumbra. Microglial cells can be activated into two different phenotypes: M1, which can worsen brain injury; or M2, which can aid in long-term recovery. In this study, we contribute a summary of experimental data on microglial cell counts in the penumbra following ischemic stroke induced by middle cerebral artery occlusion (MCAO) in mice and compile available data sets into a single set suitable for time series analysis. Further, we formulate a mathematical model of microglial cells in the penumbra during ischemic stroke due to MCAO. Through use of global sensitivity analysis and Markov Chain Monte Carlo (MCMC)-based parameter estimation, we analyze the effects of the model parameters on the number of M1 and M2 cells in the penumbra and fit identifiable parameters to the compiled experimental data set. We utilize results from MCMC parameter estimation to ascertain uncertainty bounds and forward predictions for the number of M1 and M2 microglial cells over time. Results demonstrate the significance of parameters related to M1 and M2 activation on the number of M1 and M2 microglial cells. Simulations further suggest that potential outliers in the observed data may be omitted and forecast predictions suggest a lingering inflammatory response.","Fri, 22 Mar 2024 15:31:07 UTC (288 KB)"
"10","Tests for almost stochastic dominance","Amparo Baíllo, Javier Cárcamo, Carlos Mora-Corral","Econometrics (econ.EM)","We introduce a 2-dimensional stochastic dominance (2DSD) index to characterize both strict and almost stochastic dominance. Based on this index, we derive an estimator for the minimum violation ratio (MVR), also known as the critical parameter, of the almost stochastic ordering condition between two variables. We determine the asymptotic properties of the empirical 2DSD index and MVR for the most frequently used stochastic orders. We also provide conditions under which the bootstrap estimators of these quantities are strongly consistent. As an application, we develop consistent bootstrap testing procedures for almost stochastic dominance. The performance of the tests is checked via simulations and the analysis of real data.","Fri, 22 Mar 2024 14:58:48 UTC (2,044 KB)"
"11","Self-Supervised Backbone Framework for Diverse Agricultural Vision Tasks","Sudhir Sornapudi (1), Rajhans Singh (1) ((1) Corteva Agriscience, Indianapolis, USA)","Computer Vision and Pattern Recognition (cs.CV)","Computer vision in agriculture is game-changing with its ability to transform farming into a data-driven, precise, and sustainable industry. Deep learning has empowered agriculture vision to analyze vast, complex visual data, but heavily rely on the availability of large annotated datasets. This remains a bottleneck as manual labeling is error-prone, time-consuming, and expensive. The lack of efficient labeling approaches inspired us to consider self-supervised learning as a paradigm shift, learning meaningful feature representations from raw agricultural image data. In this work, we explore how self-supervised representation learning unlocks the potential applicability to diverse agriculture vision tasks by eliminating the need for large-scale annotated datasets. We propose a lightweight framework utilizing SimCLR, a contrastive learning approach, to pre-train a ResNet-50 backbone on a large, unannotated dataset of real-world agriculture field images. Our experimental analysis and results indicate that the model learns robust features applicable to a broad range of downstream agriculture tasks discussed in the paper. Additionally, the reduced reliance on annotated data makes our approach more cost-effective and accessible, paving the way for broader adoption of computer vision in agriculture.","Fri, 22 Mar 2024 14:46:51 UTC (34,604 KB)"
"12","SFOD: Spiking Fusion Object Detector","Yimeng Fan, Wei Zhang, Changsong Liu, Mingyang Li, Wenrui Lu","Computer Vision and Pattern Recognition (cs.CV)","Event cameras, characterized by high temporal resolution, high dynamic range, low power consumption, and high pixel bandwidth, offer unique capabilities for object detection in specialized contexts. Despite these advantages, the inherent sparsity and asynchrony of event data pose challenges to existing object detection algorithms. Spiking Neural Networks (SNNs), inspired by the way the human brain codes and processes information, offer a potential solution to these difficulties. However, their performance in object detection using event cameras is limited in current implementations. In this paper, we propose the Spiking Fusion Object Detector (SFOD), a simple and efficient approach to SNN-based object detection. Specifically, we design a Spiking Fusion Module, achieving the first-time fusion of feature maps from different scales in SNNs applied to event cameras. Additionally, through integrating our analysis and experiments conducted during the pretraining of the backbone network on the NCAR dataset, we delve deeply into the impact of spiking decoding strategies and loss functions on model performance. Thereby, we establish state-of-the-art classification results based on SNNs, achieving 93.7\% accuracy on the NCAR dataset. Experimental results on the GEN1 detection dataset demonstrate that the SFOD achieves a state-of-the-art mAP of 32.1\%, outperforming existing SNN-based approaches. Our research not only underscores the potential of SNNs in object detection with event cameras but also propels the advancement of SNNs. Code is available at this https URL.","Fri, 22 Mar 2024 13:24:50 UTC (14,981 KB)"
"13","Double Cross-fit Doubly Robust Estimators: Beyond Series Regression","Alec McClean, Sivaraman Balakrishnan, Edward H. Kennedy, Larry Wasserman","Statistics Theory (math.ST)","Doubly robust estimators with cross-fitting have gained popularity in causal inference due to their favorable structure-agnostic error guarantees. However, when additional structure, such as Hölder smoothness, is available then more accurate ""double cross-fit doubly robust"" (DCDR) estimators can be constructed by splitting the training data and undersmoothing nuisance function estimators on independent samples. We study a DCDR estimator of the Expected Conditional Covariance, a functional of interest in causal inference and conditional independence testing, and derive a series of increasingly powerful results with progressively stronger assumptions. We first provide a structure-agnostic error analysis for the DCDR estimator with no assumptions on the nuisance functions or their estimators. Then, assuming the nuisance functions are Hölder smooth, but without assuming knowledge of the true smoothness level or the covariate density, we establish that DCDR estimators with several linear smoothers are semiparametric efficient under minimal conditions and achieve fast convergence rates in the non-$\sqrt{n}$ regime. When the covariate density and smoothnesses are known, we propose a minimax rate-optimal DCDR estimator based on undersmoothed kernel regression. Moreover, we show an undersmoothed DCDR estimator satisfies a slower-than-$\sqrt{n}$ central limit theorem, and that inference is possible even in the non-$\sqrt{n}$ regime. Finally, we support our theoretical results with simulations, providing intuition for double cross-fitting and undersmoothing, demonstrating where our estimator achieves semiparametric efficiency while the usual ""single cross-fit"" estimator fails, and illustrating asymptotic normality for the undersmoothed DCDR estimator.","Fri, 22 Mar 2024 12:59:03 UTC (1,902 KB)"
"14","AllHands: Ask Me Anything on Large-scale Verbatim Feedback via Large Language Models","Chaoyun Zhang, Zicheng Ma, Yuhao Wu, Shilin He, Si Qin, Minghua Ma, Xiaoting Qin, Yu Kang, Yuyi Liang, Xiaoyu Gou, Yajie Xue, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang","Software Engineering (cs.SE)","Verbatim feedback constitutes a valuable repository of user experiences, opinions, and requirements essential for software development. Effectively and efficiently extracting valuable insights from such data poses a challenging task. This paper introduces Allhands , an innovative analytic framework designed for large-scale feedback analysis through a natural language interface, leveraging large language models (LLMs). Allhands adheres to a conventional feedback analytic workflow, initially conducting classification and topic modeling on the feedback to convert them into a structurally augmented format, incorporating LLMs to enhance accuracy, robustness, generalization, and user-friendliness. Subsequently, an LLM agent is employed to interpret users' diverse questions in natural language on feedback, translating them into Python code for execution, and delivering comprehensive multi-modal responses, including text, code, tables, and images.
We evaluate Allhands across three diverse feedback datasets. The experiments demonstrate that Allhands achieves superior efficacy at all stages of analysis, including classification and topic modeling, eventually providing users with an ``ask me anything'' experience with comprehensive, correct and human-readable response. To the best of our knowledge, Allhands stands as the first comprehensive feedback analysis framework that supports diverse and customized requirements for insight extraction through a natural language interface.","Fri, 22 Mar 2024 12:13:16 UTC (817 KB)"
"15","An In-Depth Analysis of Data Reduction Methods for Sustainable Deep Learning","Víctor Toscano-Durán, Javier Perera-Lago, Eduardo Paluzo-Hidalgo, Rocío Gonzalez-Diaz, Miguel Ángel Gutierrez-Naranjo, Matteo Rucco","Machine Learning (cs.LG)","In recent years, Deep Learning has gained popularity for its ability to solve complex classification tasks, increasingly delivering better results thanks to the development of more accurate models, the availability of huge volumes of data and the improved computational capabilities of modern computers. However, these improvements in performance also bring efficiency problems, related to the storage of datasets and models, and to the waste of energy and time involved in both the training and inference processes. In this context, data reduction can help reduce energy consumption when training a deep learning model. In this paper, we present up to eight different methods to reduce the size of a tabular training dataset, and we develop a Python package to apply them. We also introduce a representativeness metric based on topology to measure how similar are the reduced datasets and the full training dataset. Additionally, we develop a methodology to apply these data reduction methods to image datasets for object detection tasks. Finally, we experimentally compare how these data reduction methods affect the representativeness of the reduced dataset, the energy consumption and the predictive performance of the model.","Fri, 22 Mar 2024 12:06:40 UTC (1,575 KB)"
"16","Text clustering with LLM embeddings","Alina Petukhova, Joao P. Matos-Carvalho, Nuno Fachada","Computation and Language (cs.CL)","Text clustering is an important approach for organising the growing amount of digital content, helping to structure and find hidden patterns in uncategorised data. In this research, we investigated how different textual embeddings - particularly those used in large language models (LLMs) - and clustering algorithms affect how text datasets are clustered. A series of experiments were conducted to assess how embeddings influence clustering results, the role played by dimensionality reduction through summarisation, and embedding size adjustment. Results reveal that LLM embeddings excel at capturing the nuances of structured language, while BERT leads the lightweight options in performance. In addition, we find that increasing embedding dimensionality and summarisation techniques do not uniformly improve clustering efficiency, suggesting that these strategies require careful analysis to use in real-life models. These results highlight a complex balance between the need for nuanced text representation and computational feasibility in text clustering applications. This study extends traditional text clustering frameworks by incorporating embeddings from LLMs, thereby paving the way for improved methodologies and opening new avenues for future research in various types of textual analysis.","Fri, 22 Mar 2024 11:08:48 UTC (83 KB)"
"17","CHisIEC: An Information Extraction Corpus for Ancient Chinese History","Xuemei Tang, Zekun Deng, Qi Su, Hao Yang, Jun Wang","Computation and Language (cs.CL)","Natural Language Processing (NLP) plays a pivotal role in the realm of Digital Humanities (DH) and serves as the cornerstone for advancing the structural analysis of historical and cultural heritage texts. This is particularly true for the domains of named entity recognition (NER) and relation extraction (RE). In our commitment to expediting ancient history and culture, we present the ``Chinese Historical Information Extraction Corpus''(CHisIEC). CHisIEC is a meticulously curated dataset designed to develop and evaluate NER and RE tasks, offering a resource to facilitate research in the field. Spanning a remarkable historical timeline encompassing data from 13 dynasties spanning over 1830 years, CHisIEC epitomizes the extensive temporal range and text heterogeneity inherent in Chinese historical documents. The dataset encompasses four distinct entity types and twelve relation types, resulting in a meticulously labeled dataset comprising 14,194 entities and 8,609 relations. To establish the robustness and versatility of our dataset, we have undertaken comprehensive experimentation involving models of various sizes and paradigms. Additionally, we have evaluated the capabilities of Large Language Models (LLMs) in the context of tasks related to ancient Chinese history. The dataset and code are available at \url{this https URL}.","Fri, 22 Mar 2024 10:12:10 UTC (1,313 KB)"
"18","GTAGCN: Generalized Topology Adaptive Graph Convolutional Networks","Sukhdeep Singh, Anuj Sharma, Vinod Kumar Chauhan","Machine Learning (cs.LG)","Graph Neural Networks (GNN) have emerged as a popular and standard approach for learning from graph-structured data. The literature on GNN highlights the potential of this evolving research area and its widespread adoption in real-life applications. However, most of the approaches are either new in concept or derived from specific techniques. Therefore, the potential of more than one approach in hybrid form has not been studied extensively, which can be well utilized for sequenced data or static data together. We derive a hybrid approach based on two established techniques as generalized aggregation networks and topology adaptive graph convolution networks that solve our purpose to apply on both types of sequenced and static nature of data, effectively. The proposed method applies to both node and graph classification. Our empirical analysis reveals that the results are at par with literature results and better for handwritten strokes as sequenced data, where graph structures have not been explored.","Fri, 22 Mar 2024 10:02:13 UTC (117 KB)"
"19","Comprehensive Lipidomic Automation Workflow using Large Language Models","Connor Beveridge, Sanjay Iyer, Caitlin E. Randolph, Matthew Muhoberac, Palak Manchanda, Amy C. Clingenpeel, Shane Tichy, Gaurav Chopra","Quantitative Methods (q-bio.QM)","Lipidomics generates large data that makes manual annotation and interpretation challenging. Lipid chemical and structural diversity with structural isomers further complicates annotation. Although, several commercial and open-source software for targeted lipid identification exists, it lacks automated method generation workflows and integration with statistical and bioinformatics tools. We have developed the Comprehensive Lipidomic Automated Workflow (CLAW) platform with integrated workflow for parsing, detailed statistical analysis and lipid annotations based on custom multiple reaction monitoring (MRM) precursor and product ion pair transitions. CLAW contains several modules including identification of carbon-carbon double bond position(s) in unsaturated lipids when combined with ozone electrospray ionization (OzESI)-MRM methodology. To demonstrate the utility of the automated workflow in CLAW, large-scale lipidomics data was collected with traditional and OzESI-MRM profiling on biological and non-biological samples. Specifically, a total of 1497 transitions organized into 10 MRM-based mass spectrometry methods were used to profile lipid droplets isolated from different brain regions of 18-24 month-old Alzheimer's disease mice and age-matched wild-type controls. Additionally, triacyclglycerols (TGs) profiles with carbon-carbon double bond specificity were generated from canola oil samples using OzESI-MRM profiling. We also developed an integrated language user interface with large language models using artificially intelligent (AI) agents that permits users to interact with the CLAW platform using a chatbot terminal to perform statistical and bioinformatic analyses. We envision CLAW pipeline to be used in high-throughput lipid structural identification tasks aiding users to generate automated lipidomics workflows ranging from data acquisition to AI agent-based bioinformatic analysis.","Fri, 22 Mar 2024 10:00:52 UTC (24,757 KB)"
"20","Construction of a Japanese Financial Benchmark for Large Language Models","Masanori Hirano","Computational Finance (q-fin.CP)","With the recent development of large language models (LLMs), models that focus on certain domains and languages have been discussed for their necessity. There is also a growing need for benchmarks to evaluate the performance of current LLMs in each domain. Therefore, in this study, we constructed a benchmark comprising multiple tasks specific to the Japanese and financial domains and performed benchmark measurements on some models. Consequently, we confirmed that GPT-4 is currently outstanding, and that the constructed benchmarks function effectively. According to our analysis, our benchmark can differentiate benchmark scores among models in all performance ranges by combining tasks with different difficulties.","Fri, 22 Mar 2024 09:40:27 UTC (154 KB)"
"21","A nonvariational form of the Neumann problem for Hölder continuous harmonic functions","M. Lanza de Cristoforis","Analysis of PDEs (math.AP)","We present a nonvariational setting for the Neumann problem for harmonic functions that are Hölder continuous and that may have infinite Dirichlet integral. Then we introduce a space of distributions on the boundary (a space of first order traces for Hölder continuous harmonic functions), we analyze the properties of the corresponding distributional single layer potential and we prove a representation theorem for harmonic Hölder continuous functions in terms of distributional single layer potentials. As an application, we solve the interior and exterior Neumann problem with distributional data in the space of first order traces that has been introduced.","Fri, 22 Mar 2024 09:29:09 UTC (38 KB)"
"22","Perturbations in PDE-constrained optimal control decay exponentially in space","Simone Göttlich, Manuel Schaller, Karl Worthmann","Optimization and Control (math.OC)","For linear-quadratic optimal control problems (OCPs) governed by elliptic and parabolic partial differential equations (PDEs), we investigate the impact of perturbations on optimal solutions. Local perturbations may occur, e.g., due to discretization of the optimality system or disturbed problem data. Whereas these perturbations may exhibit global effects in the uncontrolled case, we prove that the ramifications are exponentially damped in space under stabilizability- and detectability-like conditions. To this end, we prove a bound on the optimality condition's solution operator that is uniform in the domain size. Then, this uniformity is used in a scaling argument to show the exponential decay of perturbations in space. We numerically validate and illustrate our results by solving OCPs involving Helmholtz, Poisson, and advection-diffusion-reaction equations.","Fri, 22 Mar 2024 09:28:14 UTC (1,272 KB)"
"23","Estimation of multiple mean vectors in high dimension","Gilles Blanchard (LMO, DATASHAPE), Jean-Baptiste Fermanian (LMO), Hannah Marienwald (BIFOLD, TU)","Machine Learning (stat.ML)","We endeavour to estimate numerous multi-dimensional means of various probability distributions on a common space based on independent samples. Our approach involves forming estimators through convex combinations of empirical means derived from these samples. We introduce two strategies to find appropriate data-dependent convex combination weights: a first one employing a testing procedure to identify neighbouring means with low variance, which results in a closed-form plug-in formula for the weights, and a second one determining weights via minimization of an upper confidence bound on the quadratic risk.Through theoretical analysis, we evaluate the improvement in quadratic risk offered by our methods compared to the empirical means. Our analysis focuses on a dimensional asymptotics perspective, showing that our methods asymptotically approach an oracle (minimax) improvement as the effective dimension of the data increases.We demonstrate the efficacy of our methods in estimating multiple kernel mean embeddings through experiments on both simulated and real-world datasets.","Fri, 22 Mar 2024 08:42:41 UTC (1,755 KB)"
"24","Ellipsoidal embeddings of graphs","Michaël Fanuel, Antoine Aspeel, Michael T. Schaub, Jean-Charles Delvenne","Social and Information Networks (cs.SI)","Due to their flexibility to represent almost any kind of relational data, graph-based models have enjoyed a tremendous success over the past decades. While graphs are inherently only combinatorial objects, however, many prominent analysis tools are based on the algebraic representation of graphs via matrices such as the graph Laplacian, or on associated graph embeddings. Such embeddings associate to each node a set of coordinates in a vector space, a representation which can then be employed for learning tasks such as the classification or alignment of the nodes of the graph. As the geometric picture provided by embedding methods enables the use of a multitude of methods developed for vector space data, embeddings have thus gained interest both from a theoretical as well as a practical perspective. Inspired by trace-optimization problems, often encountered in the analysis of graph-based data, here we present a method to derive ellipsoidal embeddings of the nodes of a graph, in which each node is assigned a set of coordinates on the surface of a hyperellipsoid. Our method may be seen as an alternative to popular spectral embedding techniques, to which it shares certain similarities we discuss. To illustrate the utility of the embedding we conduct a case study in which analyse synthetic and real world networks with modular structure, and compare the results obtained with known methods in the literature.","Fri, 22 Mar 2024 08:11:56 UTC (3,665 KB)"
"25","Precise measurement of the $e^+e^-\to D_s^+D_s^-$ cross sections at center-of-mass energies from threshold to 4.95 GeV","BESIII Collaboration: M. Ablikim, M. N. Achasov, P. Adlarson, O. Afedulidis, X. C. Ai, R. Aliberti, A. Amoroso, Q. An, Y. Bai, O. Bakina, I. Balossino, Y. Ban, H.-R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, J. F. Chang, G. R. Che, G. Chelkov, C. Chen, C. H. Chen, Chao Chen, G. Chen, H. S. Chen, H. Y. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, Y. B. Chen, Y. Q. Chen, Z. J. Chen, Z. Y. Chen, S. K. Choi, G. Cibinetto, F. Cossio, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, C. Q. Deng, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, Y. Y. Duan, Z. H. Duan, P. Egorov, Y. H. Fan, J. Fang, J. Fang, S. S. Fang, W. X. Fang, Y. Fang, Y. Q. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, Y. T. Feng, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, X. B. Gao

<!--
function toggleAuthorList(whichLayer,toggleThis)
{
  var elem, vis, tempToggle;
  tempToggle=toggleThis;
  if( document.getElementById ) // standard
      elem = document.getElementById( whichLayer );
  else if( document.all ) // old msie versions
      elem = document.all[whichLayer];
  else if( document.layers ) // nn4
      elem = document.layers[whichLayer];
  vis = elem.style;
  // if the style.display value is blank we try to figure it out here
  if(vis.display==''&&elem.offsetWidth!=undefined&&elem.offsetHeight!=undefined)
    vis.display = (elem.offsetWidth!=0&&elem.offsetHeight!=0)?'inline':'none';
  vis.display = (vis.display==''||vis.display=='inline')?'none':'inline';

  // toggle link inner text
  status = vis.display;
  if(status=='none'){
      document.getElementById('toggle').innerHTML = tempToggle ;
      document.getElementById('toggle').title = ""Show Entire Author List"";
  }
  else if(status=='inline'){
      document.getElementById('toggle').innerHTML = ""(collapse list)"";
      document.getElementById('toggle').title = ""Collapse Author List"";
  }
}
//-->

        , Y. N. Gao, Yang Gao, S. Garbolino, I. Garzia, L. Ge, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A. Gilman, K. Goetzen, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, F. Hanisch, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, T. Holtmann, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, B. Y. Hu, H. M. Hu, J. F. Hu, S. L. Hu, T. Hu, Y. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, X. T. Huang, Y. P. Huang, Y. S. Huang, T. Hussain, F. Hölzken, N. Hüsken, N. in der Wiesche, J. Jackson, S. Janchiv, J. H. Jeong, Q. Ji, Q. P. Ji, W. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, X. Q. Jia, Z. K. Jia, D. Jiang, H. B. Jiang, P. C. Jiang, S. S. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, J. K. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, X. Kui, N. Kumar, A. Kupsc, W. Kühn, J. J. Lane, P. Larin, L. Lavezzi, T. T. Lei, Z. H. Lei, M. Lellmann, T. Lenz, C. Li, C. Li, C. H. Li, Cheng Li, D. M. Li, F. Li, G. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, K. Li, L. J. Li, L. K. Li, Lei Li, M. H. Li, P. R. Li, Q. M. Li, Q. X. Li, R. Li, S. X. Li, T. Li, W. D. Li, W. G. Li, X. Li, X. H. Li, X. L. Li, X. Y. Li, X. Z. Li, Y. G. Li, Z. J. Li, Z. Y. Li, C. Liang, H. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, L. Z. Liao, Y. P. Liao, J. Libby, A. Limphirat, C. C. Lin, D. X. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. Liu, F. H. Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. H. Liu, H. M. Liu, Huihui Liu, J. B. Liu, J. Y. Liu, K. Liu, K. Y. Liu, Ke Liu, L. Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, X. Liu, X. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. D. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, X. L. Lu, Y. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, J. R. Luo, M. X. Luo, T. Luo, X. L. Luo, X. R. Lyu, Y. F. Lyu, F. C. Ma, H. Ma, H. L. Ma, J. L. Ma, L. L. Ma, M. M. Ma, Q. M. Ma, R. Q. Ma, T. Ma, X. T. Ma, X. Y. Ma, Y. Ma, Y. M. Ma, F. E. Maas, M. Maggiora, S. Malde, Y. J. Mao, Z. P. Mao, S. Marcello, Z. X. Meng, J. G. Messchendorp, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, L. S. Nie, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, Y. Niu, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, P. Patteri, Y. P. Pei, M. Pelizaeus, H. P. Peng, Y. Y. Peng, K. Peters, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. Qi, H. R. Qi, M. Qi, T. Y. Qi, S. Qian, W. B. Qian, C. F. Qiao, X. K. Qiao, J. J. Qin, L. Q. Qin, L. Y. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, Z. H. Qu, C. F. Redmer, K. J. Ren, A. Rivetti, M. Rolo, G. Rong, Ch. Rosner, S. N. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, Z. J. Shang, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. Shi, H. C. Shi, J. L. Shi, J. Y. Shi, Q. Q. Shi, S. Y. Shi, X. Shi, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, Y. X. Song, S. Sosio, S. Spataro, F. Stieler, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, W. Y. Sun, Y. Sun, Y. J. Sun, Y. Z. Sun, Z. Q. Sun, Z. T. Sun, C. J. Tang, G. Y. Tang, J. Tang, M. Tang, Y. A. Tang, L. Y. Tao, Q. T. Tao, M. Tat, J. X. Teng, V. Thoren, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, Y. Wan, S. J. Wang, B. Wang, B. L. Wang, Bo Wang, D. Y. Wang, F. Wang, H. J. Wang, J. J. Wang, J. P. Wang, K. Wang, L. L. Wang, M. Wang, N. Y. Wang, S. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, X. N. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Z. Wang, Z. L. Wang, Z. Y. Wang, Ziyi Wang, D. H. Wei, F. Weidner, S. P. Wen, Y. R. Wen, U. Wiedner, G. Wilkinson, M. Wolke, L. Wollenberg, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, X. Wu, X. H. Wu, Y. Wu, Y. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, B. H. Xiang, T. Xiang, D. Xiao, G. Y. Xiao, S. Y. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, H. Y. Xu, M. Xu, Q. J. Xu, Q. N. Xu, W. Xu, W. L. Xu, X. P. Xu, Y. C. Xu, Z. P. Xu, Z. S. Xu, F. Yan, L. Yan, W. B. Yan, W. C. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, T. Yang, Y. Yang, Y. F. Yang, Y. F. Yang, Y. X. Yang, Z. W. Yang, Z. P. Yao, M. Ye, M. H. Ye, J. H. Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, T. Yu, X. D. Yu, Y. C. Yu, C. Z. Yuan, J. Yuan, J. Yuan, L. Yuan, S. C. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, A. A. Zafar, F. R. Zeng, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, Y. J. Zeng, X. Y. Zhai, Y. C. Zhai, Y. H. Zhan, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, H. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. H. Zhang, H. Q. Zhang, H. R. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. S. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, Lei Zhang, P. Zhang, Q. Y. Zhang, R. Y. Zhang, S. H. Zhang, Shulei Zhang, X. D. Zhang, X. M. Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Y. M. Zhang, Yan Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. Y. Zhang, Z. Y. Zhang, Z. Z. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, L. Zhao, Lei Zhao, M. G. Zhao, N. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, B. M. Zheng, J. P. Zheng, W. J. Zheng, Y. H. Zheng, B. Zhong, X. Zhong, H. Zhou, J. Y. Zhou, L. P. Zhou, S. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. Z. Zhou, J. Zhu, K. Zhu, K. J. Zhu, K. S. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, S. Q. Zhu, T. J. Zhu, W. D. Zhu, Y. C. Zhu, Z. A. Zhu, J. H. Zou, J. Zu
  
  
    et al. (563 additional authors not shown)
   You must enable JavaScript to view entire author list.","High Energy Physics - Experiment (hep-ex)","Using the $e^+e^-$ collision data collected with the BESIII detector operating at the BEPCII collider, at center-of-mass energies from the threshold to $4.95$~GeV, we present precise measurements of the cross sections for the process $e^+e^-\to D_s^+D_s^-$ using a single tag method. The resulting cross section lineshape exhibits several new structures, thereby offering an input for coupled channel analysis and model tests, which are critical to understand vector charmonium-like states with masses between 4 and 5~GeV.","Fri, 22 Mar 2024 07:20:20 UTC (155 KB)"
"26","Risk and Response in Large Language Models: Evaluating Key Threat Categories","Bahareh Harandizadeh, Abel Salinas, Fred Morstatter","Computation and Language (cs.CL)","This paper explores the pressing issue of risk assessment in Large Language Models (LLMs) as they become increasingly prevalent in various applications. Focusing on how reward models, which are designed to fine-tune pretrained LLMs to align with human values, perceive and categorize different types of risks, we delve into the challenges posed by the subjective nature of preference-based training data. By utilizing the Anthropic Red-team dataset, we analyze major risk categories, including Information Hazards, Malicious Uses, and Discrimination/Hateful content. Our findings indicate that LLMs tend to consider Information Hazards less harmful, a finding confirmed by a specially developed regression model. Additionally, our analysis shows that LLMs respond less stringently to Information Hazards compared to other risks. The study further reveals a significant vulnerability of LLMs to jailbreaking attacks in Information Hazard scenarios, highlighting a critical security concern in LLM risk assessment and emphasizing the need for improved AI safety measures.","Fri, 22 Mar 2024 06:46:40 UTC (10,014 KB)"
"27","Two-scale Analysis for Multiscale Landau-Lifshitz-Gilbert Equation: Theory and Numerical Methods","Xiaofei Guan, Hang Qi, Zhiwei Sun","Numerical Analysis (math.NA)","This paper discusses the theory and numerical method of two-scale analysis for the multiscale Landau-Lifshitz-Gilbert equation in composite ferromagnetic materials. The novelty of this work can be summarized in three aspects: Firstly, the more realistic and complex model is considered, including the effects of the exchange field, anisotropy field, stray field, and external magnetic field. The explicit convergence orders in the $H^1$ norm between the classical solution and the two-scale solution are obtained. Secondly, we propose a robust numerical framework, which is employed in several comprehensive experiments to validate the convergence results for the Periodic and Neumann problems. Thirdly, we design an improved implicit numerical scheme to reduce the required number of iterations and relaxes the constraints on the time step size, which can significantly improve computational efficiency. Specifically, the projection and the expansion methods are given to overcome the inherent non-consistency in the initial data between the multiscale problem and homogenized problem.","Fri, 22 Mar 2024 05:21:57 UTC (3,746 KB)"
"28","Creating a Spatial Vulnerability Index for Environmental Health","Aiden Price, Kerrie Mengersen, Michael Rigby, Paula Fiévez","Methodology (stat.ME)","Extreme natural hazards are increasing in frequency and intensity. These natural changes in our environment, combined with man-made pollution, have substantial economic, social and health impacts globally. The impact of the environment on human health (environmental health) is becoming well understood in international research literature. However, there are significant barriers to understanding key characteristics of this impact, related to substantial data volumes, data access rights and the time required to compile and compare data over regions and time. This study aims to reduce these barriers in Australia by creating an open data repository of national environmental health data and presenting a methodology for the production of health outcome-weighted population vulnerability indices related to extreme heat, extreme cold and air pollution at various temporal and geographical resolutions.
Current state-of-the-art methods for the calculation of vulnerability indices include equal weight percentile ranking and the use of principal component analysis (PCA). The weighted vulnerability index methodology proposed in this study offers an advantage over others in the literature by considering health outcomes in the calculation process. The resulting vulnerability percentiles more clearly align population sensitivity and adaptive capacity with health risks. The temporal and spatial resolutions of the indices enable national monitoring on a scale never before seen across Australia. Additionally, we show that a weekly temporal resolution can be used to identify spikes in vulnerability due to changes in relative national environmental exposure.","Fri, 22 Mar 2024 05:13:27 UTC (12,883 KB)"
"29","Addressing Concept Shift in Online Time Series Forecasting: Detect-then-Adapt","YiFan Zhang, Weiqi Chen, Zhaoyang Zhu, Dalin Qin, Liang Sun, Xue Wang, Qingsong Wen, Zhang Zhang, Liang Wang, Rong Jin","Machine Learning (cs.LG)","Online updating of time series forecasting models aims to tackle the challenge of concept drifting by adjusting forecasting models based on streaming data. While numerous algorithms have been developed, most of them focus on model design and updating. In practice, many of these methods struggle with continuous performance regression in the face of accumulated concept drifts over time. To address this limitation, we present a novel approach, Concept \textbf{D}rift \textbf{D}etection an\textbf{D} \textbf{A}daptation (D3A), that first detects drifting conception and then aggressively adapts the current model to the drifted concepts after the detection for rapid adaption. To best harness the utility of historical data for model adaptation, we propose a data augmentation strategy introducing Gaussian noise into existing training instances. It helps mitigate the data distribution gap, a critical factor contributing to train-test performance inconsistency. The significance of our data augmentation process is verified by our theoretical analysis. Our empirical studies across six datasets demonstrate the effectiveness of D3A in improving model adaptation capability. Notably, compared to a simple Temporal Convolutional Network (TCN) baseline, D3A reduces the average Mean Squared Error (MSE) by $43.9\%$. For the state-of-the-art (SOTA) model, the MSE is reduced by $33.3\%$.","Fri, 22 Mar 2024 04:44:43 UTC (5,404 KB)"
"30","Contrastive Learning on Multimodal Analysis of Electronic Health Records","Tianxi Cai, Feiqing Huang, Ryumei Nakada, Linjun Zhang, Doudou Zhou","Machine Learning (stat.ML)","Electronic health record (EHR) systems contain a wealth of multimodal clinical data including structured data like clinical codes and unstructured data such as clinical notes. However, many existing EHR-focused studies has traditionally either concentrated on an individual modality or merged different modalities in a rather rudimentary fashion. This approach often results in the perception of structured and unstructured data as separate entities, neglecting the inherent synergy between them. Specifically, the two important modalities contain clinically relevant, inextricably linked and complementary health information. A more complete picture of a patient's medical history is captured by the joint analysis of the two modalities of data. Despite the great success of multimodal contrastive learning on vision-language, its potential remains under-explored in the realm of multimodal EHR, particularly in terms of its theoretical understanding. To accommodate the statistical analysis of multimodal EHR data, in this paper, we propose a novel multimodal feature embedding generative model and design a multimodal contrastive loss to obtain the multimodal EHR feature representation. Our theoretical analysis demonstrates the effectiveness of multimodal learning compared to single-modality learning and connects the solution of the loss function to the singular value decomposition of a pointwise mutual information matrix. This connection paves the way for a privacy-preserving algorithm tailored for multimodal EHR feature representation learning. Simulation studies show that the proposed algorithm performs well under a variety of configurations. We further validate the clinical utility of the proposed algorithm in real-world EHR data.","Fri, 22 Mar 2024 03:01:42 UTC (5,781 KB)"
"31","Computational Approaches for Exponential-Family Factor Analysis","Liang Wang, Luis Carvalho","Methodology (stat.ME)","We study a general factor analysis framework where the $n$-by-$p$ data matrix is assumed to follow a general exponential family distribution entry-wise. While this model framework has been proposed before, we here further relax its distributional assumption by using a quasi-likelihood setup. By parameterizing the mean-variance relationship on data entries, we additionally introduce a dispersion parameter and entry-wise weights to model large variations and missing values. The resulting model is thus not only robust to distribution misspecification but also more flexible and able to capture non-Gaussian covariance structures of the data matrix. Our main focus is on efficient computational approaches to perform the factor analysis. Previous modeling frameworks rely on simulated maximum likelihood (SML) to find the factorization solution, but this method was shown to lead to asymptotic bias when the simulated sample size grows slower than the square root of the sample size $n$, eliminating its practical application for data matrices with large $n$. Borrowing from expectation-maximization (EM) and stochastic gradient descent (SGD), we investigate three estimation procedures based on iterative factorization updates. Our proposed solution does not show asymptotic biases, and scales even better for large matrix factorizations with error $O(1/p)$. To support our findings, we conduct simulation experiments and discuss its application in three case studies.","Fri, 22 Mar 2024 02:58:14 UTC (4,090 KB)"
"32","Analysis of Log Data from an International Online Educational Assessment System: A Multi-state Survival Modeling Approach to Reaction Time between and across Action Sequence","Jina Park, Ick Hoon Jin, Minjeong Jeon","Applications (stat.AP)","With increasingly available computer-based or online assessments, researchers have shown keen interest in analyzing log data to improve our understanding of test takers' problem-solving processes. In this paper, we propose a multi-state survival model (MSM) to action sequence data from log files, focusing on modeling test takers' reaction times between actions, in order to investigate which factors and how they influence test takers' transition speed between actions. In particular, we focus on the effects of the occurrence and timing of key actions that differentiate correct answers from incorrect answers. We demonstrate our proposed approach with problem-solving test items from the the Programme for International Assessment of Adult Competence (PIAAC) problem-solving test items.","Fri, 22 Mar 2024 02:02:19 UTC (9,935 KB)"
"33","Unraveling Contagion Origins: Optimal Estimation through Maximum-Likelihood and Starlike Tree Approximation in Markovian Spreading Models","Pei-Duo Yu, Chee Wei Tan, Liang Zheng, Chao Zhao","Social and Information Networks (cs.SI)","Identifying the source of epidemic-like spread in networks is crucial for tasks like removing internet viruses or finding the rumor source in online social networks. The challenge lies in tracing the source from a snapshot observation of infected nodes. How do we accurately pinpoint the source? Utilizing snapshot data, we apply a probabilistic approach, focusing on the graph boundary and the observed time, to detect sources via an effective maximum likelihood algorithm. A novel starlike tree approximation extends applicability to general graphs, demonstrating versatility. We highlight the utility of the Gamma function for analyzing the asymptotic behavior of the likelihood ratio between nodes. Comprehensive evaluations confirm algorithmic effectiveness in diverse network scenarios, advancing rumor source detection in large-scale network analysis and information dissemination strategies.","Fri, 22 Mar 2024 00:19:29 UTC (12,842 KB)"
"34","Description of CuInP$_{2}$S$_{6}$ ferrielectrics in a mixed Ising model","R. Yevych, V. Liubachko, V. Hryts, M. Medulych, A. Kohutych, Yu. Vysochanskii","Soft Condensed Matter (cond-mat.soft)","The appearance of spontaneous polarization in CuInP$_{2}$S$_{6}$ ferrielectrics is related to the second order Jahn-Teller effect for copper cations located in a double-well local potential, the stereoactivity of indium cations located in a three-well local potential, as well as the valence fluctuations of phosphorus cations. The paraelectric to ferrielectric phase transition is primarily determined by the coupling of indium cations with their surroundings. This transition can be analyzed using the mixed Ising model with spins $s = 1/2$ and $S = 1$. The spectrum of pseudospin fluctuations at different temperatures was calculated using a mean-field approach for a set of quantum anharmonic oscillators. The results were then compared with Raman spectroscopy data for CuInP$_{2}$S$_{6}$ crystal. The analysis indicates that the lattice anharmonicity below 150 K, is mainly determined by the indium sublattice, leading to the coexistence of the glassy state and ferrielectric phase. Above 150 K, the anharmonicity of the copper sublattice activates the ionic conductivity and results in the existence of a long-ranged fluctuated cluster of spontaneous polarization in a temperature interval of the paraelectric phase above $T_{C}$.","Thu, 21 Mar 2024 22:04:04 UTC (5,100 KB)"
"35","Revisiting the wetting behavior of solid surfaces by water-like models within a density functional theory","A. Kozina, M. Aguilar, O. Pizio, S. Sokołowski","Soft Condensed Matter (cond-mat.soft)","We perform the analysis of predictions of a classical density functional theory for associating fluids with different association strength concerned with wetting of solid surfaces. The four associating sites water-like models with non-associative square-well attraction parametrized by Clark et al. [Mol. Phys., 2006, 104, 3561] are considered. The fluid-solid potential is assumed to have a 10-4-3 functional form. The growth of water film on the substrate upon changing the chemical potential is described. The wetting and prewetting critical temperatures, as well as the prewetting phase diagram are evaluated for different fluid-solid attraction strength from the analysis of the adsorption isotherms. Moreover, the temperature dependence of the contact angle is obtained from the Young equation. It yields estimates for the wetting temperature as well. Theoretical findings are compared with experimental results and in a few cases with data from computer simulations. The theory is successful and quite accurate in describing the wetting temperature and contact angle changes with temperature for different values of fluid-substrate attraction. Moreover, the method provides an easy tool to study other associating fluids on solids of importance for chemical engineering, in comparison with laboratory experiments and computer simulations.","Thu, 21 Mar 2024 20:40:40 UTC (278 KB)"
"36","Non-holomorphic modular forms from zeta generators","Daniele Dorigoni, Mehregan Doroudiani, Joshua Drewitt, Martijn Hidding, Axel Kleinschmidt, Oliver Schlotterer, Leila Schneps, Bram Verbeek","High Energy Physics - Theory (hep-th)","We study non-holomorphic modular forms built from iterated integrals of holomorphic modular forms for SL$(2,\mathbb Z)$ known as equivariant iterated Eisenstein integrals. A special subclass of them furnishes an equivalent description of the modular graph forms appearing in the low-energy expansion of string amplitudes at genus one. Notably the Fourier expansion of modular graph forms contains single-valued multiple zeta values. We deduce the appearance of products and higher-depth instances of multiple zeta values in equivariant iterated Eisenstein integrals, and ultimately modular graph forms, from the appearance of simpler odd Riemann zeta values. This analysis relies on so-called zeta generators which act on certain non-commutative variables in the generating series of the iterated integrals. From an extension of these non-commutative variables we incorporate iterated integrals involving holomorphic cusp forms into our setup and use them to construct the modular completion of triple Eisenstein integrals. Our work represents a fully explicit realisation of the modular graph forms within Brown's framework of equivariant iterated Eisenstein integrals and reveals structural analogies between single-valued period functions appearing in genus zero and one string amplitudes.","Thu, 21 Mar 2024 20:12:04 UTC (5,750 KB)"
"37","Normalizing Flows for Domain Adaptation when Identifying $Λ$ Hyperon Events","Rowan Kelleher, Anselm Vossen","Data Analysis, Statistics and Probability (physics.data-an)","This study focuses on the novel application of a normalizing flow as a method of domain adaptation. Normalizing flows offer a way to transform data points between two different distributions. The present study investigates a method of transforming latent representations of physics data to a normal distribution and then to a physics distribution again. The final distribution models a simulated distribution. Following the transformation process, the data can be classified by a neural network trained on labeled simulation data. The present study succeeds in training two normalizing flows that can transform between data (or simulation) and a Gaussian distribution.","Thu, 21 Mar 2024 19:32:31 UTC (682 KB)"
"38","Identifying Attention-Deficit/Hyperactivity Disorder through the electroencephalogram complexity","Dimitri Marques Abramov, Henrique Santos Lima, Vladimir Lazarev, Paulo Ricardo Galhanone, Constantino Tsallis","Neurons and Cognition (q-bio.NC)","There are reasons to suggest that a number of mental disorders may be related to alteration in the neural complexity (NC). Thus, quantitative analysis of NC could be helpful in classifying mental conditions and clarifying our understanding about them. Here, we have worked with youths, typical and with attention-deficit/hyperactivity disorder (ADHD), whose neural complexity was assessed using q-statistics applied to the electroencephalogram (EEG). The EEG was recorded while subjects performed the visual Attention Network Test (ANT) based on the OddBall paradigm and during a shortpretask period of resting state. Time intervals of the EEG amplitudes that passed a threshold (signal regularity indicator) were collected from task and pretask signals from each subject. The data were satisfactorily fitted with a stretched $q$-exponential including a power-law prefactor(characterized by the exponent c), thus determining the best $(c, q)$ for each subject, indicative of their individual complexity. We found larger values of $q$ and $c$ in ADHD subjects as compared with the typical subjects both at task and pretask periods, the task values for both groups being larger than at rest. The $c$ parameter was highly specific in relation to DSM diagnosis for inattention, where well-defined clusters were observed. The parameter values were organized in four well-defined clusters in $(c, q)$-space. As expected, the tasks apparently induced greater complexity in neural functional states with likely greater amount of internal information processing. The results suggest that complexity is higher in ADHD subjects than in typical pairs. The distribution of values in the $(c, q)$-space derived from $q$-statistics seems to be a promising biomarker for ADHD diagnosis.","Thu, 21 Mar 2024 19:26:52 UTC (516 KB)"
"39","Background information: a study on the sensitivity of astrophysical gravitational-wave background searches","Arianna I. Renzini, Thomas A. Callister, Katerina Chatziioannou, Will M. Farr","High Energy Astrophysical Phenomena (astro-ph.HE)","The vast majority of gravitational-wave signals from stellar-mass compact binary mergers are too weak to be individually detected with present-day instruments and instead contribute to a faint, persistent background. This astrophysical background is targeted by searches that model the gravitational-wave ensemble collectively with a small set of parameters. The traditional search models the background as a stochastic field and estimates its amplitude by cross-correlating data from multiple interferometers. A different search uses gravitational-wave templates to marginalize over all individual event parameters and measure the duty cycle and population properties of binary mergers. Both searches ultimately estimate the total merger rate of compact binaries and are expected to yield a detection in the coming years. Given the conceptual and methodological differences between them, though, it is not well understood how their results should be mutually interpreted. In this paper, we use the Fisher information to study the implications of a background detection in terms of which region of the Universe each approach probes. Specifically, we quantify how information about the compact binary merger rate is accumulated by each search as a function of the event redshift. For the LIGO Design sensitivity and a uniform-in-comoving-volume distribution of equal-mass 30M_sol binaries, the traditional cross-correlation search obtains 99% of its information from binaries up to redshift 2.5 (average signal-to-noise-ratio <8), and the template-based search from binaries up to redshift 1.0 (average signal-to-noise-ratio ~8). While we do not calculate the total information accumulated by each search, our analysis emphasizes the need to pair any claimed detection of the stochastic background with an assessment of which binaries contribute to said detection.","Thu, 21 Mar 2024 19:14:10 UTC (847 KB)"
"40","The central black hole in the dwarf spheroidal galaxy Leo I Not supermassive, at most an intermediate-mass candidate","R. Pascale, C. Nipoti, F. Calura, A. Della Croce","Astrophysics of Galaxies (astro-ph.GA)","It has been recently claimed that a surprisingly massive black hole (BH) is present in the core of the dwarf spheroidal galaxy (dSph) Leo I. Based on integral field spectroscopy, this finding challenges the typical expectation of dSphs hosting BHs of intermediate-mass, since such a BH would better be classified as supermassive. Indeed, the analysis points toward Leo I harboring a BH with a lower mass limit exceeding a few $10^6M_\odot$ at $1\sigma$, and the no BH case excluded at 95\% significance. Such a value, comparable to the entire stellar mass of the galaxy, makes Leo I a unique system that warrants further investigations. Using equilibrium models based on distribution functions (DFs) depending on actions $f({\boldsymbol J})$ coupled with the same integral field spectroscopy data and an extensive exploration of a very large parameter space, we demonstrate, within a comprehensive Bayesian framework of model-data comparison, that the posterior on the BH mass is flat towards the low-mass end and, thus, that the kinematics of the central galaxy region only imposes an upper limit on the BH mass of few $10^5M_\odot$ (at $3\sigma$). Such an upper limit brings back the putative BH of Leo I under the category of intermediate-mass BHs, and it is also in line with formation scenarios and expectations from scaling relations at the mass regime of dwarf galaxies.","Thu, 21 Mar 2024 19:00:02 UTC (6,909 KB)"
"41","Fast likelihood-free inference in the LSS Stage IV era","Guillermo Franco Abellán, Guadalupe Cañas Herrera, Matteo Martinelli, Oleg Savchenko, Davide Sciotti, Christoph Weniger","Cosmology and Nongalactic Astrophysics (astro-ph.CO)","Forthcoming large-scale structure (LSS) Stage IV surveys will provide us with unprecedented data to probe the nature of dark matter and dark energy. However, analysing these data with conventional Markov Chain Monte Carlo (MCMC) methods will be challenging, due to the increase in the number of nuisance parameters and the presence of intractable likelihoods. In light of this, we present the first application of Marginal Neural Ratio Estimation (MNRE) (a recent approach in simulation-based inference) to LSS photometric probes: weak lensing, galaxy clustering and the cross-correlation power spectra. In order to analyse the hundreds of spectra simultaneously, we find that a pre-compression of data using principal component analysis, as well as parameter-specific data summaries lead to highly accurate results. Using expected Stage IV experimental noise, we are able to recover the posterior distribution for the cosmological parameters with a speedup factor of $\sim 40-60$ compared to classical MCMC methods. To illustrate that the performance of MNRE is not impeded when posteriors are highly non-Gaussian, we test a scenario of two-body decaying dark matter, finding that Stage IV surveys can improve current bounds on the model by up to one order of magnitude. This result supports that MNRE is a powerful framework to constrain the standard cosmological model and its extensions with next-generation LSS surveys.","Thu, 21 Mar 2024 18:00:02 UTC (2,825 KB)"
"42","Foundation Models for Time Series Analysis: A Tutorial and Survey","Yuxuan Liang, Haomin Wen, Yuqi Nie, Yushan Jiang, Ming Jin, Dongjin Song, Shirui Pan, Qingsong Wen","Machine Learning (cs.LG)","Time series analysis stands as a focal point within the data mining community, serving as a cornerstone for extracting valuable insights crucial to a myriad of real-world applications. Recent advancements in Foundation Models (FMs) have fundamentally reshaped the paradigm of model design for time series analysis, boosting various downstream tasks in practice. These innovative approaches often leverage pre-trained or fine-tuned FMs to harness generalized knowledge tailored specifically for time series analysis. In this survey, we aim to furnish a comprehensive and up-to-date overview of FMs for time series analysis. While prior surveys have predominantly focused on either the application or the pipeline aspects of FMs in time series analysis, they have often lacked an in-depth understanding of the underlying mechanisms that elucidate why and how FMs benefit time series analysis. To address this gap, our survey adopts a model-centric classification, delineating various pivotal elements of time-series FMs, including model architectures, pre-training techniques, adaptation methods, and data modalities. Overall, this survey serves to consolidate the latest advancements in FMs pertinent to time series analysis, accentuating their theoretical underpinnings, recent strides in development, and avenues for future research exploration.","Thu, 21 Mar 2024 10:08:37 UTC (2,004 KB)"
"43","Individual and Product-Related Antecedents of Electronic Word-of-Mouth","Bogdan Anastasiei, Nicoleta Dospinescu, Octavian Dospinescu","Computers and Society (cs.CY)","This research investigates the antecedents of positive and negative electronic word-of-mouth (eWOM) propensity, as well as the impact of eWOM propensity on the intention to repurchase the product. Two types of eWOM predictors were considered: product related variables and personal factors. The data were collected through an online survey conducted on a sample of 335 Romanian subjects, and the analysis method was Structural Equation Modeling. Our findings show that personal factors - social media usage behavior, marketing mavenism and need to evaluate - are the most important antecedents of the intention to write product reviews and comments online, either positive or negative. From the product related factors, only brand trust influences the propensity to provide eWOM. Furthermore, both positive and negative eWOM intentions are associated with the repurchase intention.","Tue, 19 Mar 2024 07:50:26 UTC (592 KB)"
"44","Visualizing Progress in Broadening Participation in Computing: The Value of Context","Valerie Barr, Carla E. Brodley, Manuel A. Pérez-Quiñones","Computers and Society (cs.CY)","Concerns about representation in computing within the U.S. have driven numerous activities to broaden participation. Assessment of the impact of these efforts and, indeed, a clear assessment of the actual ""problem"" being addressed are limited by the nature of the most common data analysis which looks at the representation of each population as a percentage of the number of students graduating with a degree in computing. This use of a single metric cannot adequately assess the impact of broadening participation efforts. First, this approach fails to account for changing demographics of the undergraduate population in terms of overall numbers and relative proportion of the Federally designated gender, race, and ethnicity groupings. A second issue is that the majority of literature on broadening participation in computing (BPC) reports data on gender or on race/ethnicity, omitting data on students' intersectional identities. This leads to an incorrect understanding of both the data and the challenges we face as a field. In this paper we present several different approaches to tracking the impact of BPC efforts. We make three recommendations: 1) cohort-based analysis should be used to accurately show student engagement in computing; 2) the field as a whole needs to adopt the norm of always reporting intersectional data; 3) university demographic context matters when looking at how well a CS department is doing to broaden participation in computing, including longitudinal analysis of university demographic shifts that impact the local demographics of computing.","Mon, 18 Mar 2024 01:12:02 UTC (3,485 KB)"
"45","Synergy of Information in Multimodal IoT Systems -- Discovering the impact of daily behaviour routines on physical activity level","Mohsen Shirali, Zahra Ahmadi, Carlos Fernández-Llatas, Jose-Luis Bayo-Monton","Computers and Society (cs.CY)","The intricate connection between daily behaviours and health necessitates robust behaviour monitoring, particularly with the advent of IoT systems. This study introduces an innovative approach, exploiting the synergy of information from various IoT sources, to assess the alignment of behaviour routines with health guidelines. We grouped routines based on guideline compliance and used a clustering method to identify similarities in behaviours and key characteristics within each cluster. Applied to an elderly care case study, our approach unveils patterns leading to physical inactivity by categorising days based on recommended daily steps. Utilising data from wristbands, smartphones, and ambient sensors, the study provides insights not achievable with single-source data. Visualisation in a calendar view aids health experts in understanding patient behaviours, enabling precise interventions. Notably, the approach facilitates early detection of behaviour changes during events like COVID-19 and Ramadan, available in our dataset. This work signifies a promising path for behavioural analysis and discovering variations to empower smart healthcare, offering insights into patient health, personalised interventions, and healthier routines through continuous IoT-driven data analysis.","Sun, 17 Mar 2024 21:06:38 UTC (7,792 KB)"
"46","A2CI: A Cloud-based, Service-oriented Geospatial Cyberinfrastructure to Support Atmospheric Research","Wenwen Li, Hu Shao, Sizhe Wang, Xiran Zhou, Sheng Wu","Computers and Society (cs.CY)","Big earth science data offers the scientific community great opportunities. Many more studies at large-scales, over long-terms and at high resolution can now be conducted using the rich information collected by remote sensing satellites, ground-based sensor networks, and even social media input. However, the hundreds of terabytes of information collected and compiled on an hourly basis by NASA and other government agencies present a significant challenge for atmospheric scientists seeking to improve the understanding of the Earth atmospheric system. These challenges include effective discovery, organization, analysis and visualization of large amounts of data. This paper reports the outcomes of an NSF-funded project that developed a geospatial cyberinfrastructure -- the A2CI (Atmospheric Analysis Cyberinfrastructure) -- to support atmospheric research. We first introduce the service-oriented system framework then describe in detail the implementation of the data discovery module, data management module, data integration module, data analysis and visualization modules following the cloud computing principles-Data-as-a-Service, Software-as-a-Service, Platform-as-a-Service and Infrastructure-as-a-Service. We demonstrate the graphic user interface by performing an analysis between Sea Surface Temperature and the intensity of tropical storms in the North Atlantic and Pacific oceans. We expect this work to contribute to the technical advancement of cyberinfrastructure research as well as to the development of an online, collaborative scientific analysis system for atmospheric science.","Fri, 15 Mar 2024 08:28:38 UTC (2,731 KB)"
"47","Developing and Deploying Industry Standards for Artificial Intelligence in Education (AIED): Challenges, Strategies, and Future Directions","Richard Tong, Haoyang Li, Joleen Liang, Qingsong Wen","Computers and Society (cs.CY)","The adoption of Artificial Intelligence in Education (AIED) holds the promise of revolutionizing educational practices by offering personalized learning experiences, automating administrative and pedagogical tasks, and reducing the cost of content creation. However, the lack of standardized practices in the development and deployment of AIED solutions has led to fragmented ecosystems, which presents challenges in interoperability, scalability, and ethical governance. This article aims to address the critical need to develop and implement industry standards in AIED, offering a comprehensive analysis of the current landscape, challenges, and strategic approaches to overcome these obstacles. We begin by examining the various applications of AIED in various educational settings and identify key areas lacking in standardization, including system interoperability, ontology mapping, data integration, evaluation, and ethical governance. Then, we propose a multi-tiered framework for establishing robust industry standards for AIED. In addition, we discuss methodologies for the iterative development and deployment of standards, incorporating feedback loops from real-world applications to refine and adapt standards over time. The paper also highlights the role of emerging technologies and pedagogical theories in shaping future standards for AIED. Finally, we outline a strategic roadmap for stakeholders to implement these standards, fostering a cohesive and ethical AIED ecosystem. By establishing comprehensive industry standards, such as those by IEEE Artificial Intelligence Standards Committee (AISC) and International Organization for Standardization (ISO), we can accelerate and scale AIED solutions to improve educational outcomes, ensuring that technological advances align with the principles of inclusivity, fairness, and educational excellence.","Wed, 13 Mar 2024 22:38:08 UTC (2,156 KB)"
"48","Kernel Alignment for Unsupervised Feature Selection via Matrix Factorization","Ziyuan Lin, Deanna Needell","Machine Learning (cs.LG)","By removing irrelevant and redundant features, feature selection aims to find a good representation of the original features. With the prevalence of unlabeled data, unsupervised feature selection has been proven effective in alleviating the so-called curse of dimensionality. Most existing matrix factorization-based unsupervised feature selection methods are built upon subspace learning, but they have limitations in capturing nonlinear structural information among features. It is well-known that kernel techniques can capture nonlinear structural information. In this paper, we construct a model by integrating kernel functions and kernel alignment, which can be equivalently characterized as a matrix factorization problem. However, such an extension raises another issue: the algorithm performance heavily depends on the choice of kernel, which is often unknown a priori. Therefore, we further propose a multiple kernel-based learning method. By doing so, our model can learn both linear and nonlinear similarity information and automatically generate the most appropriate kernel. Experimental analysis on real-world data demonstrates that the two proposed methods outperform other classic and state-of-the-art unsupervised feature selection methods in terms of clustering results and redundancy reduction in almost all datasets tested.","Wed, 13 Mar 2024 20:35:44 UTC (836 KB)"
"49","Evaluating Pedagogical Incentives in Undergraduate Computing: A Mixed Methods Approach Using Learning Analytics","Laura J. Johnston, Takoua Jendoubi","Computers and Society (cs.CY)","In the context of higher education's evolving dynamics post-COVID-19, this paper assesses the impact of new pedagogical incentives implemented in a first-year undergraduate computing module at University College London. We employ a mixed methods approach, combining learning analytics with qualitative data, to evaluate the effectiveness of these incentives on increasing student engagement.
A longitudinal overview of resource interactions is mapped through Bayesian network analysis of Moodle activity logs from 204 students. This analysis identifies early resource engagement as a predictive indicator of continued engagement while also suggesting that the new incentives disproportionately benefit highly engaged students. Focus group discussions complement this analysis, providing insights into student perceptions of the pedagogical changes and the module design. These qualitative findings underscore the challenge of sustaining engagement through the new incentives and highlight the importance of communication in blended learning environments.
Our paper introduces an interpretable and actionable model for student engagement, which integrates objective, data-driven analysis with students' perspectives. This model provides educators with a tool to evaluate and improve instructional strategies. By demonstrating the effectiveness of our mixed methods approach in capturing the intricacies of student behaviour in digital learning environments, we underscore the model's potential to improve online pedagogical practices across diverse educational settings.","Wed, 13 Mar 2024 16:39:38 UTC (139 KB)"
"50","QubiCSV: An Open-Source Data Storage and Visualization Platform for Collaborative Qubit Control","Devanshu Brahmbhatt, Yilun Xu, Neel Vora, Larry Chen, Neelay Fruitwala, Gang Huang, Qing Ji, Phuc Nguyen","Quantum Physics (quant-ph)","Developing collaborative research platforms for quantum bit control is crucial for driving innovation in the field, as they enable the exchange of ideas, data, and implementation to achieve more impactful outcomes. Furthermore, considering the high costs associated with quantum experimental setups, collaborative environments are vital for maximizing resource utilization efficiently. However, the lack of dedicated data management platforms presents a significant obstacle to progress, highlighting the necessity for essential assistive tools tailored for this purpose. Current qubit control systems are unable to handle complicated management of extensive calibration data and do not support effectively visualizing intricate quantum experiment outcomes. In this paper, we introduce QubiCSV (Qubit Control Storage and Visualization), a platform specifically designed to meet the demands of quantum computing research, focusing on the storage and analysis of calibration and characterization data in qubit control systems. As an open-source tool, QubiCSV facilitates efficient data management of quantum computing, providing data versioning capabilities for data storage and allowing researchers and programmers to interact with qubits in real time. The insightful visualization are developed to interpret complex quantum experiments and optimize qubit performance. QubiCSV not only streamlines the handling of qubit control system data but also improves the user experience with intuitive visualization features, making it a valuable asset for researchers in the quantum computing domain.","Thu, 7 Mar 2024 00:49:42 UTC (19,150 KB)"
"51","Can the NANOGrav observations constrain the geometry of the universe?","Matteo Califano, Rocco D'Agostino, Daniele Vernieri","Cosmology and Nongalactic Astrophysics (astro-ph.CO)","The theory of inflation provides an elegant explanation for the nearly flat universe observed today, which represents one of the pillars of the standard cosmological model. However, recent studies have reported some deviations from a flat geometry, arguing that a closed universe would be instead favored by observations. Given its central role played in the cosmological context, this paper revisits the issue of spatial curvature in light of the stochastic gravitational wave background signal recently detected by the NANOGrav collaboration. For this purpose, we investigate the primordial gravitational waves generated during inflation and their propagation in the post-inflationary universe. We propose a new parametrization of the gravitational wave power spectrum, taking into account spatial curvature, the tensor-to-scalar ratio and the spectral index of tensor perturbations. Therefore, we compare the theoretical predictions with NANOGrav data to possibly constrain the geometry of the universe. We find that the choice of the priors has a significant effect on the computed posterior distributions. In particular, using flat uniform priors results in $\Omega_{\mathcal{K},0}= 0.00 \pm 0.67$ at the 68\% confidence level. On the other hand, imposing a Planck prior, we obtain $\Omega_{\mathcal{K},0}= -0.05 \pm 0.17$ at the 68\% confidence level. This result aligns with the analysis of the cosmic microwave background radiation, and no deviations from a flat universe are found.","Fri, 22 Mar 2024 17:52:27 UTC (1,475 KB)"
"52","Closing the Information Gap in Unidentified Anomalous Phenomena (UAP) Studies","Gretchen R. Stahlman","Digital Libraries (cs.DL)","Unidentified Anomalous Phenomena (UAP), also known as Unidentified Flying Objects (UFOs), has shifted from being a stigmatized topic on the fringes of scientific inquiry to a legitimate subject of scientific interest with a need for high quality, curated data, and rigorous scientific investigation. This paper presents a preliminary scoping review and analysis of scholarly literature related to UAP from 1967 until 2023, exploring a diverse range of research areas across disciplines to illustrate scholarly discourse about the topic. The paper focuses on characterizing papers published in recent years and notes that Library & Information Science is unrepresented in the current UAP literature. The paper also discusses how researchers across the iFields can contribute to UAP studies through inherent expertise such as data curation and data science as well as information behavior and information literacy, among others. The paper concludes by emphasizing that UAP Studies offer a rich intellectual realm for information science research, with the iFields well positioned to play a crucial role in supporting and engaging in the study of UAP.","Fri, 22 Mar 2024 17:40:04 UTC (385 KB)"
"53","Energy-dependent Boosted Dark Matter from Diffuse Supernova Neutrino Background","Anirban Das, Tim Herbermann, Manibrata Sen, Volodymyr Takhistov","High Energy Physics - Phenomenology (hep-ph)","Diffuse neutrinos from past supernovae in the Universe present us with a unique opportunity to test dark matter (DM) interactions. These neutrinos can scatter and boost the DM particles in the Milky Way halo to relativistic energies allowing us to detect them in terrestrial laboratories. Focusing on generic models of DM-neutrino and electron interactions, mediated by a vector or a scalar boson, we implement energy-dependent scattering cross-sections and perform detailed numerical analysis of DM attenuation due to electron scattering in-medium while propagating towards terrestrial experiments. We set new limits on DM-neutrino and electron interactions for DM with masses in the range $\sim (0.1, 10^4)~$MeV, using recent data from XENONnT, LUX-ZEPLIN, and PandaX-4T direct detection experiments. We demonstrate that consideration of energy-dependent cross-sections for DM interactions can significantly affect constraints previously derived under the assumption of constant cross-sections, modifying them by multiple orders of magnitude.","Fri, 22 Mar 2024 17:38:44 UTC (2,307 KB)"
"54","Learning Topological Representations for Deep Image Understanding","Xiaoling Hu","Computer Vision and Pattern Recognition (cs.CV)","In many scenarios, especially biomedical applications, the correct delineation of complex fine-scaled structures such as neurons, tissues, and vessels is critical for downstream analysis. Despite the strong predictive power of deep learning methods, they do not provide a satisfactory representation of these structures, thus creating significant barriers in scalable annotation and downstream analysis. In this dissertation, we tackle such challenges by proposing novel representations of these topological structures in a deep learning framework. We leverage the mathematical tools from topological data analysis, i.e., persistent homology and discrete Morse theory, to develop principled methods for better segmentation and uncertainty estimation, which will become powerful tools for scalable annotation.","Fri, 22 Mar 2024 17:23:37 UTC (31,299 KB)"
"55","Neural Plasticity-Inspired Foundation Model for Observing the Earth Crossing Modalities","Zhitong Xiong, Yi Wang, Fahong Zhang, Adam J. Stewart, Joëlle Hanna, Damian Borth, Ioannis Papoutsis, Bertrand Le Saux, Gustau Camps-Valls, Xiao Xiang Zhu","Computer Vision and Pattern Recognition (cs.CV)","The development of foundation models has revolutionized our ability to interpret the Earth's surface using satellite observational data. Traditional models have been siloed, tailored to specific sensors or data types like optical, radar, and hyperspectral, each with its own unique characteristics. This specialization hinders the potential for a holistic analysis that could benefit from the combined strengths of these diverse data sources. Our novel approach introduces the Dynamic One-For-All (DOFA) model, leveraging the concept of neural plasticity in brain science to integrate various data modalities into a single framework adaptively. This dynamic hypernetwork, adjusting to different wavelengths, enables a single versatile Transformer jointly trained on data from five sensors to excel across 12 distinct Earth observation tasks, including sensors never seen during pretraining. DOFA's innovative design offers a promising leap towards more accurate, efficient, and unified Earth observation analysis, showcasing remarkable adaptability and performance in harnessing the potential of multimodal Earth observation data.","Fri, 22 Mar 2024 17:11:47 UTC (35,969 KB)"
"56","Low-Regularity Solutions of the Nonlinear Schrödinger Equation on the Spatial Quarter-Plane","Dionyssios Mantzavinos, Türker Ozsarı","Analysis of PDEs (math.AP)","The Hadamard well-posedness of the nonlinear Schrödinger equation with power nonlinearity formulated on the spatial quarter-plane is established in a low-regularity setting with Sobolev initial data and Dirichlet boundary data in appropriate Bourgain-type spaces. As both of the spatial variables are restricted to the half-line, a different approach is needed than the one previously used for the well-posedness of other initial-boundary value problems. In particular, now the solution of the forced linear initial-boundary problem is estimated \textit{directly}, both in Sobolev spaces and in Strichartz-type spaces, i.e. without a linear decomposition that would require estimates for the associated homogeneous and nonhomogeneous initial value problems. In the process of deriving the linear estimates, the function spaces for the boundary data are identified as the intersections of certain modified Bourgain-type spaces that involve spatial half-line Fourier transforms instead of the usual whole-line Fourier transform found in the definition of the standard Bourgain space associated with the one-dimensional initial value problem. The fact that the quarter-plane has a corner at the origin poses an additional challenge, as it requires one to expand the validity of certain Sobolev extension results to the case of a domain with a non-smooth (Lipschitz) and non-compact boundary.","Fri, 22 Mar 2024 17:02:48 UTC (40 KB)"
"57","Global Analysis of LISA Data with Galactic Binaries and Massive Black Hole Binaries","Stefan H. Strub, Luigi Ferraioli, Cédric Schmelzbach, Simon C. Stähler, Domenico Giardini","General Relativity and Quantum Cosmology (gr-qc)","The Laser Interferometer Space Antenna (LISA) is a planned space-based observatory to measure gravitational waves in the millihertz frequency band. This frequency band is expected to be dominated by signals from millions of Galactic binaries and tens of merging massive black hole binaries. The LISA Data Challenge 2a is focused on the robust signal extraction from a blend of these two types of gravitational wave signals. Here, we introduce a novel high performance and cost-effective global fit pipeline extracting and characterizing galactic binary and massive black hole binary signals and estimate the noise of the residual. We preform the pipeline in a time-evolving weekly analysis starting with and observation time of 1 week until we reach a full year. As expected we detect more galactic binaries and massive black hole binaries bringing the noise estimate of the residual closer to the instrument noise by each week of additional observation time. Furthermore, we present a novel maximum likelihood estimate-based algorithm for extracting multiple massive black hole binaries. Additionally we demonstrate a massive black hole binary signal extraction with a more accurate LISA response, considering higher harmonic modes, in a noisy data set.","Fri, 22 Mar 2024 16:11:53 UTC (4,837 KB)"
"58","A data-driven approach to PDE-constrained optimization in inverse problems","Tristan van Leeuwen, Yunan Yang","Optimization and Control (math.OC)","Inverse problems are ubiquitous in science and engineering. Many of these are naturally formulated as a PDE-constrained optimization problem. These non-linear, large-scale, constrained optimization problems know many challenges, of which the inherent non-linearity of the problem is an important one. As an alternative to this physics-driven approach, data-driven methods have been proposed. These methods come with their own set of challenges, and it appears that, ideally, one would devise hybrid methods that combine the best of both worlds. In this paper, we propose one way of combining PDE-constrained optimization with recently proposed data-driven reduced-order models. Starting from an infinite-dimensional formulation of the inverse problem with discrete data, we propose a general framework for the analysis and discretisation of such problems. The proposed approach is based on a relaxed formulation of the PDE-constrained optimization problem, which reduces to a weighted non-linear least-squares problem. The weight matrix turns out to be the Gram matrix of solutions of the PDE, and it can be estimated directly from the measurements. We provide a number of representative case studies and numerical examples.","Fri, 22 Mar 2024 15:40:09 UTC (1,115 KB)"
"59","A data-informed mathematical model of microglial cell dynamics during ischemic stroke in the middle cerebral artery","Sara Amato, Andrea Arnold","Cell Behavior (q-bio.CB)","Neuroinflammation immediately follows the onset of ischemic stroke in the middle cerebral artery. During this process, microglial cells are activated in and recruited to the penumbra. Microglial cells can be activated into two different phenotypes: M1, which can worsen brain injury; or M2, which can aid in long-term recovery. In this study, we contribute a summary of experimental data on microglial cell counts in the penumbra following ischemic stroke induced by middle cerebral artery occlusion (MCAO) in mice and compile available data sets into a single set suitable for time series analysis. Further, we formulate a mathematical model of microglial cells in the penumbra during ischemic stroke due to MCAO. Through use of global sensitivity analysis and Markov Chain Monte Carlo (MCMC)-based parameter estimation, we analyze the effects of the model parameters on the number of M1 and M2 cells in the penumbra and fit identifiable parameters to the compiled experimental data set. We utilize results from MCMC parameter estimation to ascertain uncertainty bounds and forward predictions for the number of M1 and M2 microglial cells over time. Results demonstrate the significance of parameters related to M1 and M2 activation on the number of M1 and M2 microglial cells. Simulations further suggest that potential outliers in the observed data may be omitted and forecast predictions suggest a lingering inflammatory response.","Fri, 22 Mar 2024 15:31:07 UTC (288 KB)"
"60","Tests for almost stochastic dominance","Amparo Baíllo, Javier Cárcamo, Carlos Mora-Corral","Econometrics (econ.EM)","We introduce a 2-dimensional stochastic dominance (2DSD) index to characterize both strict and almost stochastic dominance. Based on this index, we derive an estimator for the minimum violation ratio (MVR), also known as the critical parameter, of the almost stochastic ordering condition between two variables. We determine the asymptotic properties of the empirical 2DSD index and MVR for the most frequently used stochastic orders. We also provide conditions under which the bootstrap estimators of these quantities are strongly consistent. As an application, we develop consistent bootstrap testing procedures for almost stochastic dominance. The performance of the tests is checked via simulations and the analysis of real data.","Fri, 22 Mar 2024 14:58:48 UTC (2,044 KB)"
"61","Self-Supervised Backbone Framework for Diverse Agricultural Vision Tasks","Sudhir Sornapudi (1), Rajhans Singh (1) ((1) Corteva Agriscience, Indianapolis, USA)","Computer Vision and Pattern Recognition (cs.CV)","Computer vision in agriculture is game-changing with its ability to transform farming into a data-driven, precise, and sustainable industry. Deep learning has empowered agriculture vision to analyze vast, complex visual data, but heavily rely on the availability of large annotated datasets. This remains a bottleneck as manual labeling is error-prone, time-consuming, and expensive. The lack of efficient labeling approaches inspired us to consider self-supervised learning as a paradigm shift, learning meaningful feature representations from raw agricultural image data. In this work, we explore how self-supervised representation learning unlocks the potential applicability to diverse agriculture vision tasks by eliminating the need for large-scale annotated datasets. We propose a lightweight framework utilizing SimCLR, a contrastive learning approach, to pre-train a ResNet-50 backbone on a large, unannotated dataset of real-world agriculture field images. Our experimental analysis and results indicate that the model learns robust features applicable to a broad range of downstream agriculture tasks discussed in the paper. Additionally, the reduced reliance on annotated data makes our approach more cost-effective and accessible, paving the way for broader adoption of computer vision in agriculture.","Fri, 22 Mar 2024 14:46:51 UTC (34,604 KB)"
"62","SFOD: Spiking Fusion Object Detector","Yimeng Fan, Wei Zhang, Changsong Liu, Mingyang Li, Wenrui Lu","Computer Vision and Pattern Recognition (cs.CV)","Event cameras, characterized by high temporal resolution, high dynamic range, low power consumption, and high pixel bandwidth, offer unique capabilities for object detection in specialized contexts. Despite these advantages, the inherent sparsity and asynchrony of event data pose challenges to existing object detection algorithms. Spiking Neural Networks (SNNs), inspired by the way the human brain codes and processes information, offer a potential solution to these difficulties. However, their performance in object detection using event cameras is limited in current implementations. In this paper, we propose the Spiking Fusion Object Detector (SFOD), a simple and efficient approach to SNN-based object detection. Specifically, we design a Spiking Fusion Module, achieving the first-time fusion of feature maps from different scales in SNNs applied to event cameras. Additionally, through integrating our analysis and experiments conducted during the pretraining of the backbone network on the NCAR dataset, we delve deeply into the impact of spiking decoding strategies and loss functions on model performance. Thereby, we establish state-of-the-art classification results based on SNNs, achieving 93.7\% accuracy on the NCAR dataset. Experimental results on the GEN1 detection dataset demonstrate that the SFOD achieves a state-of-the-art mAP of 32.1\%, outperforming existing SNN-based approaches. Our research not only underscores the potential of SNNs in object detection with event cameras but also propels the advancement of SNNs. Code is available at this https URL.","Fri, 22 Mar 2024 13:24:50 UTC (14,981 KB)"
"63","Double Cross-fit Doubly Robust Estimators: Beyond Series Regression","Alec McClean, Sivaraman Balakrishnan, Edward H. Kennedy, Larry Wasserman","Statistics Theory (math.ST)","Doubly robust estimators with cross-fitting have gained popularity in causal inference due to their favorable structure-agnostic error guarantees. However, when additional structure, such as Hölder smoothness, is available then more accurate ""double cross-fit doubly robust"" (DCDR) estimators can be constructed by splitting the training data and undersmoothing nuisance function estimators on independent samples. We study a DCDR estimator of the Expected Conditional Covariance, a functional of interest in causal inference and conditional independence testing, and derive a series of increasingly powerful results with progressively stronger assumptions. We first provide a structure-agnostic error analysis for the DCDR estimator with no assumptions on the nuisance functions or their estimators. Then, assuming the nuisance functions are Hölder smooth, but without assuming knowledge of the true smoothness level or the covariate density, we establish that DCDR estimators with several linear smoothers are semiparametric efficient under minimal conditions and achieve fast convergence rates in the non-$\sqrt{n}$ regime. When the covariate density and smoothnesses are known, we propose a minimax rate-optimal DCDR estimator based on undersmoothed kernel regression. Moreover, we show an undersmoothed DCDR estimator satisfies a slower-than-$\sqrt{n}$ central limit theorem, and that inference is possible even in the non-$\sqrt{n}$ regime. Finally, we support our theoretical results with simulations, providing intuition for double cross-fitting and undersmoothing, demonstrating where our estimator achieves semiparametric efficiency while the usual ""single cross-fit"" estimator fails, and illustrating asymptotic normality for the undersmoothed DCDR estimator.","Fri, 22 Mar 2024 12:59:03 UTC (1,902 KB)"
"64","AllHands: Ask Me Anything on Large-scale Verbatim Feedback via Large Language Models","Chaoyun Zhang, Zicheng Ma, Yuhao Wu, Shilin He, Si Qin, Minghua Ma, Xiaoting Qin, Yu Kang, Yuyi Liang, Xiaoyu Gou, Yajie Xue, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang","Software Engineering (cs.SE)","Verbatim feedback constitutes a valuable repository of user experiences, opinions, and requirements essential for software development. Effectively and efficiently extracting valuable insights from such data poses a challenging task. This paper introduces Allhands , an innovative analytic framework designed for large-scale feedback analysis through a natural language interface, leveraging large language models (LLMs). Allhands adheres to a conventional feedback analytic workflow, initially conducting classification and topic modeling on the feedback to convert them into a structurally augmented format, incorporating LLMs to enhance accuracy, robustness, generalization, and user-friendliness. Subsequently, an LLM agent is employed to interpret users' diverse questions in natural language on feedback, translating them into Python code for execution, and delivering comprehensive multi-modal responses, including text, code, tables, and images.
We evaluate Allhands across three diverse feedback datasets. The experiments demonstrate that Allhands achieves superior efficacy at all stages of analysis, including classification and topic modeling, eventually providing users with an ``ask me anything'' experience with comprehensive, correct and human-readable response. To the best of our knowledge, Allhands stands as the first comprehensive feedback analysis framework that supports diverse and customized requirements for insight extraction through a natural language interface.","Fri, 22 Mar 2024 12:13:16 UTC (817 KB)"
"65","An In-Depth Analysis of Data Reduction Methods for Sustainable Deep Learning","Víctor Toscano-Durán, Javier Perera-Lago, Eduardo Paluzo-Hidalgo, Rocío Gonzalez-Diaz, Miguel Ángel Gutierrez-Naranjo, Matteo Rucco","Machine Learning (cs.LG)","In recent years, Deep Learning has gained popularity for its ability to solve complex classification tasks, increasingly delivering better results thanks to the development of more accurate models, the availability of huge volumes of data and the improved computational capabilities of modern computers. However, these improvements in performance also bring efficiency problems, related to the storage of datasets and models, and to the waste of energy and time involved in both the training and inference processes. In this context, data reduction can help reduce energy consumption when training a deep learning model. In this paper, we present up to eight different methods to reduce the size of a tabular training dataset, and we develop a Python package to apply them. We also introduce a representativeness metric based on topology to measure how similar are the reduced datasets and the full training dataset. Additionally, we develop a methodology to apply these data reduction methods to image datasets for object detection tasks. Finally, we experimentally compare how these data reduction methods affect the representativeness of the reduced dataset, the energy consumption and the predictive performance of the model.","Fri, 22 Mar 2024 12:06:40 UTC (1,575 KB)"
"66","Text clustering with LLM embeddings","Alina Petukhova, Joao P. Matos-Carvalho, Nuno Fachada","Computation and Language (cs.CL)","Text clustering is an important approach for organising the growing amount of digital content, helping to structure and find hidden patterns in uncategorised data. In this research, we investigated how different textual embeddings - particularly those used in large language models (LLMs) - and clustering algorithms affect how text datasets are clustered. A series of experiments were conducted to assess how embeddings influence clustering results, the role played by dimensionality reduction through summarisation, and embedding size adjustment. Results reveal that LLM embeddings excel at capturing the nuances of structured language, while BERT leads the lightweight options in performance. In addition, we find that increasing embedding dimensionality and summarisation techniques do not uniformly improve clustering efficiency, suggesting that these strategies require careful analysis to use in real-life models. These results highlight a complex balance between the need for nuanced text representation and computational feasibility in text clustering applications. This study extends traditional text clustering frameworks by incorporating embeddings from LLMs, thereby paving the way for improved methodologies and opening new avenues for future research in various types of textual analysis.","Fri, 22 Mar 2024 11:08:48 UTC (83 KB)"
"67","CHisIEC: An Information Extraction Corpus for Ancient Chinese History","Xuemei Tang, Zekun Deng, Qi Su, Hao Yang, Jun Wang","Computation and Language (cs.CL)","Natural Language Processing (NLP) plays a pivotal role in the realm of Digital Humanities (DH) and serves as the cornerstone for advancing the structural analysis of historical and cultural heritage texts. This is particularly true for the domains of named entity recognition (NER) and relation extraction (RE). In our commitment to expediting ancient history and culture, we present the ``Chinese Historical Information Extraction Corpus''(CHisIEC). CHisIEC is a meticulously curated dataset designed to develop and evaluate NER and RE tasks, offering a resource to facilitate research in the field. Spanning a remarkable historical timeline encompassing data from 13 dynasties spanning over 1830 years, CHisIEC epitomizes the extensive temporal range and text heterogeneity inherent in Chinese historical documents. The dataset encompasses four distinct entity types and twelve relation types, resulting in a meticulously labeled dataset comprising 14,194 entities and 8,609 relations. To establish the robustness and versatility of our dataset, we have undertaken comprehensive experimentation involving models of various sizes and paradigms. Additionally, we have evaluated the capabilities of Large Language Models (LLMs) in the context of tasks related to ancient Chinese history. The dataset and code are available at \url{this https URL}.","Fri, 22 Mar 2024 10:12:10 UTC (1,313 KB)"
"68","GTAGCN: Generalized Topology Adaptive Graph Convolutional Networks","Sukhdeep Singh, Anuj Sharma, Vinod Kumar Chauhan","Machine Learning (cs.LG)","Graph Neural Networks (GNN) have emerged as a popular and standard approach for learning from graph-structured data. The literature on GNN highlights the potential of this evolving research area and its widespread adoption in real-life applications. However, most of the approaches are either new in concept or derived from specific techniques. Therefore, the potential of more than one approach in hybrid form has not been studied extensively, which can be well utilized for sequenced data or static data together. We derive a hybrid approach based on two established techniques as generalized aggregation networks and topology adaptive graph convolution networks that solve our purpose to apply on both types of sequenced and static nature of data, effectively. The proposed method applies to both node and graph classification. Our empirical analysis reveals that the results are at par with literature results and better for handwritten strokes as sequenced data, where graph structures have not been explored.","Fri, 22 Mar 2024 10:02:13 UTC (117 KB)"
"69","Comprehensive Lipidomic Automation Workflow using Large Language Models","Connor Beveridge, Sanjay Iyer, Caitlin E. Randolph, Matthew Muhoberac, Palak Manchanda, Amy C. Clingenpeel, Shane Tichy, Gaurav Chopra","Quantitative Methods (q-bio.QM)","Lipidomics generates large data that makes manual annotation and interpretation challenging. Lipid chemical and structural diversity with structural isomers further complicates annotation. Although, several commercial and open-source software for targeted lipid identification exists, it lacks automated method generation workflows and integration with statistical and bioinformatics tools. We have developed the Comprehensive Lipidomic Automated Workflow (CLAW) platform with integrated workflow for parsing, detailed statistical analysis and lipid annotations based on custom multiple reaction monitoring (MRM) precursor and product ion pair transitions. CLAW contains several modules including identification of carbon-carbon double bond position(s) in unsaturated lipids when combined with ozone electrospray ionization (OzESI)-MRM methodology. To demonstrate the utility of the automated workflow in CLAW, large-scale lipidomics data was collected with traditional and OzESI-MRM profiling on biological and non-biological samples. Specifically, a total of 1497 transitions organized into 10 MRM-based mass spectrometry methods were used to profile lipid droplets isolated from different brain regions of 18-24 month-old Alzheimer's disease mice and age-matched wild-type controls. Additionally, triacyclglycerols (TGs) profiles with carbon-carbon double bond specificity were generated from canola oil samples using OzESI-MRM profiling. We also developed an integrated language user interface with large language models using artificially intelligent (AI) agents that permits users to interact with the CLAW platform using a chatbot terminal to perform statistical and bioinformatic analyses. We envision CLAW pipeline to be used in high-throughput lipid structural identification tasks aiding users to generate automated lipidomics workflows ranging from data acquisition to AI agent-based bioinformatic analysis.","Fri, 22 Mar 2024 10:00:52 UTC (24,757 KB)"
"70","Construction of a Japanese Financial Benchmark for Large Language Models","Masanori Hirano","Computational Finance (q-fin.CP)","With the recent development of large language models (LLMs), models that focus on certain domains and languages have been discussed for their necessity. There is also a growing need for benchmarks to evaluate the performance of current LLMs in each domain. Therefore, in this study, we constructed a benchmark comprising multiple tasks specific to the Japanese and financial domains and performed benchmark measurements on some models. Consequently, we confirmed that GPT-4 is currently outstanding, and that the constructed benchmarks function effectively. According to our analysis, our benchmark can differentiate benchmark scores among models in all performance ranges by combining tasks with different difficulties.","Fri, 22 Mar 2024 09:40:27 UTC (154 KB)"
"71","A nonvariational form of the Neumann problem for Hölder continuous harmonic functions","M. Lanza de Cristoforis","Analysis of PDEs (math.AP)","We present a nonvariational setting for the Neumann problem for harmonic functions that are Hölder continuous and that may have infinite Dirichlet integral. Then we introduce a space of distributions on the boundary (a space of first order traces for Hölder continuous harmonic functions), we analyze the properties of the corresponding distributional single layer potential and we prove a representation theorem for harmonic Hölder continuous functions in terms of distributional single layer potentials. As an application, we solve the interior and exterior Neumann problem with distributional data in the space of first order traces that has been introduced.","Fri, 22 Mar 2024 09:29:09 UTC (38 KB)"
"72","Perturbations in PDE-constrained optimal control decay exponentially in space","Simone Göttlich, Manuel Schaller, Karl Worthmann","Optimization and Control (math.OC)","For linear-quadratic optimal control problems (OCPs) governed by elliptic and parabolic partial differential equations (PDEs), we investigate the impact of perturbations on optimal solutions. Local perturbations may occur, e.g., due to discretization of the optimality system or disturbed problem data. Whereas these perturbations may exhibit global effects in the uncontrolled case, we prove that the ramifications are exponentially damped in space under stabilizability- and detectability-like conditions. To this end, we prove a bound on the optimality condition's solution operator that is uniform in the domain size. Then, this uniformity is used in a scaling argument to show the exponential decay of perturbations in space. We numerically validate and illustrate our results by solving OCPs involving Helmholtz, Poisson, and advection-diffusion-reaction equations.","Fri, 22 Mar 2024 09:28:14 UTC (1,272 KB)"
"73","Estimation of multiple mean vectors in high dimension","Gilles Blanchard (LMO, DATASHAPE), Jean-Baptiste Fermanian (LMO), Hannah Marienwald (BIFOLD, TU)","Machine Learning (stat.ML)","We endeavour to estimate numerous multi-dimensional means of various probability distributions on a common space based on independent samples. Our approach involves forming estimators through convex combinations of empirical means derived from these samples. We introduce two strategies to find appropriate data-dependent convex combination weights: a first one employing a testing procedure to identify neighbouring means with low variance, which results in a closed-form plug-in formula for the weights, and a second one determining weights via minimization of an upper confidence bound on the quadratic risk.Through theoretical analysis, we evaluate the improvement in quadratic risk offered by our methods compared to the empirical means. Our analysis focuses on a dimensional asymptotics perspective, showing that our methods asymptotically approach an oracle (minimax) improvement as the effective dimension of the data increases.We demonstrate the efficacy of our methods in estimating multiple kernel mean embeddings through experiments on both simulated and real-world datasets.","Fri, 22 Mar 2024 08:42:41 UTC (1,755 KB)"
"74","Ellipsoidal embeddings of graphs","Michaël Fanuel, Antoine Aspeel, Michael T. Schaub, Jean-Charles Delvenne","Social and Information Networks (cs.SI)","Due to their flexibility to represent almost any kind of relational data, graph-based models have enjoyed a tremendous success over the past decades. While graphs are inherently only combinatorial objects, however, many prominent analysis tools are based on the algebraic representation of graphs via matrices such as the graph Laplacian, or on associated graph embeddings. Such embeddings associate to each node a set of coordinates in a vector space, a representation which can then be employed for learning tasks such as the classification or alignment of the nodes of the graph. As the geometric picture provided by embedding methods enables the use of a multitude of methods developed for vector space data, embeddings have thus gained interest both from a theoretical as well as a practical perspective. Inspired by trace-optimization problems, often encountered in the analysis of graph-based data, here we present a method to derive ellipsoidal embeddings of the nodes of a graph, in which each node is assigned a set of coordinates on the surface of a hyperellipsoid. Our method may be seen as an alternative to popular spectral embedding techniques, to which it shares certain similarities we discuss. To illustrate the utility of the embedding we conduct a case study in which analyse synthetic and real world networks with modular structure, and compare the results obtained with known methods in the literature.","Fri, 22 Mar 2024 08:11:56 UTC (3,665 KB)"
"75","Precise measurement of the $e^+e^-\to D_s^+D_s^-$ cross sections at center-of-mass energies from threshold to 4.95 GeV","BESIII Collaboration: M. Ablikim, M. N. Achasov, P. Adlarson, O. Afedulidis, X. C. Ai, R. Aliberti, A. Amoroso, Q. An, Y. Bai, O. Bakina, I. Balossino, Y. Ban, H.-R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, J. F. Chang, G. R. Che, G. Chelkov, C. Chen, C. H. Chen, Chao Chen, G. Chen, H. S. Chen, H. Y. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, Y. B. Chen, Y. Q. Chen, Z. J. Chen, Z. Y. Chen, S. K. Choi, G. Cibinetto, F. Cossio, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, C. Q. Deng, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, Y. Y. Duan, Z. H. Duan, P. Egorov, Y. H. Fan, J. Fang, J. Fang, S. S. Fang, W. X. Fang, Y. Fang, Y. Q. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, Y. T. Feng, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, X. B. Gao

<!--
function toggleAuthorList(whichLayer,toggleThis)
{
  var elem, vis, tempToggle;
  tempToggle=toggleThis;
  if( document.getElementById ) // standard
      elem = document.getElementById( whichLayer );
  else if( document.all ) // old msie versions
      elem = document.all[whichLayer];
  else if( document.layers ) // nn4
      elem = document.layers[whichLayer];
  vis = elem.style;
  // if the style.display value is blank we try to figure it out here
  if(vis.display==''&&elem.offsetWidth!=undefined&&elem.offsetHeight!=undefined)
    vis.display = (elem.offsetWidth!=0&&elem.offsetHeight!=0)?'inline':'none';
  vis.display = (vis.display==''||vis.display=='inline')?'none':'inline';

  // toggle link inner text
  status = vis.display;
  if(status=='none'){
      document.getElementById('toggle').innerHTML = tempToggle ;
      document.getElementById('toggle').title = ""Show Entire Author List"";
  }
  else if(status=='inline'){
      document.getElementById('toggle').innerHTML = ""(collapse list)"";
      document.getElementById('toggle').title = ""Collapse Author List"";
  }
}
//-->

        , Y. N. Gao, Yang Gao, S. Garbolino, I. Garzia, L. Ge, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A. Gilman, K. Goetzen, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, F. Hanisch, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, T. Holtmann, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, B. Y. Hu, H. M. Hu, J. F. Hu, S. L. Hu, T. Hu, Y. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, X. T. Huang, Y. P. Huang, Y. S. Huang, T. Hussain, F. Hölzken, N. Hüsken, N. in der Wiesche, J. Jackson, S. Janchiv, J. H. Jeong, Q. Ji, Q. P. Ji, W. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, X. Q. Jia, Z. K. Jia, D. Jiang, H. B. Jiang, P. C. Jiang, S. S. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, J. K. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, X. Kui, N. Kumar, A. Kupsc, W. Kühn, J. J. Lane, P. Larin, L. Lavezzi, T. T. Lei, Z. H. Lei, M. Lellmann, T. Lenz, C. Li, C. Li, C. H. Li, Cheng Li, D. M. Li, F. Li, G. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, K. Li, L. J. Li, L. K. Li, Lei Li, M. H. Li, P. R. Li, Q. M. Li, Q. X. Li, R. Li, S. X. Li, T. Li, W. D. Li, W. G. Li, X. Li, X. H. Li, X. L. Li, X. Y. Li, X. Z. Li, Y. G. Li, Z. J. Li, Z. Y. Li, C. Liang, H. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, L. Z. Liao, Y. P. Liao, J. Libby, A. Limphirat, C. C. Lin, D. X. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. Liu, F. H. Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. H. Liu, H. M. Liu, Huihui Liu, J. B. Liu, J. Y. Liu, K. Liu, K. Y. Liu, Ke Liu, L. Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, X. Liu, X. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. D. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, X. L. Lu, Y. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, J. R. Luo, M. X. Luo, T. Luo, X. L. Luo, X. R. Lyu, Y. F. Lyu, F. C. Ma, H. Ma, H. L. Ma, J. L. Ma, L. L. Ma, M. M. Ma, Q. M. Ma, R. Q. Ma, T. Ma, X. T. Ma, X. Y. Ma, Y. Ma, Y. M. Ma, F. E. Maas, M. Maggiora, S. Malde, Y. J. Mao, Z. P. Mao, S. Marcello, Z. X. Meng, J. G. Messchendorp, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, L. S. Nie, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, Y. Niu, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, P. Patteri, Y. P. Pei, M. Pelizaeus, H. P. Peng, Y. Y. Peng, K. Peters, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. Qi, H. R. Qi, M. Qi, T. Y. Qi, S. Qian, W. B. Qian, C. F. Qiao, X. K. Qiao, J. J. Qin, L. Q. Qin, L. Y. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, Z. H. Qu, C. F. Redmer, K. J. Ren, A. Rivetti, M. Rolo, G. Rong, Ch. Rosner, S. N. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, Z. J. Shang, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. Shi, H. C. Shi, J. L. Shi, J. Y. Shi, Q. Q. Shi, S. Y. Shi, X. Shi, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, Y. X. Song, S. Sosio, S. Spataro, F. Stieler, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, W. Y. Sun, Y. Sun, Y. J. Sun, Y. Z. Sun, Z. Q. Sun, Z. T. Sun, C. J. Tang, G. Y. Tang, J. Tang, M. Tang, Y. A. Tang, L. Y. Tao, Q. T. Tao, M. Tat, J. X. Teng, V. Thoren, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, Y. Wan, S. J. Wang, B. Wang, B. L. Wang, Bo Wang, D. Y. Wang, F. Wang, H. J. Wang, J. J. Wang, J. P. Wang, K. Wang, L. L. Wang, M. Wang, N. Y. Wang, S. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, X. N. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Z. Wang, Z. L. Wang, Z. Y. Wang, Ziyi Wang, D. H. Wei, F. Weidner, S. P. Wen, Y. R. Wen, U. Wiedner, G. Wilkinson, M. Wolke, L. Wollenberg, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, X. Wu, X. H. Wu, Y. Wu, Y. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, B. H. Xiang, T. Xiang, D. Xiao, G. Y. Xiao, S. Y. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, H. Y. Xu, M. Xu, Q. J. Xu, Q. N. Xu, W. Xu, W. L. Xu, X. P. Xu, Y. C. Xu, Z. P. Xu, Z. S. Xu, F. Yan, L. Yan, W. B. Yan, W. C. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, T. Yang, Y. Yang, Y. F. Yang, Y. F. Yang, Y. X. Yang, Z. W. Yang, Z. P. Yao, M. Ye, M. H. Ye, J. H. Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, T. Yu, X. D. Yu, Y. C. Yu, C. Z. Yuan, J. Yuan, J. Yuan, L. Yuan, S. C. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, A. A. Zafar, F. R. Zeng, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, Y. J. Zeng, X. Y. Zhai, Y. C. Zhai, Y. H. Zhan, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, H. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. H. Zhang, H. Q. Zhang, H. R. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. S. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, Lei Zhang, P. Zhang, Q. Y. Zhang, R. Y. Zhang, S. H. Zhang, Shulei Zhang, X. D. Zhang, X. M. Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Y. M. Zhang, Yan Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. Y. Zhang, Z. Y. Zhang, Z. Z. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, L. Zhao, Lei Zhao, M. G. Zhao, N. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, B. M. Zheng, J. P. Zheng, W. J. Zheng, Y. H. Zheng, B. Zhong, X. Zhong, H. Zhou, J. Y. Zhou, L. P. Zhou, S. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. Z. Zhou, J. Zhu, K. Zhu, K. J. Zhu, K. S. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, S. Q. Zhu, T. J. Zhu, W. D. Zhu, Y. C. Zhu, Z. A. Zhu, J. H. Zou, J. Zu
  
  
    et al. (563 additional authors not shown)
   You must enable JavaScript to view entire author list.","High Energy Physics - Experiment (hep-ex)","Using the $e^+e^-$ collision data collected with the BESIII detector operating at the BEPCII collider, at center-of-mass energies from the threshold to $4.95$~GeV, we present precise measurements of the cross sections for the process $e^+e^-\to D_s^+D_s^-$ using a single tag method. The resulting cross section lineshape exhibits several new structures, thereby offering an input for coupled channel analysis and model tests, which are critical to understand vector charmonium-like states with masses between 4 and 5~GeV.","Fri, 22 Mar 2024 07:20:20 UTC (155 KB)"
"76","Risk and Response in Large Language Models: Evaluating Key Threat Categories","Bahareh Harandizadeh, Abel Salinas, Fred Morstatter","Computation and Language (cs.CL)","This paper explores the pressing issue of risk assessment in Large Language Models (LLMs) as they become increasingly prevalent in various applications. Focusing on how reward models, which are designed to fine-tune pretrained LLMs to align with human values, perceive and categorize different types of risks, we delve into the challenges posed by the subjective nature of preference-based training data. By utilizing the Anthropic Red-team dataset, we analyze major risk categories, including Information Hazards, Malicious Uses, and Discrimination/Hateful content. Our findings indicate that LLMs tend to consider Information Hazards less harmful, a finding confirmed by a specially developed regression model. Additionally, our analysis shows that LLMs respond less stringently to Information Hazards compared to other risks. The study further reveals a significant vulnerability of LLMs to jailbreaking attacks in Information Hazard scenarios, highlighting a critical security concern in LLM risk assessment and emphasizing the need for improved AI safety measures.","Fri, 22 Mar 2024 06:46:40 UTC (10,014 KB)"
"77","Two-scale Analysis for Multiscale Landau-Lifshitz-Gilbert Equation: Theory and Numerical Methods","Xiaofei Guan, Hang Qi, Zhiwei Sun","Numerical Analysis (math.NA)","This paper discusses the theory and numerical method of two-scale analysis for the multiscale Landau-Lifshitz-Gilbert equation in composite ferromagnetic materials. The novelty of this work can be summarized in three aspects: Firstly, the more realistic and complex model is considered, including the effects of the exchange field, anisotropy field, stray field, and external magnetic field. The explicit convergence orders in the $H^1$ norm between the classical solution and the two-scale solution are obtained. Secondly, we propose a robust numerical framework, which is employed in several comprehensive experiments to validate the convergence results for the Periodic and Neumann problems. Thirdly, we design an improved implicit numerical scheme to reduce the required number of iterations and relaxes the constraints on the time step size, which can significantly improve computational efficiency. Specifically, the projection and the expansion methods are given to overcome the inherent non-consistency in the initial data between the multiscale problem and homogenized problem.","Fri, 22 Mar 2024 05:21:57 UTC (3,746 KB)"
"78","Creating a Spatial Vulnerability Index for Environmental Health","Aiden Price, Kerrie Mengersen, Michael Rigby, Paula Fiévez","Methodology (stat.ME)","Extreme natural hazards are increasing in frequency and intensity. These natural changes in our environment, combined with man-made pollution, have substantial economic, social and health impacts globally. The impact of the environment on human health (environmental health) is becoming well understood in international research literature. However, there are significant barriers to understanding key characteristics of this impact, related to substantial data volumes, data access rights and the time required to compile and compare data over regions and time. This study aims to reduce these barriers in Australia by creating an open data repository of national environmental health data and presenting a methodology for the production of health outcome-weighted population vulnerability indices related to extreme heat, extreme cold and air pollution at various temporal and geographical resolutions.
Current state-of-the-art methods for the calculation of vulnerability indices include equal weight percentile ranking and the use of principal component analysis (PCA). The weighted vulnerability index methodology proposed in this study offers an advantage over others in the literature by considering health outcomes in the calculation process. The resulting vulnerability percentiles more clearly align population sensitivity and adaptive capacity with health risks. The temporal and spatial resolutions of the indices enable national monitoring on a scale never before seen across Australia. Additionally, we show that a weekly temporal resolution can be used to identify spikes in vulnerability due to changes in relative national environmental exposure.","Fri, 22 Mar 2024 05:13:27 UTC (12,883 KB)"
"79","Addressing Concept Shift in Online Time Series Forecasting: Detect-then-Adapt","YiFan Zhang, Weiqi Chen, Zhaoyang Zhu, Dalin Qin, Liang Sun, Xue Wang, Qingsong Wen, Zhang Zhang, Liang Wang, Rong Jin","Machine Learning (cs.LG)","Online updating of time series forecasting models aims to tackle the challenge of concept drifting by adjusting forecasting models based on streaming data. While numerous algorithms have been developed, most of them focus on model design and updating. In practice, many of these methods struggle with continuous performance regression in the face of accumulated concept drifts over time. To address this limitation, we present a novel approach, Concept \textbf{D}rift \textbf{D}etection an\textbf{D} \textbf{A}daptation (D3A), that first detects drifting conception and then aggressively adapts the current model to the drifted concepts after the detection for rapid adaption. To best harness the utility of historical data for model adaptation, we propose a data augmentation strategy introducing Gaussian noise into existing training instances. It helps mitigate the data distribution gap, a critical factor contributing to train-test performance inconsistency. The significance of our data augmentation process is verified by our theoretical analysis. Our empirical studies across six datasets demonstrate the effectiveness of D3A in improving model adaptation capability. Notably, compared to a simple Temporal Convolutional Network (TCN) baseline, D3A reduces the average Mean Squared Error (MSE) by $43.9\%$. For the state-of-the-art (SOTA) model, the MSE is reduced by $33.3\%$.","Fri, 22 Mar 2024 04:44:43 UTC (5,404 KB)"
"80","Contrastive Learning on Multimodal Analysis of Electronic Health Records","Tianxi Cai, Feiqing Huang, Ryumei Nakada, Linjun Zhang, Doudou Zhou","Machine Learning (stat.ML)","Electronic health record (EHR) systems contain a wealth of multimodal clinical data including structured data like clinical codes and unstructured data such as clinical notes. However, many existing EHR-focused studies has traditionally either concentrated on an individual modality or merged different modalities in a rather rudimentary fashion. This approach often results in the perception of structured and unstructured data as separate entities, neglecting the inherent synergy between them. Specifically, the two important modalities contain clinically relevant, inextricably linked and complementary health information. A more complete picture of a patient's medical history is captured by the joint analysis of the two modalities of data. Despite the great success of multimodal contrastive learning on vision-language, its potential remains under-explored in the realm of multimodal EHR, particularly in terms of its theoretical understanding. To accommodate the statistical analysis of multimodal EHR data, in this paper, we propose a novel multimodal feature embedding generative model and design a multimodal contrastive loss to obtain the multimodal EHR feature representation. Our theoretical analysis demonstrates the effectiveness of multimodal learning compared to single-modality learning and connects the solution of the loss function to the singular value decomposition of a pointwise mutual information matrix. This connection paves the way for a privacy-preserving algorithm tailored for multimodal EHR feature representation learning. Simulation studies show that the proposed algorithm performs well under a variety of configurations. We further validate the clinical utility of the proposed algorithm in real-world EHR data.","Fri, 22 Mar 2024 03:01:42 UTC (5,781 KB)"
"81","Computational Approaches for Exponential-Family Factor Analysis","Liang Wang, Luis Carvalho","Methodology (stat.ME)","We study a general factor analysis framework where the $n$-by-$p$ data matrix is assumed to follow a general exponential family distribution entry-wise. While this model framework has been proposed before, we here further relax its distributional assumption by using a quasi-likelihood setup. By parameterizing the mean-variance relationship on data entries, we additionally introduce a dispersion parameter and entry-wise weights to model large variations and missing values. The resulting model is thus not only robust to distribution misspecification but also more flexible and able to capture non-Gaussian covariance structures of the data matrix. Our main focus is on efficient computational approaches to perform the factor analysis. Previous modeling frameworks rely on simulated maximum likelihood (SML) to find the factorization solution, but this method was shown to lead to asymptotic bias when the simulated sample size grows slower than the square root of the sample size $n$, eliminating its practical application for data matrices with large $n$. Borrowing from expectation-maximization (EM) and stochastic gradient descent (SGD), we investigate three estimation procedures based on iterative factorization updates. Our proposed solution does not show asymptotic biases, and scales even better for large matrix factorizations with error $O(1/p)$. To support our findings, we conduct simulation experiments and discuss its application in three case studies.","Fri, 22 Mar 2024 02:58:14 UTC (4,090 KB)"
"82","Analysis of Log Data from an International Online Educational Assessment System: A Multi-state Survival Modeling Approach to Reaction Time between and across Action Sequence","Jina Park, Ick Hoon Jin, Minjeong Jeon","Applications (stat.AP)","With increasingly available computer-based or online assessments, researchers have shown keen interest in analyzing log data to improve our understanding of test takers' problem-solving processes. In this paper, we propose a multi-state survival model (MSM) to action sequence data from log files, focusing on modeling test takers' reaction times between actions, in order to investigate which factors and how they influence test takers' transition speed between actions. In particular, we focus on the effects of the occurrence and timing of key actions that differentiate correct answers from incorrect answers. We demonstrate our proposed approach with problem-solving test items from the the Programme for International Assessment of Adult Competence (PIAAC) problem-solving test items.","Fri, 22 Mar 2024 02:02:19 UTC (9,935 KB)"
"83","Unraveling Contagion Origins: Optimal Estimation through Maximum-Likelihood and Starlike Tree Approximation in Markovian Spreading Models","Pei-Duo Yu, Chee Wei Tan, Liang Zheng, Chao Zhao","Social and Information Networks (cs.SI)","Identifying the source of epidemic-like spread in networks is crucial for tasks like removing internet viruses or finding the rumor source in online social networks. The challenge lies in tracing the source from a snapshot observation of infected nodes. How do we accurately pinpoint the source? Utilizing snapshot data, we apply a probabilistic approach, focusing on the graph boundary and the observed time, to detect sources via an effective maximum likelihood algorithm. A novel starlike tree approximation extends applicability to general graphs, demonstrating versatility. We highlight the utility of the Gamma function for analyzing the asymptotic behavior of the likelihood ratio between nodes. Comprehensive evaluations confirm algorithmic effectiveness in diverse network scenarios, advancing rumor source detection in large-scale network analysis and information dissemination strategies.","Fri, 22 Mar 2024 00:19:29 UTC (12,842 KB)"
"84","Description of CuInP$_{2}$S$_{6}$ ferrielectrics in a mixed Ising model","R. Yevych, V. Liubachko, V. Hryts, M. Medulych, A. Kohutych, Yu. Vysochanskii","Soft Condensed Matter (cond-mat.soft)","The appearance of spontaneous polarization in CuInP$_{2}$S$_{6}$ ferrielectrics is related to the second order Jahn-Teller effect for copper cations located in a double-well local potential, the stereoactivity of indium cations located in a three-well local potential, as well as the valence fluctuations of phosphorus cations. The paraelectric to ferrielectric phase transition is primarily determined by the coupling of indium cations with their surroundings. This transition can be analyzed using the mixed Ising model with spins $s = 1/2$ and $S = 1$. The spectrum of pseudospin fluctuations at different temperatures was calculated using a mean-field approach for a set of quantum anharmonic oscillators. The results were then compared with Raman spectroscopy data for CuInP$_{2}$S$_{6}$ crystal. The analysis indicates that the lattice anharmonicity below 150 K, is mainly determined by the indium sublattice, leading to the coexistence of the glassy state and ferrielectric phase. Above 150 K, the anharmonicity of the copper sublattice activates the ionic conductivity and results in the existence of a long-ranged fluctuated cluster of spontaneous polarization in a temperature interval of the paraelectric phase above $T_{C}$.","Thu, 21 Mar 2024 22:04:04 UTC (5,100 KB)"
"85","Revisiting the wetting behavior of solid surfaces by water-like models within a density functional theory","A. Kozina, M. Aguilar, O. Pizio, S. Sokołowski","Soft Condensed Matter (cond-mat.soft)","We perform the analysis of predictions of a classical density functional theory for associating fluids with different association strength concerned with wetting of solid surfaces. The four associating sites water-like models with non-associative square-well attraction parametrized by Clark et al. [Mol. Phys., 2006, 104, 3561] are considered. The fluid-solid potential is assumed to have a 10-4-3 functional form. The growth of water film on the substrate upon changing the chemical potential is described. The wetting and prewetting critical temperatures, as well as the prewetting phase diagram are evaluated for different fluid-solid attraction strength from the analysis of the adsorption isotherms. Moreover, the temperature dependence of the contact angle is obtained from the Young equation. It yields estimates for the wetting temperature as well. Theoretical findings are compared with experimental results and in a few cases with data from computer simulations. The theory is successful and quite accurate in describing the wetting temperature and contact angle changes with temperature for different values of fluid-substrate attraction. Moreover, the method provides an easy tool to study other associating fluids on solids of importance for chemical engineering, in comparison with laboratory experiments and computer simulations.","Thu, 21 Mar 2024 20:40:40 UTC (278 KB)"
"86","Non-holomorphic modular forms from zeta generators","Daniele Dorigoni, Mehregan Doroudiani, Joshua Drewitt, Martijn Hidding, Axel Kleinschmidt, Oliver Schlotterer, Leila Schneps, Bram Verbeek","High Energy Physics - Theory (hep-th)","We study non-holomorphic modular forms built from iterated integrals of holomorphic modular forms for SL$(2,\mathbb Z)$ known as equivariant iterated Eisenstein integrals. A special subclass of them furnishes an equivalent description of the modular graph forms appearing in the low-energy expansion of string amplitudes at genus one. Notably the Fourier expansion of modular graph forms contains single-valued multiple zeta values. We deduce the appearance of products and higher-depth instances of multiple zeta values in equivariant iterated Eisenstein integrals, and ultimately modular graph forms, from the appearance of simpler odd Riemann zeta values. This analysis relies on so-called zeta generators which act on certain non-commutative variables in the generating series of the iterated integrals. From an extension of these non-commutative variables we incorporate iterated integrals involving holomorphic cusp forms into our setup and use them to construct the modular completion of triple Eisenstein integrals. Our work represents a fully explicit realisation of the modular graph forms within Brown's framework of equivariant iterated Eisenstein integrals and reveals structural analogies between single-valued period functions appearing in genus zero and one string amplitudes.","Thu, 21 Mar 2024 20:12:04 UTC (5,750 KB)"
"87","Normalizing Flows for Domain Adaptation when Identifying $Λ$ Hyperon Events","Rowan Kelleher, Anselm Vossen","Data Analysis, Statistics and Probability (physics.data-an)","This study focuses on the novel application of a normalizing flow as a method of domain adaptation. Normalizing flows offer a way to transform data points between two different distributions. The present study investigates a method of transforming latent representations of physics data to a normal distribution and then to a physics distribution again. The final distribution models a simulated distribution. Following the transformation process, the data can be classified by a neural network trained on labeled simulation data. The present study succeeds in training two normalizing flows that can transform between data (or simulation) and a Gaussian distribution.","Thu, 21 Mar 2024 19:32:31 UTC (682 KB)"
"88","Identifying Attention-Deficit/Hyperactivity Disorder through the electroencephalogram complexity","Dimitri Marques Abramov, Henrique Santos Lima, Vladimir Lazarev, Paulo Ricardo Galhanone, Constantino Tsallis","Neurons and Cognition (q-bio.NC)","There are reasons to suggest that a number of mental disorders may be related to alteration in the neural complexity (NC). Thus, quantitative analysis of NC could be helpful in classifying mental conditions and clarifying our understanding about them. Here, we have worked with youths, typical and with attention-deficit/hyperactivity disorder (ADHD), whose neural complexity was assessed using q-statistics applied to the electroencephalogram (EEG). The EEG was recorded while subjects performed the visual Attention Network Test (ANT) based on the OddBall paradigm and during a shortpretask period of resting state. Time intervals of the EEG amplitudes that passed a threshold (signal regularity indicator) were collected from task and pretask signals from each subject. The data were satisfactorily fitted with a stretched $q$-exponential including a power-law prefactor(characterized by the exponent c), thus determining the best $(c, q)$ for each subject, indicative of their individual complexity. We found larger values of $q$ and $c$ in ADHD subjects as compared with the typical subjects both at task and pretask periods, the task values for both groups being larger than at rest. The $c$ parameter was highly specific in relation to DSM diagnosis for inattention, where well-defined clusters were observed. The parameter values were organized in four well-defined clusters in $(c, q)$-space. As expected, the tasks apparently induced greater complexity in neural functional states with likely greater amount of internal information processing. The results suggest that complexity is higher in ADHD subjects than in typical pairs. The distribution of values in the $(c, q)$-space derived from $q$-statistics seems to be a promising biomarker for ADHD diagnosis.","Thu, 21 Mar 2024 19:26:52 UTC (516 KB)"
"89","Background information: a study on the sensitivity of astrophysical gravitational-wave background searches","Arianna I. Renzini, Thomas A. Callister, Katerina Chatziioannou, Will M. Farr","High Energy Astrophysical Phenomena (astro-ph.HE)","The vast majority of gravitational-wave signals from stellar-mass compact binary mergers are too weak to be individually detected with present-day instruments and instead contribute to a faint, persistent background. This astrophysical background is targeted by searches that model the gravitational-wave ensemble collectively with a small set of parameters. The traditional search models the background as a stochastic field and estimates its amplitude by cross-correlating data from multiple interferometers. A different search uses gravitational-wave templates to marginalize over all individual event parameters and measure the duty cycle and population properties of binary mergers. Both searches ultimately estimate the total merger rate of compact binaries and are expected to yield a detection in the coming years. Given the conceptual and methodological differences between them, though, it is not well understood how their results should be mutually interpreted. In this paper, we use the Fisher information to study the implications of a background detection in terms of which region of the Universe each approach probes. Specifically, we quantify how information about the compact binary merger rate is accumulated by each search as a function of the event redshift. For the LIGO Design sensitivity and a uniform-in-comoving-volume distribution of equal-mass 30M_sol binaries, the traditional cross-correlation search obtains 99% of its information from binaries up to redshift 2.5 (average signal-to-noise-ratio <8), and the template-based search from binaries up to redshift 1.0 (average signal-to-noise-ratio ~8). While we do not calculate the total information accumulated by each search, our analysis emphasizes the need to pair any claimed detection of the stochastic background with an assessment of which binaries contribute to said detection.","Thu, 21 Mar 2024 19:14:10 UTC (847 KB)"
"90","The central black hole in the dwarf spheroidal galaxy Leo I Not supermassive, at most an intermediate-mass candidate","R. Pascale, C. Nipoti, F. Calura, A. Della Croce","Astrophysics of Galaxies (astro-ph.GA)","It has been recently claimed that a surprisingly massive black hole (BH) is present in the core of the dwarf spheroidal galaxy (dSph) Leo I. Based on integral field spectroscopy, this finding challenges the typical expectation of dSphs hosting BHs of intermediate-mass, since such a BH would better be classified as supermassive. Indeed, the analysis points toward Leo I harboring a BH with a lower mass limit exceeding a few $10^6M_\odot$ at $1\sigma$, and the no BH case excluded at 95\% significance. Such a value, comparable to the entire stellar mass of the galaxy, makes Leo I a unique system that warrants further investigations. Using equilibrium models based on distribution functions (DFs) depending on actions $f({\boldsymbol J})$ coupled with the same integral field spectroscopy data and an extensive exploration of a very large parameter space, we demonstrate, within a comprehensive Bayesian framework of model-data comparison, that the posterior on the BH mass is flat towards the low-mass end and, thus, that the kinematics of the central galaxy region only imposes an upper limit on the BH mass of few $10^5M_\odot$ (at $3\sigma$). Such an upper limit brings back the putative BH of Leo I under the category of intermediate-mass BHs, and it is also in line with formation scenarios and expectations from scaling relations at the mass regime of dwarf galaxies.","Thu, 21 Mar 2024 19:00:02 UTC (6,909 KB)"
"91","Fast likelihood-free inference in the LSS Stage IV era","Guillermo Franco Abellán, Guadalupe Cañas Herrera, Matteo Martinelli, Oleg Savchenko, Davide Sciotti, Christoph Weniger","Cosmology and Nongalactic Astrophysics (astro-ph.CO)","Forthcoming large-scale structure (LSS) Stage IV surveys will provide us with unprecedented data to probe the nature of dark matter and dark energy. However, analysing these data with conventional Markov Chain Monte Carlo (MCMC) methods will be challenging, due to the increase in the number of nuisance parameters and the presence of intractable likelihoods. In light of this, we present the first application of Marginal Neural Ratio Estimation (MNRE) (a recent approach in simulation-based inference) to LSS photometric probes: weak lensing, galaxy clustering and the cross-correlation power spectra. In order to analyse the hundreds of spectra simultaneously, we find that a pre-compression of data using principal component analysis, as well as parameter-specific data summaries lead to highly accurate results. Using expected Stage IV experimental noise, we are able to recover the posterior distribution for the cosmological parameters with a speedup factor of $\sim 40-60$ compared to classical MCMC methods. To illustrate that the performance of MNRE is not impeded when posteriors are highly non-Gaussian, we test a scenario of two-body decaying dark matter, finding that Stage IV surveys can improve current bounds on the model by up to one order of magnitude. This result supports that MNRE is a powerful framework to constrain the standard cosmological model and its extensions with next-generation LSS surveys.","Thu, 21 Mar 2024 18:00:02 UTC (2,825 KB)"
"92","Foundation Models for Time Series Analysis: A Tutorial and Survey","Yuxuan Liang, Haomin Wen, Yuqi Nie, Yushan Jiang, Ming Jin, Dongjin Song, Shirui Pan, Qingsong Wen","Machine Learning (cs.LG)","Time series analysis stands as a focal point within the data mining community, serving as a cornerstone for extracting valuable insights crucial to a myriad of real-world applications. Recent advancements in Foundation Models (FMs) have fundamentally reshaped the paradigm of model design for time series analysis, boosting various downstream tasks in practice. These innovative approaches often leverage pre-trained or fine-tuned FMs to harness generalized knowledge tailored specifically for time series analysis. In this survey, we aim to furnish a comprehensive and up-to-date overview of FMs for time series analysis. While prior surveys have predominantly focused on either the application or the pipeline aspects of FMs in time series analysis, they have often lacked an in-depth understanding of the underlying mechanisms that elucidate why and how FMs benefit time series analysis. To address this gap, our survey adopts a model-centric classification, delineating various pivotal elements of time-series FMs, including model architectures, pre-training techniques, adaptation methods, and data modalities. Overall, this survey serves to consolidate the latest advancements in FMs pertinent to time series analysis, accentuating their theoretical underpinnings, recent strides in development, and avenues for future research exploration.","Thu, 21 Mar 2024 10:08:37 UTC (2,004 KB)"
"93","Individual and Product-Related Antecedents of Electronic Word-of-Mouth","Bogdan Anastasiei, Nicoleta Dospinescu, Octavian Dospinescu","Computers and Society (cs.CY)","This research investigates the antecedents of positive and negative electronic word-of-mouth (eWOM) propensity, as well as the impact of eWOM propensity on the intention to repurchase the product. Two types of eWOM predictors were considered: product related variables and personal factors. The data were collected through an online survey conducted on a sample of 335 Romanian subjects, and the analysis method was Structural Equation Modeling. Our findings show that personal factors - social media usage behavior, marketing mavenism and need to evaluate - are the most important antecedents of the intention to write product reviews and comments online, either positive or negative. From the product related factors, only brand trust influences the propensity to provide eWOM. Furthermore, both positive and negative eWOM intentions are associated with the repurchase intention.","Tue, 19 Mar 2024 07:50:26 UTC (592 KB)"
"94","Visualizing Progress in Broadening Participation in Computing: The Value of Context","Valerie Barr, Carla E. Brodley, Manuel A. Pérez-Quiñones","Computers and Society (cs.CY)","Concerns about representation in computing within the U.S. have driven numerous activities to broaden participation. Assessment of the impact of these efforts and, indeed, a clear assessment of the actual ""problem"" being addressed are limited by the nature of the most common data analysis which looks at the representation of each population as a percentage of the number of students graduating with a degree in computing. This use of a single metric cannot adequately assess the impact of broadening participation efforts. First, this approach fails to account for changing demographics of the undergraduate population in terms of overall numbers and relative proportion of the Federally designated gender, race, and ethnicity groupings. A second issue is that the majority of literature on broadening participation in computing (BPC) reports data on gender or on race/ethnicity, omitting data on students' intersectional identities. This leads to an incorrect understanding of both the data and the challenges we face as a field. In this paper we present several different approaches to tracking the impact of BPC efforts. We make three recommendations: 1) cohort-based analysis should be used to accurately show student engagement in computing; 2) the field as a whole needs to adopt the norm of always reporting intersectional data; 3) university demographic context matters when looking at how well a CS department is doing to broaden participation in computing, including longitudinal analysis of university demographic shifts that impact the local demographics of computing.","Mon, 18 Mar 2024 01:12:02 UTC (3,485 KB)"
"95","Synergy of Information in Multimodal IoT Systems -- Discovering the impact of daily behaviour routines on physical activity level","Mohsen Shirali, Zahra Ahmadi, Carlos Fernández-Llatas, Jose-Luis Bayo-Monton","Computers and Society (cs.CY)","The intricate connection between daily behaviours and health necessitates robust behaviour monitoring, particularly with the advent of IoT systems. This study introduces an innovative approach, exploiting the synergy of information from various IoT sources, to assess the alignment of behaviour routines with health guidelines. We grouped routines based on guideline compliance and used a clustering method to identify similarities in behaviours and key characteristics within each cluster. Applied to an elderly care case study, our approach unveils patterns leading to physical inactivity by categorising days based on recommended daily steps. Utilising data from wristbands, smartphones, and ambient sensors, the study provides insights not achievable with single-source data. Visualisation in a calendar view aids health experts in understanding patient behaviours, enabling precise interventions. Notably, the approach facilitates early detection of behaviour changes during events like COVID-19 and Ramadan, available in our dataset. This work signifies a promising path for behavioural analysis and discovering variations to empower smart healthcare, offering insights into patient health, personalised interventions, and healthier routines through continuous IoT-driven data analysis.","Sun, 17 Mar 2024 21:06:38 UTC (7,792 KB)"
"96","A2CI: A Cloud-based, Service-oriented Geospatial Cyberinfrastructure to Support Atmospheric Research","Wenwen Li, Hu Shao, Sizhe Wang, Xiran Zhou, Sheng Wu","Computers and Society (cs.CY)","Big earth science data offers the scientific community great opportunities. Many more studies at large-scales, over long-terms and at high resolution can now be conducted using the rich information collected by remote sensing satellites, ground-based sensor networks, and even social media input. However, the hundreds of terabytes of information collected and compiled on an hourly basis by NASA and other government agencies present a significant challenge for atmospheric scientists seeking to improve the understanding of the Earth atmospheric system. These challenges include effective discovery, organization, analysis and visualization of large amounts of data. This paper reports the outcomes of an NSF-funded project that developed a geospatial cyberinfrastructure -- the A2CI (Atmospheric Analysis Cyberinfrastructure) -- to support atmospheric research. We first introduce the service-oriented system framework then describe in detail the implementation of the data discovery module, data management module, data integration module, data analysis and visualization modules following the cloud computing principles-Data-as-a-Service, Software-as-a-Service, Platform-as-a-Service and Infrastructure-as-a-Service. We demonstrate the graphic user interface by performing an analysis between Sea Surface Temperature and the intensity of tropical storms in the North Atlantic and Pacific oceans. We expect this work to contribute to the technical advancement of cyberinfrastructure research as well as to the development of an online, collaborative scientific analysis system for atmospheric science.","Fri, 15 Mar 2024 08:28:38 UTC (2,731 KB)"
"97","Developing and Deploying Industry Standards for Artificial Intelligence in Education (AIED): Challenges, Strategies, and Future Directions","Richard Tong, Haoyang Li, Joleen Liang, Qingsong Wen","Computers and Society (cs.CY)","The adoption of Artificial Intelligence in Education (AIED) holds the promise of revolutionizing educational practices by offering personalized learning experiences, automating administrative and pedagogical tasks, and reducing the cost of content creation. However, the lack of standardized practices in the development and deployment of AIED solutions has led to fragmented ecosystems, which presents challenges in interoperability, scalability, and ethical governance. This article aims to address the critical need to develop and implement industry standards in AIED, offering a comprehensive analysis of the current landscape, challenges, and strategic approaches to overcome these obstacles. We begin by examining the various applications of AIED in various educational settings and identify key areas lacking in standardization, including system interoperability, ontology mapping, data integration, evaluation, and ethical governance. Then, we propose a multi-tiered framework for establishing robust industry standards for AIED. In addition, we discuss methodologies for the iterative development and deployment of standards, incorporating feedback loops from real-world applications to refine and adapt standards over time. The paper also highlights the role of emerging technologies and pedagogical theories in shaping future standards for AIED. Finally, we outline a strategic roadmap for stakeholders to implement these standards, fostering a cohesive and ethical AIED ecosystem. By establishing comprehensive industry standards, such as those by IEEE Artificial Intelligence Standards Committee (AISC) and International Organization for Standardization (ISO), we can accelerate and scale AIED solutions to improve educational outcomes, ensuring that technological advances align with the principles of inclusivity, fairness, and educational excellence.","Wed, 13 Mar 2024 22:38:08 UTC (2,156 KB)"
"98","Kernel Alignment for Unsupervised Feature Selection via Matrix Factorization","Ziyuan Lin, Deanna Needell","Machine Learning (cs.LG)","By removing irrelevant and redundant features, feature selection aims to find a good representation of the original features. With the prevalence of unlabeled data, unsupervised feature selection has been proven effective in alleviating the so-called curse of dimensionality. Most existing matrix factorization-based unsupervised feature selection methods are built upon subspace learning, but they have limitations in capturing nonlinear structural information among features. It is well-known that kernel techniques can capture nonlinear structural information. In this paper, we construct a model by integrating kernel functions and kernel alignment, which can be equivalently characterized as a matrix factorization problem. However, such an extension raises another issue: the algorithm performance heavily depends on the choice of kernel, which is often unknown a priori. Therefore, we further propose a multiple kernel-based learning method. By doing so, our model can learn both linear and nonlinear similarity information and automatically generate the most appropriate kernel. Experimental analysis on real-world data demonstrates that the two proposed methods outperform other classic and state-of-the-art unsupervised feature selection methods in terms of clustering results and redundancy reduction in almost all datasets tested.","Wed, 13 Mar 2024 20:35:44 UTC (836 KB)"
"99","Evaluating Pedagogical Incentives in Undergraduate Computing: A Mixed Methods Approach Using Learning Analytics","Laura J. Johnston, Takoua Jendoubi","Computers and Society (cs.CY)","In the context of higher education's evolving dynamics post-COVID-19, this paper assesses the impact of new pedagogical incentives implemented in a first-year undergraduate computing module at University College London. We employ a mixed methods approach, combining learning analytics with qualitative data, to evaluate the effectiveness of these incentives on increasing student engagement.
A longitudinal overview of resource interactions is mapped through Bayesian network analysis of Moodle activity logs from 204 students. This analysis identifies early resource engagement as a predictive indicator of continued engagement while also suggesting that the new incentives disproportionately benefit highly engaged students. Focus group discussions complement this analysis, providing insights into student perceptions of the pedagogical changes and the module design. These qualitative findings underscore the challenge of sustaining engagement through the new incentives and highlight the importance of communication in blended learning environments.
Our paper introduces an interpretable and actionable model for student engagement, which integrates objective, data-driven analysis with students' perspectives. This model provides educators with a tool to evaluate and improve instructional strategies. By demonstrating the effectiveness of our mixed methods approach in capturing the intricacies of student behaviour in digital learning environments, we underscore the model's potential to improve online pedagogical practices across diverse educational settings.","Wed, 13 Mar 2024 16:39:38 UTC (139 KB)"
"100","QubiCSV: An Open-Source Data Storage and Visualization Platform for Collaborative Qubit Control","Devanshu Brahmbhatt, Yilun Xu, Neel Vora, Larry Chen, Neelay Fruitwala, Gang Huang, Qing Ji, Phuc Nguyen","Quantum Physics (quant-ph)","Developing collaborative research platforms for quantum bit control is crucial for driving innovation in the field, as they enable the exchange of ideas, data, and implementation to achieve more impactful outcomes. Furthermore, considering the high costs associated with quantum experimental setups, collaborative environments are vital for maximizing resource utilization efficiently. However, the lack of dedicated data management platforms presents a significant obstacle to progress, highlighting the necessity for essential assistive tools tailored for this purpose. Current qubit control systems are unable to handle complicated management of extensive calibration data and do not support effectively visualizing intricate quantum experiment outcomes. In this paper, we introduce QubiCSV (Qubit Control Storage and Visualization), a platform specifically designed to meet the demands of quantum computing research, focusing on the storage and analysis of calibration and characterization data in qubit control systems. As an open-source tool, QubiCSV facilitates efficient data management of quantum computing, providing data versioning capabilities for data storage and allowing researchers and programmers to interact with qubits in real time. The insightful visualization are developed to interpret complex quantum experiments and optimize qubit performance. QubiCSV not only streamlines the handling of qubit control system data but also improves the user experience with intuitive visualization features, making it a valuable asset for researchers in the quantum computing domain.","Thu, 7 Mar 2024 00:49:42 UTC (19,150 KB)"
"101","Can the NANOGrav observations constrain the geometry of the universe?","Matteo Califano, Rocco D'Agostino, Daniele Vernieri","Cosmology and Nongalactic Astrophysics (astro-ph.CO)","The theory of inflation provides an elegant explanation for the nearly flat universe observed today, which represents one of the pillars of the standard cosmological model. However, recent studies have reported some deviations from a flat geometry, arguing that a closed universe would be instead favored by observations. Given its central role played in the cosmological context, this paper revisits the issue of spatial curvature in light of the stochastic gravitational wave background signal recently detected by the NANOGrav collaboration. For this purpose, we investigate the primordial gravitational waves generated during inflation and their propagation in the post-inflationary universe. We propose a new parametrization of the gravitational wave power spectrum, taking into account spatial curvature, the tensor-to-scalar ratio and the spectral index of tensor perturbations. Therefore, we compare the theoretical predictions with NANOGrav data to possibly constrain the geometry of the universe. We find that the choice of the priors has a significant effect on the computed posterior distributions. In particular, using flat uniform priors results in $\Omega_{\mathcal{K},0}= 0.00 \pm 0.67$ at the 68\% confidence level. On the other hand, imposing a Planck prior, we obtain $\Omega_{\mathcal{K},0}= -0.05 \pm 0.17$ at the 68\% confidence level. This result aligns with the analysis of the cosmic microwave background radiation, and no deviations from a flat universe are found.","Fri, 22 Mar 2024 17:52:27 UTC (1,475 KB)"
"102","Closing the Information Gap in Unidentified Anomalous Phenomena (UAP) Studies","Gretchen R. Stahlman","Digital Libraries (cs.DL)","Unidentified Anomalous Phenomena (UAP), also known as Unidentified Flying Objects (UFOs), has shifted from being a stigmatized topic on the fringes of scientific inquiry to a legitimate subject of scientific interest with a need for high quality, curated data, and rigorous scientific investigation. This paper presents a preliminary scoping review and analysis of scholarly literature related to UAP from 1967 until 2023, exploring a diverse range of research areas across disciplines to illustrate scholarly discourse about the topic. The paper focuses on characterizing papers published in recent years and notes that Library & Information Science is unrepresented in the current UAP literature. The paper also discusses how researchers across the iFields can contribute to UAP studies through inherent expertise such as data curation and data science as well as information behavior and information literacy, among others. The paper concludes by emphasizing that UAP Studies offer a rich intellectual realm for information science research, with the iFields well positioned to play a crucial role in supporting and engaging in the study of UAP.","Fri, 22 Mar 2024 17:40:04 UTC (385 KB)"
"103","Energy-dependent Boosted Dark Matter from Diffuse Supernova Neutrino Background","Anirban Das, Tim Herbermann, Manibrata Sen, Volodymyr Takhistov","High Energy Physics - Phenomenology (hep-ph)","Diffuse neutrinos from past supernovae in the Universe present us with a unique opportunity to test dark matter (DM) interactions. These neutrinos can scatter and boost the DM particles in the Milky Way halo to relativistic energies allowing us to detect them in terrestrial laboratories. Focusing on generic models of DM-neutrino and electron interactions, mediated by a vector or a scalar boson, we implement energy-dependent scattering cross-sections and perform detailed numerical analysis of DM attenuation due to electron scattering in-medium while propagating towards terrestrial experiments. We set new limits on DM-neutrino and electron interactions for DM with masses in the range $\sim (0.1, 10^4)~$MeV, using recent data from XENONnT, LUX-ZEPLIN, and PandaX-4T direct detection experiments. We demonstrate that consideration of energy-dependent cross-sections for DM interactions can significantly affect constraints previously derived under the assumption of constant cross-sections, modifying them by multiple orders of magnitude.","Fri, 22 Mar 2024 17:38:44 UTC (2,307 KB)"
"104","Learning Topological Representations for Deep Image Understanding","Xiaoling Hu","Computer Vision and Pattern Recognition (cs.CV)","In many scenarios, especially biomedical applications, the correct delineation of complex fine-scaled structures such as neurons, tissues, and vessels is critical for downstream analysis. Despite the strong predictive power of deep learning methods, they do not provide a satisfactory representation of these structures, thus creating significant barriers in scalable annotation and downstream analysis. In this dissertation, we tackle such challenges by proposing novel representations of these topological structures in a deep learning framework. We leverage the mathematical tools from topological data analysis, i.e., persistent homology and discrete Morse theory, to develop principled methods for better segmentation and uncertainty estimation, which will become powerful tools for scalable annotation.","Fri, 22 Mar 2024 17:23:37 UTC (31,299 KB)"
"105","Neural Plasticity-Inspired Foundation Model for Observing the Earth Crossing Modalities","Zhitong Xiong, Yi Wang, Fahong Zhang, Adam J. Stewart, Joëlle Hanna, Damian Borth, Ioannis Papoutsis, Bertrand Le Saux, Gustau Camps-Valls, Xiao Xiang Zhu","Computer Vision and Pattern Recognition (cs.CV)","The development of foundation models has revolutionized our ability to interpret the Earth's surface using satellite observational data. Traditional models have been siloed, tailored to specific sensors or data types like optical, radar, and hyperspectral, each with its own unique characteristics. This specialization hinders the potential for a holistic analysis that could benefit from the combined strengths of these diverse data sources. Our novel approach introduces the Dynamic One-For-All (DOFA) model, leveraging the concept of neural plasticity in brain science to integrate various data modalities into a single framework adaptively. This dynamic hypernetwork, adjusting to different wavelengths, enables a single versatile Transformer jointly trained on data from five sensors to excel across 12 distinct Earth observation tasks, including sensors never seen during pretraining. DOFA's innovative design offers a promising leap towards more accurate, efficient, and unified Earth observation analysis, showcasing remarkable adaptability and performance in harnessing the potential of multimodal Earth observation data.","Fri, 22 Mar 2024 17:11:47 UTC (35,969 KB)"
"106","Low-Regularity Solutions of the Nonlinear Schrödinger Equation on the Spatial Quarter-Plane","Dionyssios Mantzavinos, Türker Ozsarı","Analysis of PDEs (math.AP)","The Hadamard well-posedness of the nonlinear Schrödinger equation with power nonlinearity formulated on the spatial quarter-plane is established in a low-regularity setting with Sobolev initial data and Dirichlet boundary data in appropriate Bourgain-type spaces. As both of the spatial variables are restricted to the half-line, a different approach is needed than the one previously used for the well-posedness of other initial-boundary value problems. In particular, now the solution of the forced linear initial-boundary problem is estimated \textit{directly}, both in Sobolev spaces and in Strichartz-type spaces, i.e. without a linear decomposition that would require estimates for the associated homogeneous and nonhomogeneous initial value problems. In the process of deriving the linear estimates, the function spaces for the boundary data are identified as the intersections of certain modified Bourgain-type spaces that involve spatial half-line Fourier transforms instead of the usual whole-line Fourier transform found in the definition of the standard Bourgain space associated with the one-dimensional initial value problem. The fact that the quarter-plane has a corner at the origin poses an additional challenge, as it requires one to expand the validity of certain Sobolev extension results to the case of a domain with a non-smooth (Lipschitz) and non-compact boundary.","Fri, 22 Mar 2024 17:02:48 UTC (40 KB)"
"107","Global Analysis of LISA Data with Galactic Binaries and Massive Black Hole Binaries","Stefan H. Strub, Luigi Ferraioli, Cédric Schmelzbach, Simon C. Stähler, Domenico Giardini","General Relativity and Quantum Cosmology (gr-qc)","The Laser Interferometer Space Antenna (LISA) is a planned space-based observatory to measure gravitational waves in the millihertz frequency band. This frequency band is expected to be dominated by signals from millions of Galactic binaries and tens of merging massive black hole binaries. The LISA Data Challenge 2a is focused on the robust signal extraction from a blend of these two types of gravitational wave signals. Here, we introduce a novel high performance and cost-effective global fit pipeline extracting and characterizing galactic binary and massive black hole binary signals and estimate the noise of the residual. We preform the pipeline in a time-evolving weekly analysis starting with and observation time of 1 week until we reach a full year. As expected we detect more galactic binaries and massive black hole binaries bringing the noise estimate of the residual closer to the instrument noise by each week of additional observation time. Furthermore, we present a novel maximum likelihood estimate-based algorithm for extracting multiple massive black hole binaries. Additionally we demonstrate a massive black hole binary signal extraction with a more accurate LISA response, considering higher harmonic modes, in a noisy data set.","Fri, 22 Mar 2024 16:11:53 UTC (4,837 KB)"
"108","A data-driven approach to PDE-constrained optimization in inverse problems","Tristan van Leeuwen, Yunan Yang","Optimization and Control (math.OC)","Inverse problems are ubiquitous in science and engineering. Many of these are naturally formulated as a PDE-constrained optimization problem. These non-linear, large-scale, constrained optimization problems know many challenges, of which the inherent non-linearity of the problem is an important one. As an alternative to this physics-driven approach, data-driven methods have been proposed. These methods come with their own set of challenges, and it appears that, ideally, one would devise hybrid methods that combine the best of both worlds. In this paper, we propose one way of combining PDE-constrained optimization with recently proposed data-driven reduced-order models. Starting from an infinite-dimensional formulation of the inverse problem with discrete data, we propose a general framework for the analysis and discretisation of such problems. The proposed approach is based on a relaxed formulation of the PDE-constrained optimization problem, which reduces to a weighted non-linear least-squares problem. The weight matrix turns out to be the Gram matrix of solutions of the PDE, and it can be estimated directly from the measurements. We provide a number of representative case studies and numerical examples.","Fri, 22 Mar 2024 15:40:09 UTC (1,115 KB)"
"109","A data-informed mathematical model of microglial cell dynamics during ischemic stroke in the middle cerebral artery","Sara Amato, Andrea Arnold","Cell Behavior (q-bio.CB)","Neuroinflammation immediately follows the onset of ischemic stroke in the middle cerebral artery. During this process, microglial cells are activated in and recruited to the penumbra. Microglial cells can be activated into two different phenotypes: M1, which can worsen brain injury; or M2, which can aid in long-term recovery. In this study, we contribute a summary of experimental data on microglial cell counts in the penumbra following ischemic stroke induced by middle cerebral artery occlusion (MCAO) in mice and compile available data sets into a single set suitable for time series analysis. Further, we formulate a mathematical model of microglial cells in the penumbra during ischemic stroke due to MCAO. Through use of global sensitivity analysis and Markov Chain Monte Carlo (MCMC)-based parameter estimation, we analyze the effects of the model parameters on the number of M1 and M2 cells in the penumbra and fit identifiable parameters to the compiled experimental data set. We utilize results from MCMC parameter estimation to ascertain uncertainty bounds and forward predictions for the number of M1 and M2 microglial cells over time. Results demonstrate the significance of parameters related to M1 and M2 activation on the number of M1 and M2 microglial cells. Simulations further suggest that potential outliers in the observed data may be omitted and forecast predictions suggest a lingering inflammatory response.","Fri, 22 Mar 2024 15:31:07 UTC (288 KB)"
"110","Tests for almost stochastic dominance","Amparo Baíllo, Javier Cárcamo, Carlos Mora-Corral","Econometrics (econ.EM)","We introduce a 2-dimensional stochastic dominance (2DSD) index to characterize both strict and almost stochastic dominance. Based on this index, we derive an estimator for the minimum violation ratio (MVR), also known as the critical parameter, of the almost stochastic ordering condition between two variables. We determine the asymptotic properties of the empirical 2DSD index and MVR for the most frequently used stochastic orders. We also provide conditions under which the bootstrap estimators of these quantities are strongly consistent. As an application, we develop consistent bootstrap testing procedures for almost stochastic dominance. The performance of the tests is checked via simulations and the analysis of real data.","Fri, 22 Mar 2024 14:58:48 UTC (2,044 KB)"
"111","Self-Supervised Backbone Framework for Diverse Agricultural Vision Tasks","Sudhir Sornapudi (1), Rajhans Singh (1) ((1) Corteva Agriscience, Indianapolis, USA)","Computer Vision and Pattern Recognition (cs.CV)","Computer vision in agriculture is game-changing with its ability to transform farming into a data-driven, precise, and sustainable industry. Deep learning has empowered agriculture vision to analyze vast, complex visual data, but heavily rely on the availability of large annotated datasets. This remains a bottleneck as manual labeling is error-prone, time-consuming, and expensive. The lack of efficient labeling approaches inspired us to consider self-supervised learning as a paradigm shift, learning meaningful feature representations from raw agricultural image data. In this work, we explore how self-supervised representation learning unlocks the potential applicability to diverse agriculture vision tasks by eliminating the need for large-scale annotated datasets. We propose a lightweight framework utilizing SimCLR, a contrastive learning approach, to pre-train a ResNet-50 backbone on a large, unannotated dataset of real-world agriculture field images. Our experimental analysis and results indicate that the model learns robust features applicable to a broad range of downstream agriculture tasks discussed in the paper. Additionally, the reduced reliance on annotated data makes our approach more cost-effective and accessible, paving the way for broader adoption of computer vision in agriculture.","Fri, 22 Mar 2024 14:46:51 UTC (34,604 KB)"
"112","SFOD: Spiking Fusion Object Detector","Yimeng Fan, Wei Zhang, Changsong Liu, Mingyang Li, Wenrui Lu","Computer Vision and Pattern Recognition (cs.CV)","Event cameras, characterized by high temporal resolution, high dynamic range, low power consumption, and high pixel bandwidth, offer unique capabilities for object detection in specialized contexts. Despite these advantages, the inherent sparsity and asynchrony of event data pose challenges to existing object detection algorithms. Spiking Neural Networks (SNNs), inspired by the way the human brain codes and processes information, offer a potential solution to these difficulties. However, their performance in object detection using event cameras is limited in current implementations. In this paper, we propose the Spiking Fusion Object Detector (SFOD), a simple and efficient approach to SNN-based object detection. Specifically, we design a Spiking Fusion Module, achieving the first-time fusion of feature maps from different scales in SNNs applied to event cameras. Additionally, through integrating our analysis and experiments conducted during the pretraining of the backbone network on the NCAR dataset, we delve deeply into the impact of spiking decoding strategies and loss functions on model performance. Thereby, we establish state-of-the-art classification results based on SNNs, achieving 93.7\% accuracy on the NCAR dataset. Experimental results on the GEN1 detection dataset demonstrate that the SFOD achieves a state-of-the-art mAP of 32.1\%, outperforming existing SNN-based approaches. Our research not only underscores the potential of SNNs in object detection with event cameras but also propels the advancement of SNNs. Code is available at this https URL.","Fri, 22 Mar 2024 13:24:50 UTC (14,981 KB)"
"113","Double Cross-fit Doubly Robust Estimators: Beyond Series Regression","Alec McClean, Sivaraman Balakrishnan, Edward H. Kennedy, Larry Wasserman","Statistics Theory (math.ST)","Doubly robust estimators with cross-fitting have gained popularity in causal inference due to their favorable structure-agnostic error guarantees. However, when additional structure, such as Hölder smoothness, is available then more accurate ""double cross-fit doubly robust"" (DCDR) estimators can be constructed by splitting the training data and undersmoothing nuisance function estimators on independent samples. We study a DCDR estimator of the Expected Conditional Covariance, a functional of interest in causal inference and conditional independence testing, and derive a series of increasingly powerful results with progressively stronger assumptions. We first provide a structure-agnostic error analysis for the DCDR estimator with no assumptions on the nuisance functions or their estimators. Then, assuming the nuisance functions are Hölder smooth, but without assuming knowledge of the true smoothness level or the covariate density, we establish that DCDR estimators with several linear smoothers are semiparametric efficient under minimal conditions and achieve fast convergence rates in the non-$\sqrt{n}$ regime. When the covariate density and smoothnesses are known, we propose a minimax rate-optimal DCDR estimator based on undersmoothed kernel regression. Moreover, we show an undersmoothed DCDR estimator satisfies a slower-than-$\sqrt{n}$ central limit theorem, and that inference is possible even in the non-$\sqrt{n}$ regime. Finally, we support our theoretical results with simulations, providing intuition for double cross-fitting and undersmoothing, demonstrating where our estimator achieves semiparametric efficiency while the usual ""single cross-fit"" estimator fails, and illustrating asymptotic normality for the undersmoothed DCDR estimator.","Fri, 22 Mar 2024 12:59:03 UTC (1,902 KB)"
"114","AllHands: Ask Me Anything on Large-scale Verbatim Feedback via Large Language Models","Chaoyun Zhang, Zicheng Ma, Yuhao Wu, Shilin He, Si Qin, Minghua Ma, Xiaoting Qin, Yu Kang, Yuyi Liang, Xiaoyu Gou, Yajie Xue, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang","Software Engineering (cs.SE)","Verbatim feedback constitutes a valuable repository of user experiences, opinions, and requirements essential for software development. Effectively and efficiently extracting valuable insights from such data poses a challenging task. This paper introduces Allhands , an innovative analytic framework designed for large-scale feedback analysis through a natural language interface, leveraging large language models (LLMs). Allhands adheres to a conventional feedback analytic workflow, initially conducting classification and topic modeling on the feedback to convert them into a structurally augmented format, incorporating LLMs to enhance accuracy, robustness, generalization, and user-friendliness. Subsequently, an LLM agent is employed to interpret users' diverse questions in natural language on feedback, translating them into Python code for execution, and delivering comprehensive multi-modal responses, including text, code, tables, and images.
We evaluate Allhands across three diverse feedback datasets. The experiments demonstrate that Allhands achieves superior efficacy at all stages of analysis, including classification and topic modeling, eventually providing users with an ``ask me anything'' experience with comprehensive, correct and human-readable response. To the best of our knowledge, Allhands stands as the first comprehensive feedback analysis framework that supports diverse and customized requirements for insight extraction through a natural language interface.","Fri, 22 Mar 2024 12:13:16 UTC (817 KB)"
"115","An In-Depth Analysis of Data Reduction Methods for Sustainable Deep Learning","Víctor Toscano-Durán, Javier Perera-Lago, Eduardo Paluzo-Hidalgo, Rocío Gonzalez-Diaz, Miguel Ángel Gutierrez-Naranjo, Matteo Rucco","Machine Learning (cs.LG)","In recent years, Deep Learning has gained popularity for its ability to solve complex classification tasks, increasingly delivering better results thanks to the development of more accurate models, the availability of huge volumes of data and the improved computational capabilities of modern computers. However, these improvements in performance also bring efficiency problems, related to the storage of datasets and models, and to the waste of energy and time involved in both the training and inference processes. In this context, data reduction can help reduce energy consumption when training a deep learning model. In this paper, we present up to eight different methods to reduce the size of a tabular training dataset, and we develop a Python package to apply them. We also introduce a representativeness metric based on topology to measure how similar are the reduced datasets and the full training dataset. Additionally, we develop a methodology to apply these data reduction methods to image datasets for object detection tasks. Finally, we experimentally compare how these data reduction methods affect the representativeness of the reduced dataset, the energy consumption and the predictive performance of the model.","Fri, 22 Mar 2024 12:06:40 UTC (1,575 KB)"
"116","Text clustering with LLM embeddings","Alina Petukhova, Joao P. Matos-Carvalho, Nuno Fachada","Computation and Language (cs.CL)","Text clustering is an important approach for organising the growing amount of digital content, helping to structure and find hidden patterns in uncategorised data. In this research, we investigated how different textual embeddings - particularly those used in large language models (LLMs) - and clustering algorithms affect how text datasets are clustered. A series of experiments were conducted to assess how embeddings influence clustering results, the role played by dimensionality reduction through summarisation, and embedding size adjustment. Results reveal that LLM embeddings excel at capturing the nuances of structured language, while BERT leads the lightweight options in performance. In addition, we find that increasing embedding dimensionality and summarisation techniques do not uniformly improve clustering efficiency, suggesting that these strategies require careful analysis to use in real-life models. These results highlight a complex balance between the need for nuanced text representation and computational feasibility in text clustering applications. This study extends traditional text clustering frameworks by incorporating embeddings from LLMs, thereby paving the way for improved methodologies and opening new avenues for future research in various types of textual analysis.","Fri, 22 Mar 2024 11:08:48 UTC (83 KB)"
"117","CHisIEC: An Information Extraction Corpus for Ancient Chinese History","Xuemei Tang, Zekun Deng, Qi Su, Hao Yang, Jun Wang","Computation and Language (cs.CL)","Natural Language Processing (NLP) plays a pivotal role in the realm of Digital Humanities (DH) and serves as the cornerstone for advancing the structural analysis of historical and cultural heritage texts. This is particularly true for the domains of named entity recognition (NER) and relation extraction (RE). In our commitment to expediting ancient history and culture, we present the ``Chinese Historical Information Extraction Corpus''(CHisIEC). CHisIEC is a meticulously curated dataset designed to develop and evaluate NER and RE tasks, offering a resource to facilitate research in the field. Spanning a remarkable historical timeline encompassing data from 13 dynasties spanning over 1830 years, CHisIEC epitomizes the extensive temporal range and text heterogeneity inherent in Chinese historical documents. The dataset encompasses four distinct entity types and twelve relation types, resulting in a meticulously labeled dataset comprising 14,194 entities and 8,609 relations. To establish the robustness and versatility of our dataset, we have undertaken comprehensive experimentation involving models of various sizes and paradigms. Additionally, we have evaluated the capabilities of Large Language Models (LLMs) in the context of tasks related to ancient Chinese history. The dataset and code are available at \url{this https URL}.","Fri, 22 Mar 2024 10:12:10 UTC (1,313 KB)"
"118","GTAGCN: Generalized Topology Adaptive Graph Convolutional Networks","Sukhdeep Singh, Anuj Sharma, Vinod Kumar Chauhan","Machine Learning (cs.LG)","Graph Neural Networks (GNN) have emerged as a popular and standard approach for learning from graph-structured data. The literature on GNN highlights the potential of this evolving research area and its widespread adoption in real-life applications. However, most of the approaches are either new in concept or derived from specific techniques. Therefore, the potential of more than one approach in hybrid form has not been studied extensively, which can be well utilized for sequenced data or static data together. We derive a hybrid approach based on two established techniques as generalized aggregation networks and topology adaptive graph convolution networks that solve our purpose to apply on both types of sequenced and static nature of data, effectively. The proposed method applies to both node and graph classification. Our empirical analysis reveals that the results are at par with literature results and better for handwritten strokes as sequenced data, where graph structures have not been explored.","Fri, 22 Mar 2024 10:02:13 UTC (117 KB)"
"119","Comprehensive Lipidomic Automation Workflow using Large Language Models","Connor Beveridge, Sanjay Iyer, Caitlin E. Randolph, Matthew Muhoberac, Palak Manchanda, Amy C. Clingenpeel, Shane Tichy, Gaurav Chopra","Quantitative Methods (q-bio.QM)","Lipidomics generates large data that makes manual annotation and interpretation challenging. Lipid chemical and structural diversity with structural isomers further complicates annotation. Although, several commercial and open-source software for targeted lipid identification exists, it lacks automated method generation workflows and integration with statistical and bioinformatics tools. We have developed the Comprehensive Lipidomic Automated Workflow (CLAW) platform with integrated workflow for parsing, detailed statistical analysis and lipid annotations based on custom multiple reaction monitoring (MRM) precursor and product ion pair transitions. CLAW contains several modules including identification of carbon-carbon double bond position(s) in unsaturated lipids when combined with ozone electrospray ionization (OzESI)-MRM methodology. To demonstrate the utility of the automated workflow in CLAW, large-scale lipidomics data was collected with traditional and OzESI-MRM profiling on biological and non-biological samples. Specifically, a total of 1497 transitions organized into 10 MRM-based mass spectrometry methods were used to profile lipid droplets isolated from different brain regions of 18-24 month-old Alzheimer's disease mice and age-matched wild-type controls. Additionally, triacyclglycerols (TGs) profiles with carbon-carbon double bond specificity were generated from canola oil samples using OzESI-MRM profiling. We also developed an integrated language user interface with large language models using artificially intelligent (AI) agents that permits users to interact with the CLAW platform using a chatbot terminal to perform statistical and bioinformatic analyses. We envision CLAW pipeline to be used in high-throughput lipid structural identification tasks aiding users to generate automated lipidomics workflows ranging from data acquisition to AI agent-based bioinformatic analysis.","Fri, 22 Mar 2024 10:00:52 UTC (24,757 KB)"
"120","Construction of a Japanese Financial Benchmark for Large Language Models","Masanori Hirano","Computational Finance (q-fin.CP)","With the recent development of large language models (LLMs), models that focus on certain domains and languages have been discussed for their necessity. There is also a growing need for benchmarks to evaluate the performance of current LLMs in each domain. Therefore, in this study, we constructed a benchmark comprising multiple tasks specific to the Japanese and financial domains and performed benchmark measurements on some models. Consequently, we confirmed that GPT-4 is currently outstanding, and that the constructed benchmarks function effectively. According to our analysis, our benchmark can differentiate benchmark scores among models in all performance ranges by combining tasks with different difficulties.","Fri, 22 Mar 2024 09:40:27 UTC (154 KB)"
"121","A nonvariational form of the Neumann problem for Hölder continuous harmonic functions","M. Lanza de Cristoforis","Analysis of PDEs (math.AP)","We present a nonvariational setting for the Neumann problem for harmonic functions that are Hölder continuous and that may have infinite Dirichlet integral. Then we introduce a space of distributions on the boundary (a space of first order traces for Hölder continuous harmonic functions), we analyze the properties of the corresponding distributional single layer potential and we prove a representation theorem for harmonic Hölder continuous functions in terms of distributional single layer potentials. As an application, we solve the interior and exterior Neumann problem with distributional data in the space of first order traces that has been introduced.","Fri, 22 Mar 2024 09:29:09 UTC (38 KB)"
"122","Perturbations in PDE-constrained optimal control decay exponentially in space","Simone Göttlich, Manuel Schaller, Karl Worthmann","Optimization and Control (math.OC)","For linear-quadratic optimal control problems (OCPs) governed by elliptic and parabolic partial differential equations (PDEs), we investigate the impact of perturbations on optimal solutions. Local perturbations may occur, e.g., due to discretization of the optimality system or disturbed problem data. Whereas these perturbations may exhibit global effects in the uncontrolled case, we prove that the ramifications are exponentially damped in space under stabilizability- and detectability-like conditions. To this end, we prove a bound on the optimality condition's solution operator that is uniform in the domain size. Then, this uniformity is used in a scaling argument to show the exponential decay of perturbations in space. We numerically validate and illustrate our results by solving OCPs involving Helmholtz, Poisson, and advection-diffusion-reaction equations.","Fri, 22 Mar 2024 09:28:14 UTC (1,272 KB)"
"123","Estimation of multiple mean vectors in high dimension","Gilles Blanchard (LMO, DATASHAPE), Jean-Baptiste Fermanian (LMO), Hannah Marienwald (BIFOLD, TU)","Machine Learning (stat.ML)","We endeavour to estimate numerous multi-dimensional means of various probability distributions on a common space based on independent samples. Our approach involves forming estimators through convex combinations of empirical means derived from these samples. We introduce two strategies to find appropriate data-dependent convex combination weights: a first one employing a testing procedure to identify neighbouring means with low variance, which results in a closed-form plug-in formula for the weights, and a second one determining weights via minimization of an upper confidence bound on the quadratic risk.Through theoretical analysis, we evaluate the improvement in quadratic risk offered by our methods compared to the empirical means. Our analysis focuses on a dimensional asymptotics perspective, showing that our methods asymptotically approach an oracle (minimax) improvement as the effective dimension of the data increases.We demonstrate the efficacy of our methods in estimating multiple kernel mean embeddings through experiments on both simulated and real-world datasets.","Fri, 22 Mar 2024 08:42:41 UTC (1,755 KB)"
"124","Ellipsoidal embeddings of graphs","Michaël Fanuel, Antoine Aspeel, Michael T. Schaub, Jean-Charles Delvenne","Social and Information Networks (cs.SI)","Due to their flexibility to represent almost any kind of relational data, graph-based models have enjoyed a tremendous success over the past decades. While graphs are inherently only combinatorial objects, however, many prominent analysis tools are based on the algebraic representation of graphs via matrices such as the graph Laplacian, or on associated graph embeddings. Such embeddings associate to each node a set of coordinates in a vector space, a representation which can then be employed for learning tasks such as the classification or alignment of the nodes of the graph. As the geometric picture provided by embedding methods enables the use of a multitude of methods developed for vector space data, embeddings have thus gained interest both from a theoretical as well as a practical perspective. Inspired by trace-optimization problems, often encountered in the analysis of graph-based data, here we present a method to derive ellipsoidal embeddings of the nodes of a graph, in which each node is assigned a set of coordinates on the surface of a hyperellipsoid. Our method may be seen as an alternative to popular spectral embedding techniques, to which it shares certain similarities we discuss. To illustrate the utility of the embedding we conduct a case study in which analyse synthetic and real world networks with modular structure, and compare the results obtained with known methods in the literature.","Fri, 22 Mar 2024 08:11:56 UTC (3,665 KB)"
"125","Precise measurement of the $e^+e^-\to D_s^+D_s^-$ cross sections at center-of-mass energies from threshold to 4.95 GeV","BESIII Collaboration: M. Ablikim, M. N. Achasov, P. Adlarson, O. Afedulidis, X. C. Ai, R. Aliberti, A. Amoroso, Q. An, Y. Bai, O. Bakina, I. Balossino, Y. Ban, H.-R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, J. F. Chang, G. R. Che, G. Chelkov, C. Chen, C. H. Chen, Chao Chen, G. Chen, H. S. Chen, H. Y. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, Y. B. Chen, Y. Q. Chen, Z. J. Chen, Z. Y. Chen, S. K. Choi, G. Cibinetto, F. Cossio, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, C. Q. Deng, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, Y. Y. Duan, Z. H. Duan, P. Egorov, Y. H. Fan, J. Fang, J. Fang, S. S. Fang, W. X. Fang, Y. Fang, Y. Q. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, Y. T. Feng, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, X. B. Gao

<!--
function toggleAuthorList(whichLayer,toggleThis)
{
  var elem, vis, tempToggle;
  tempToggle=toggleThis;
  if( document.getElementById ) // standard
      elem = document.getElementById( whichLayer );
  else if( document.all ) // old msie versions
      elem = document.all[whichLayer];
  else if( document.layers ) // nn4
      elem = document.layers[whichLayer];
  vis = elem.style;
  // if the style.display value is blank we try to figure it out here
  if(vis.display==''&&elem.offsetWidth!=undefined&&elem.offsetHeight!=undefined)
    vis.display = (elem.offsetWidth!=0&&elem.offsetHeight!=0)?'inline':'none';
  vis.display = (vis.display==''||vis.display=='inline')?'none':'inline';

  // toggle link inner text
  status = vis.display;
  if(status=='none'){
      document.getElementById('toggle').innerHTML = tempToggle ;
      document.getElementById('toggle').title = ""Show Entire Author List"";
  }
  else if(status=='inline'){
      document.getElementById('toggle').innerHTML = ""(collapse list)"";
      document.getElementById('toggle').title = ""Collapse Author List"";
  }
}
//-->

        , Y. N. Gao, Yang Gao, S. Garbolino, I. Garzia, L. Ge, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A. Gilman, K. Goetzen, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, F. Hanisch, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, T. Holtmann, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, B. Y. Hu, H. M. Hu, J. F. Hu, S. L. Hu, T. Hu, Y. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, X. T. Huang, Y. P. Huang, Y. S. Huang, T. Hussain, F. Hölzken, N. Hüsken, N. in der Wiesche, J. Jackson, S. Janchiv, J. H. Jeong, Q. Ji, Q. P. Ji, W. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, X. Q. Jia, Z. K. Jia, D. Jiang, H. B. Jiang, P. C. Jiang, S. S. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, J. K. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, X. Kui, N. Kumar, A. Kupsc, W. Kühn, J. J. Lane, P. Larin, L. Lavezzi, T. T. Lei, Z. H. Lei, M. Lellmann, T. Lenz, C. Li, C. Li, C. H. Li, Cheng Li, D. M. Li, F. Li, G. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, K. Li, L. J. Li, L. K. Li, Lei Li, M. H. Li, P. R. Li, Q. M. Li, Q. X. Li, R. Li, S. X. Li, T. Li, W. D. Li, W. G. Li, X. Li, X. H. Li, X. L. Li, X. Y. Li, X. Z. Li, Y. G. Li, Z. J. Li, Z. Y. Li, C. Liang, H. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, L. Z. Liao, Y. P. Liao, J. Libby, A. Limphirat, C. C. Lin, D. X. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. Liu, F. H. Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. H. Liu, H. M. Liu, Huihui Liu, J. B. Liu, J. Y. Liu, K. Liu, K. Y. Liu, Ke Liu, L. Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, X. Liu, X. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. D. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, X. L. Lu, Y. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, J. R. Luo, M. X. Luo, T. Luo, X. L. Luo, X. R. Lyu, Y. F. Lyu, F. C. Ma, H. Ma, H. L. Ma, J. L. Ma, L. L. Ma, M. M. Ma, Q. M. Ma, R. Q. Ma, T. Ma, X. T. Ma, X. Y. Ma, Y. Ma, Y. M. Ma, F. E. Maas, M. Maggiora, S. Malde, Y. J. Mao, Z. P. Mao, S. Marcello, Z. X. Meng, J. G. Messchendorp, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, L. S. Nie, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, Y. Niu, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, P. Patteri, Y. P. Pei, M. Pelizaeus, H. P. Peng, Y. Y. Peng, K. Peters, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. Qi, H. R. Qi, M. Qi, T. Y. Qi, S. Qian, W. B. Qian, C. F. Qiao, X. K. Qiao, J. J. Qin, L. Q. Qin, L. Y. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, Z. H. Qu, C. F. Redmer, K. J. Ren, A. Rivetti, M. Rolo, G. Rong, Ch. Rosner, S. N. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, Z. J. Shang, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. Shi, H. C. Shi, J. L. Shi, J. Y. Shi, Q. Q. Shi, S. Y. Shi, X. Shi, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, Y. X. Song, S. Sosio, S. Spataro, F. Stieler, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, W. Y. Sun, Y. Sun, Y. J. Sun, Y. Z. Sun, Z. Q. Sun, Z. T. Sun, C. J. Tang, G. Y. Tang, J. Tang, M. Tang, Y. A. Tang, L. Y. Tao, Q. T. Tao, M. Tat, J. X. Teng, V. Thoren, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, Y. Wan, S. J. Wang, B. Wang, B. L. Wang, Bo Wang, D. Y. Wang, F. Wang, H. J. Wang, J. J. Wang, J. P. Wang, K. Wang, L. L. Wang, M. Wang, N. Y. Wang, S. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, X. N. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Z. Wang, Z. L. Wang, Z. Y. Wang, Ziyi Wang, D. H. Wei, F. Weidner, S. P. Wen, Y. R. Wen, U. Wiedner, G. Wilkinson, M. Wolke, L. Wollenberg, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, X. Wu, X. H. Wu, Y. Wu, Y. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, B. H. Xiang, T. Xiang, D. Xiao, G. Y. Xiao, S. Y. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, H. Y. Xu, M. Xu, Q. J. Xu, Q. N. Xu, W. Xu, W. L. Xu, X. P. Xu, Y. C. Xu, Z. P. Xu, Z. S. Xu, F. Yan, L. Yan, W. B. Yan, W. C. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, T. Yang, Y. Yang, Y. F. Yang, Y. F. Yang, Y. X. Yang, Z. W. Yang, Z. P. Yao, M. Ye, M. H. Ye, J. H. Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, T. Yu, X. D. Yu, Y. C. Yu, C. Z. Yuan, J. Yuan, J. Yuan, L. Yuan, S. C. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, A. A. Zafar, F. R. Zeng, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, Y. J. Zeng, X. Y. Zhai, Y. C. Zhai, Y. H. Zhan, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, H. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. H. Zhang, H. Q. Zhang, H. R. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. S. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, Lei Zhang, P. Zhang, Q. Y. Zhang, R. Y. Zhang, S. H. Zhang, Shulei Zhang, X. D. Zhang, X. M. Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Y. M. Zhang, Yan Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. Y. Zhang, Z. Y. Zhang, Z. Z. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, L. Zhao, Lei Zhao, M. G. Zhao, N. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, B. M. Zheng, J. P. Zheng, W. J. Zheng, Y. H. Zheng, B. Zhong, X. Zhong, H. Zhou, J. Y. Zhou, L. P. Zhou, S. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. Z. Zhou, J. Zhu, K. Zhu, K. J. Zhu, K. S. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, S. Q. Zhu, T. J. Zhu, W. D. Zhu, Y. C. Zhu, Z. A. Zhu, J. H. Zou, J. Zu
  
  
    et al. (563 additional authors not shown)
   You must enable JavaScript to view entire author list.","High Energy Physics - Experiment (hep-ex)","Using the $e^+e^-$ collision data collected with the BESIII detector operating at the BEPCII collider, at center-of-mass energies from the threshold to $4.95$~GeV, we present precise measurements of the cross sections for the process $e^+e^-\to D_s^+D_s^-$ using a single tag method. The resulting cross section lineshape exhibits several new structures, thereby offering an input for coupled channel analysis and model tests, which are critical to understand vector charmonium-like states with masses between 4 and 5~GeV.","Fri, 22 Mar 2024 07:20:20 UTC (155 KB)"
"126","Risk and Response in Large Language Models: Evaluating Key Threat Categories","Bahareh Harandizadeh, Abel Salinas, Fred Morstatter","Computation and Language (cs.CL)","This paper explores the pressing issue of risk assessment in Large Language Models (LLMs) as they become increasingly prevalent in various applications. Focusing on how reward models, which are designed to fine-tune pretrained LLMs to align with human values, perceive and categorize different types of risks, we delve into the challenges posed by the subjective nature of preference-based training data. By utilizing the Anthropic Red-team dataset, we analyze major risk categories, including Information Hazards, Malicious Uses, and Discrimination/Hateful content. Our findings indicate that LLMs tend to consider Information Hazards less harmful, a finding confirmed by a specially developed regression model. Additionally, our analysis shows that LLMs respond less stringently to Information Hazards compared to other risks. The study further reveals a significant vulnerability of LLMs to jailbreaking attacks in Information Hazard scenarios, highlighting a critical security concern in LLM risk assessment and emphasizing the need for improved AI safety measures.","Fri, 22 Mar 2024 06:46:40 UTC (10,014 KB)"
"127","Two-scale Analysis for Multiscale Landau-Lifshitz-Gilbert Equation: Theory and Numerical Methods","Xiaofei Guan, Hang Qi, Zhiwei Sun","Numerical Analysis (math.NA)","This paper discusses the theory and numerical method of two-scale analysis for the multiscale Landau-Lifshitz-Gilbert equation in composite ferromagnetic materials. The novelty of this work can be summarized in three aspects: Firstly, the more realistic and complex model is considered, including the effects of the exchange field, anisotropy field, stray field, and external magnetic field. The explicit convergence orders in the $H^1$ norm between the classical solution and the two-scale solution are obtained. Secondly, we propose a robust numerical framework, which is employed in several comprehensive experiments to validate the convergence results for the Periodic and Neumann problems. Thirdly, we design an improved implicit numerical scheme to reduce the required number of iterations and relaxes the constraints on the time step size, which can significantly improve computational efficiency. Specifically, the projection and the expansion methods are given to overcome the inherent non-consistency in the initial data between the multiscale problem and homogenized problem.","Fri, 22 Mar 2024 05:21:57 UTC (3,746 KB)"
"128","Creating a Spatial Vulnerability Index for Environmental Health","Aiden Price, Kerrie Mengersen, Michael Rigby, Paula Fiévez","Methodology (stat.ME)","Extreme natural hazards are increasing in frequency and intensity. These natural changes in our environment, combined with man-made pollution, have substantial economic, social and health impacts globally. The impact of the environment on human health (environmental health) is becoming well understood in international research literature. However, there are significant barriers to understanding key characteristics of this impact, related to substantial data volumes, data access rights and the time required to compile and compare data over regions and time. This study aims to reduce these barriers in Australia by creating an open data repository of national environmental health data and presenting a methodology for the production of health outcome-weighted population vulnerability indices related to extreme heat, extreme cold and air pollution at various temporal and geographical resolutions.
Current state-of-the-art methods for the calculation of vulnerability indices include equal weight percentile ranking and the use of principal component analysis (PCA). The weighted vulnerability index methodology proposed in this study offers an advantage over others in the literature by considering health outcomes in the calculation process. The resulting vulnerability percentiles more clearly align population sensitivity and adaptive capacity with health risks. The temporal and spatial resolutions of the indices enable national monitoring on a scale never before seen across Australia. Additionally, we show that a weekly temporal resolution can be used to identify spikes in vulnerability due to changes in relative national environmental exposure.","Fri, 22 Mar 2024 05:13:27 UTC (12,883 KB)"
"129","Addressing Concept Shift in Online Time Series Forecasting: Detect-then-Adapt","YiFan Zhang, Weiqi Chen, Zhaoyang Zhu, Dalin Qin, Liang Sun, Xue Wang, Qingsong Wen, Zhang Zhang, Liang Wang, Rong Jin","Machine Learning (cs.LG)","Online updating of time series forecasting models aims to tackle the challenge of concept drifting by adjusting forecasting models based on streaming data. While numerous algorithms have been developed, most of them focus on model design and updating. In practice, many of these methods struggle with continuous performance regression in the face of accumulated concept drifts over time. To address this limitation, we present a novel approach, Concept \textbf{D}rift \textbf{D}etection an\textbf{D} \textbf{A}daptation (D3A), that first detects drifting conception and then aggressively adapts the current model to the drifted concepts after the detection for rapid adaption. To best harness the utility of historical data for model adaptation, we propose a data augmentation strategy introducing Gaussian noise into existing training instances. It helps mitigate the data distribution gap, a critical factor contributing to train-test performance inconsistency. The significance of our data augmentation process is verified by our theoretical analysis. Our empirical studies across six datasets demonstrate the effectiveness of D3A in improving model adaptation capability. Notably, compared to a simple Temporal Convolutional Network (TCN) baseline, D3A reduces the average Mean Squared Error (MSE) by $43.9\%$. For the state-of-the-art (SOTA) model, the MSE is reduced by $33.3\%$.","Fri, 22 Mar 2024 04:44:43 UTC (5,404 KB)"
"130","Contrastive Learning on Multimodal Analysis of Electronic Health Records","Tianxi Cai, Feiqing Huang, Ryumei Nakada, Linjun Zhang, Doudou Zhou","Machine Learning (stat.ML)","Electronic health record (EHR) systems contain a wealth of multimodal clinical data including structured data like clinical codes and unstructured data such as clinical notes. However, many existing EHR-focused studies has traditionally either concentrated on an individual modality or merged different modalities in a rather rudimentary fashion. This approach often results in the perception of structured and unstructured data as separate entities, neglecting the inherent synergy between them. Specifically, the two important modalities contain clinically relevant, inextricably linked and complementary health information. A more complete picture of a patient's medical history is captured by the joint analysis of the two modalities of data. Despite the great success of multimodal contrastive learning on vision-language, its potential remains under-explored in the realm of multimodal EHR, particularly in terms of its theoretical understanding. To accommodate the statistical analysis of multimodal EHR data, in this paper, we propose a novel multimodal feature embedding generative model and design a multimodal contrastive loss to obtain the multimodal EHR feature representation. Our theoretical analysis demonstrates the effectiveness of multimodal learning compared to single-modality learning and connects the solution of the loss function to the singular value decomposition of a pointwise mutual information matrix. This connection paves the way for a privacy-preserving algorithm tailored for multimodal EHR feature representation learning. Simulation studies show that the proposed algorithm performs well under a variety of configurations. We further validate the clinical utility of the proposed algorithm in real-world EHR data.","Fri, 22 Mar 2024 03:01:42 UTC (5,781 KB)"
"131","Computational Approaches for Exponential-Family Factor Analysis","Liang Wang, Luis Carvalho","Methodology (stat.ME)","We study a general factor analysis framework where the $n$-by-$p$ data matrix is assumed to follow a general exponential family distribution entry-wise. While this model framework has been proposed before, we here further relax its distributional assumption by using a quasi-likelihood setup. By parameterizing the mean-variance relationship on data entries, we additionally introduce a dispersion parameter and entry-wise weights to model large variations and missing values. The resulting model is thus not only robust to distribution misspecification but also more flexible and able to capture non-Gaussian covariance structures of the data matrix. Our main focus is on efficient computational approaches to perform the factor analysis. Previous modeling frameworks rely on simulated maximum likelihood (SML) to find the factorization solution, but this method was shown to lead to asymptotic bias when the simulated sample size grows slower than the square root of the sample size $n$, eliminating its practical application for data matrices with large $n$. Borrowing from expectation-maximization (EM) and stochastic gradient descent (SGD), we investigate three estimation procedures based on iterative factorization updates. Our proposed solution does not show asymptotic biases, and scales even better for large matrix factorizations with error $O(1/p)$. To support our findings, we conduct simulation experiments and discuss its application in three case studies.","Fri, 22 Mar 2024 02:58:14 UTC (4,090 KB)"
"132","Analysis of Log Data from an International Online Educational Assessment System: A Multi-state Survival Modeling Approach to Reaction Time between and across Action Sequence","Jina Park, Ick Hoon Jin, Minjeong Jeon","Applications (stat.AP)","With increasingly available computer-based or online assessments, researchers have shown keen interest in analyzing log data to improve our understanding of test takers' problem-solving processes. In this paper, we propose a multi-state survival model (MSM) to action sequence data from log files, focusing on modeling test takers' reaction times between actions, in order to investigate which factors and how they influence test takers' transition speed between actions. In particular, we focus on the effects of the occurrence and timing of key actions that differentiate correct answers from incorrect answers. We demonstrate our proposed approach with problem-solving test items from the the Programme for International Assessment of Adult Competence (PIAAC) problem-solving test items.","Fri, 22 Mar 2024 02:02:19 UTC (9,935 KB)"
"133","Unraveling Contagion Origins: Optimal Estimation through Maximum-Likelihood and Starlike Tree Approximation in Markovian Spreading Models","Pei-Duo Yu, Chee Wei Tan, Liang Zheng, Chao Zhao","Social and Information Networks (cs.SI)","Identifying the source of epidemic-like spread in networks is crucial for tasks like removing internet viruses or finding the rumor source in online social networks. The challenge lies in tracing the source from a snapshot observation of infected nodes. How do we accurately pinpoint the source? Utilizing snapshot data, we apply a probabilistic approach, focusing on the graph boundary and the observed time, to detect sources via an effective maximum likelihood algorithm. A novel starlike tree approximation extends applicability to general graphs, demonstrating versatility. We highlight the utility of the Gamma function for analyzing the asymptotic behavior of the likelihood ratio between nodes. Comprehensive evaluations confirm algorithmic effectiveness in diverse network scenarios, advancing rumor source detection in large-scale network analysis and information dissemination strategies.","Fri, 22 Mar 2024 00:19:29 UTC (12,842 KB)"
"134","Description of CuInP$_{2}$S$_{6}$ ferrielectrics in a mixed Ising model","R. Yevych, V. Liubachko, V. Hryts, M. Medulych, A. Kohutych, Yu. Vysochanskii","Soft Condensed Matter (cond-mat.soft)","The appearance of spontaneous polarization in CuInP$_{2}$S$_{6}$ ferrielectrics is related to the second order Jahn-Teller effect for copper cations located in a double-well local potential, the stereoactivity of indium cations located in a three-well local potential, as well as the valence fluctuations of phosphorus cations. The paraelectric to ferrielectric phase transition is primarily determined by the coupling of indium cations with their surroundings. This transition can be analyzed using the mixed Ising model with spins $s = 1/2$ and $S = 1$. The spectrum of pseudospin fluctuations at different temperatures was calculated using a mean-field approach for a set of quantum anharmonic oscillators. The results were then compared with Raman spectroscopy data for CuInP$_{2}$S$_{6}$ crystal. The analysis indicates that the lattice anharmonicity below 150 K, is mainly determined by the indium sublattice, leading to the coexistence of the glassy state and ferrielectric phase. Above 150 K, the anharmonicity of the copper sublattice activates the ionic conductivity and results in the existence of a long-ranged fluctuated cluster of spontaneous polarization in a temperature interval of the paraelectric phase above $T_{C}$.","Thu, 21 Mar 2024 22:04:04 UTC (5,100 KB)"
"135","Revisiting the wetting behavior of solid surfaces by water-like models within a density functional theory","A. Kozina, M. Aguilar, O. Pizio, S. Sokołowski","Soft Condensed Matter (cond-mat.soft)","We perform the analysis of predictions of a classical density functional theory for associating fluids with different association strength concerned with wetting of solid surfaces. The four associating sites water-like models with non-associative square-well attraction parametrized by Clark et al. [Mol. Phys., 2006, 104, 3561] are considered. The fluid-solid potential is assumed to have a 10-4-3 functional form. The growth of water film on the substrate upon changing the chemical potential is described. The wetting and prewetting critical temperatures, as well as the prewetting phase diagram are evaluated for different fluid-solid attraction strength from the analysis of the adsorption isotherms. Moreover, the temperature dependence of the contact angle is obtained from the Young equation. It yields estimates for the wetting temperature as well. Theoretical findings are compared with experimental results and in a few cases with data from computer simulations. The theory is successful and quite accurate in describing the wetting temperature and contact angle changes with temperature for different values of fluid-substrate attraction. Moreover, the method provides an easy tool to study other associating fluids on solids of importance for chemical engineering, in comparison with laboratory experiments and computer simulations.","Thu, 21 Mar 2024 20:40:40 UTC (278 KB)"
"136","Non-holomorphic modular forms from zeta generators","Daniele Dorigoni, Mehregan Doroudiani, Joshua Drewitt, Martijn Hidding, Axel Kleinschmidt, Oliver Schlotterer, Leila Schneps, Bram Verbeek","High Energy Physics - Theory (hep-th)","We study non-holomorphic modular forms built from iterated integrals of holomorphic modular forms for SL$(2,\mathbb Z)$ known as equivariant iterated Eisenstein integrals. A special subclass of them furnishes an equivalent description of the modular graph forms appearing in the low-energy expansion of string amplitudes at genus one. Notably the Fourier expansion of modular graph forms contains single-valued multiple zeta values. We deduce the appearance of products and higher-depth instances of multiple zeta values in equivariant iterated Eisenstein integrals, and ultimately modular graph forms, from the appearance of simpler odd Riemann zeta values. This analysis relies on so-called zeta generators which act on certain non-commutative variables in the generating series of the iterated integrals. From an extension of these non-commutative variables we incorporate iterated integrals involving holomorphic cusp forms into our setup and use them to construct the modular completion of triple Eisenstein integrals. Our work represents a fully explicit realisation of the modular graph forms within Brown's framework of equivariant iterated Eisenstein integrals and reveals structural analogies between single-valued period functions appearing in genus zero and one string amplitudes.","Thu, 21 Mar 2024 20:12:04 UTC (5,750 KB)"
"137","Normalizing Flows for Domain Adaptation when Identifying $Λ$ Hyperon Events","Rowan Kelleher, Anselm Vossen","Data Analysis, Statistics and Probability (physics.data-an)","This study focuses on the novel application of a normalizing flow as a method of domain adaptation. Normalizing flows offer a way to transform data points between two different distributions. The present study investigates a method of transforming latent representations of physics data to a normal distribution and then to a physics distribution again. The final distribution models a simulated distribution. Following the transformation process, the data can be classified by a neural network trained on labeled simulation data. The present study succeeds in training two normalizing flows that can transform between data (or simulation) and a Gaussian distribution.","Thu, 21 Mar 2024 19:32:31 UTC (682 KB)"
"138","Identifying Attention-Deficit/Hyperactivity Disorder through the electroencephalogram complexity","Dimitri Marques Abramov, Henrique Santos Lima, Vladimir Lazarev, Paulo Ricardo Galhanone, Constantino Tsallis","Neurons and Cognition (q-bio.NC)","There are reasons to suggest that a number of mental disorders may be related to alteration in the neural complexity (NC). Thus, quantitative analysis of NC could be helpful in classifying mental conditions and clarifying our understanding about them. Here, we have worked with youths, typical and with attention-deficit/hyperactivity disorder (ADHD), whose neural complexity was assessed using q-statistics applied to the electroencephalogram (EEG). The EEG was recorded while subjects performed the visual Attention Network Test (ANT) based on the OddBall paradigm and during a shortpretask period of resting state. Time intervals of the EEG amplitudes that passed a threshold (signal regularity indicator) were collected from task and pretask signals from each subject. The data were satisfactorily fitted with a stretched $q$-exponential including a power-law prefactor(characterized by the exponent c), thus determining the best $(c, q)$ for each subject, indicative of their individual complexity. We found larger values of $q$ and $c$ in ADHD subjects as compared with the typical subjects both at task and pretask periods, the task values for both groups being larger than at rest. The $c$ parameter was highly specific in relation to DSM diagnosis for inattention, where well-defined clusters were observed. The parameter values were organized in four well-defined clusters in $(c, q)$-space. As expected, the tasks apparently induced greater complexity in neural functional states with likely greater amount of internal information processing. The results suggest that complexity is higher in ADHD subjects than in typical pairs. The distribution of values in the $(c, q)$-space derived from $q$-statistics seems to be a promising biomarker for ADHD diagnosis.","Thu, 21 Mar 2024 19:26:52 UTC (516 KB)"
"139","Background information: a study on the sensitivity of astrophysical gravitational-wave background searches","Arianna I. Renzini, Thomas A. Callister, Katerina Chatziioannou, Will M. Farr","High Energy Astrophysical Phenomena (astro-ph.HE)","The vast majority of gravitational-wave signals from stellar-mass compact binary mergers are too weak to be individually detected with present-day instruments and instead contribute to a faint, persistent background. This astrophysical background is targeted by searches that model the gravitational-wave ensemble collectively with a small set of parameters. The traditional search models the background as a stochastic field and estimates its amplitude by cross-correlating data from multiple interferometers. A different search uses gravitational-wave templates to marginalize over all individual event parameters and measure the duty cycle and population properties of binary mergers. Both searches ultimately estimate the total merger rate of compact binaries and are expected to yield a detection in the coming years. Given the conceptual and methodological differences between them, though, it is not well understood how their results should be mutually interpreted. In this paper, we use the Fisher information to study the implications of a background detection in terms of which region of the Universe each approach probes. Specifically, we quantify how information about the compact binary merger rate is accumulated by each search as a function of the event redshift. For the LIGO Design sensitivity and a uniform-in-comoving-volume distribution of equal-mass 30M_sol binaries, the traditional cross-correlation search obtains 99% of its information from binaries up to redshift 2.5 (average signal-to-noise-ratio <8), and the template-based search from binaries up to redshift 1.0 (average signal-to-noise-ratio ~8). While we do not calculate the total information accumulated by each search, our analysis emphasizes the need to pair any claimed detection of the stochastic background with an assessment of which binaries contribute to said detection.","Thu, 21 Mar 2024 19:14:10 UTC (847 KB)"
"140","The central black hole in the dwarf spheroidal galaxy Leo I Not supermassive, at most an intermediate-mass candidate","R. Pascale, C. Nipoti, F. Calura, A. Della Croce","Astrophysics of Galaxies (astro-ph.GA)","It has been recently claimed that a surprisingly massive black hole (BH) is present in the core of the dwarf spheroidal galaxy (dSph) Leo I. Based on integral field spectroscopy, this finding challenges the typical expectation of dSphs hosting BHs of intermediate-mass, since such a BH would better be classified as supermassive. Indeed, the analysis points toward Leo I harboring a BH with a lower mass limit exceeding a few $10^6M_\odot$ at $1\sigma$, and the no BH case excluded at 95\% significance. Such a value, comparable to the entire stellar mass of the galaxy, makes Leo I a unique system that warrants further investigations. Using equilibrium models based on distribution functions (DFs) depending on actions $f({\boldsymbol J})$ coupled with the same integral field spectroscopy data and an extensive exploration of a very large parameter space, we demonstrate, within a comprehensive Bayesian framework of model-data comparison, that the posterior on the BH mass is flat towards the low-mass end and, thus, that the kinematics of the central galaxy region only imposes an upper limit on the BH mass of few $10^5M_\odot$ (at $3\sigma$). Such an upper limit brings back the putative BH of Leo I under the category of intermediate-mass BHs, and it is also in line with formation scenarios and expectations from scaling relations at the mass regime of dwarf galaxies.","Thu, 21 Mar 2024 19:00:02 UTC (6,909 KB)"
"141","Fast likelihood-free inference in the LSS Stage IV era","Guillermo Franco Abellán, Guadalupe Cañas Herrera, Matteo Martinelli, Oleg Savchenko, Davide Sciotti, Christoph Weniger","Cosmology and Nongalactic Astrophysics (astro-ph.CO)","Forthcoming large-scale structure (LSS) Stage IV surveys will provide us with unprecedented data to probe the nature of dark matter and dark energy. However, analysing these data with conventional Markov Chain Monte Carlo (MCMC) methods will be challenging, due to the increase in the number of nuisance parameters and the presence of intractable likelihoods. In light of this, we present the first application of Marginal Neural Ratio Estimation (MNRE) (a recent approach in simulation-based inference) to LSS photometric probes: weak lensing, galaxy clustering and the cross-correlation power spectra. In order to analyse the hundreds of spectra simultaneously, we find that a pre-compression of data using principal component analysis, as well as parameter-specific data summaries lead to highly accurate results. Using expected Stage IV experimental noise, we are able to recover the posterior distribution for the cosmological parameters with a speedup factor of $\sim 40-60$ compared to classical MCMC methods. To illustrate that the performance of MNRE is not impeded when posteriors are highly non-Gaussian, we test a scenario of two-body decaying dark matter, finding that Stage IV surveys can improve current bounds on the model by up to one order of magnitude. This result supports that MNRE is a powerful framework to constrain the standard cosmological model and its extensions with next-generation LSS surveys.","Thu, 21 Mar 2024 18:00:02 UTC (2,825 KB)"
"142","Foundation Models for Time Series Analysis: A Tutorial and Survey","Yuxuan Liang, Haomin Wen, Yuqi Nie, Yushan Jiang, Ming Jin, Dongjin Song, Shirui Pan, Qingsong Wen","Machine Learning (cs.LG)","Time series analysis stands as a focal point within the data mining community, serving as a cornerstone for extracting valuable insights crucial to a myriad of real-world applications. Recent advancements in Foundation Models (FMs) have fundamentally reshaped the paradigm of model design for time series analysis, boosting various downstream tasks in practice. These innovative approaches often leverage pre-trained or fine-tuned FMs to harness generalized knowledge tailored specifically for time series analysis. In this survey, we aim to furnish a comprehensive and up-to-date overview of FMs for time series analysis. While prior surveys have predominantly focused on either the application or the pipeline aspects of FMs in time series analysis, they have often lacked an in-depth understanding of the underlying mechanisms that elucidate why and how FMs benefit time series analysis. To address this gap, our survey adopts a model-centric classification, delineating various pivotal elements of time-series FMs, including model architectures, pre-training techniques, adaptation methods, and data modalities. Overall, this survey serves to consolidate the latest advancements in FMs pertinent to time series analysis, accentuating their theoretical underpinnings, recent strides in development, and avenues for future research exploration.","Thu, 21 Mar 2024 10:08:37 UTC (2,004 KB)"
"143","Individual and Product-Related Antecedents of Electronic Word-of-Mouth","Bogdan Anastasiei, Nicoleta Dospinescu, Octavian Dospinescu","Computers and Society (cs.CY)","This research investigates the antecedents of positive and negative electronic word-of-mouth (eWOM) propensity, as well as the impact of eWOM propensity on the intention to repurchase the product. Two types of eWOM predictors were considered: product related variables and personal factors. The data were collected through an online survey conducted on a sample of 335 Romanian subjects, and the analysis method was Structural Equation Modeling. Our findings show that personal factors - social media usage behavior, marketing mavenism and need to evaluate - are the most important antecedents of the intention to write product reviews and comments online, either positive or negative. From the product related factors, only brand trust influences the propensity to provide eWOM. Furthermore, both positive and negative eWOM intentions are associated with the repurchase intention.","Tue, 19 Mar 2024 07:50:26 UTC (592 KB)"
"144","Visualizing Progress in Broadening Participation in Computing: The Value of Context","Valerie Barr, Carla E. Brodley, Manuel A. Pérez-Quiñones","Computers and Society (cs.CY)","Concerns about representation in computing within the U.S. have driven numerous activities to broaden participation. Assessment of the impact of these efforts and, indeed, a clear assessment of the actual ""problem"" being addressed are limited by the nature of the most common data analysis which looks at the representation of each population as a percentage of the number of students graduating with a degree in computing. This use of a single metric cannot adequately assess the impact of broadening participation efforts. First, this approach fails to account for changing demographics of the undergraduate population in terms of overall numbers and relative proportion of the Federally designated gender, race, and ethnicity groupings. A second issue is that the majority of literature on broadening participation in computing (BPC) reports data on gender or on race/ethnicity, omitting data on students' intersectional identities. This leads to an incorrect understanding of both the data and the challenges we face as a field. In this paper we present several different approaches to tracking the impact of BPC efforts. We make three recommendations: 1) cohort-based analysis should be used to accurately show student engagement in computing; 2) the field as a whole needs to adopt the norm of always reporting intersectional data; 3) university demographic context matters when looking at how well a CS department is doing to broaden participation in computing, including longitudinal analysis of university demographic shifts that impact the local demographics of computing.","Mon, 18 Mar 2024 01:12:02 UTC (3,485 KB)"
"145","Synergy of Information in Multimodal IoT Systems -- Discovering the impact of daily behaviour routines on physical activity level","Mohsen Shirali, Zahra Ahmadi, Carlos Fernández-Llatas, Jose-Luis Bayo-Monton","Computers and Society (cs.CY)","The intricate connection between daily behaviours and health necessitates robust behaviour monitoring, particularly with the advent of IoT systems. This study introduces an innovative approach, exploiting the synergy of information from various IoT sources, to assess the alignment of behaviour routines with health guidelines. We grouped routines based on guideline compliance and used a clustering method to identify similarities in behaviours and key characteristics within each cluster. Applied to an elderly care case study, our approach unveils patterns leading to physical inactivity by categorising days based on recommended daily steps. Utilising data from wristbands, smartphones, and ambient sensors, the study provides insights not achievable with single-source data. Visualisation in a calendar view aids health experts in understanding patient behaviours, enabling precise interventions. Notably, the approach facilitates early detection of behaviour changes during events like COVID-19 and Ramadan, available in our dataset. This work signifies a promising path for behavioural analysis and discovering variations to empower smart healthcare, offering insights into patient health, personalised interventions, and healthier routines through continuous IoT-driven data analysis.","Sun, 17 Mar 2024 21:06:38 UTC (7,792 KB)"
"146","A2CI: A Cloud-based, Service-oriented Geospatial Cyberinfrastructure to Support Atmospheric Research","Wenwen Li, Hu Shao, Sizhe Wang, Xiran Zhou, Sheng Wu","Computers and Society (cs.CY)","Big earth science data offers the scientific community great opportunities. Many more studies at large-scales, over long-terms and at high resolution can now be conducted using the rich information collected by remote sensing satellites, ground-based sensor networks, and even social media input. However, the hundreds of terabytes of information collected and compiled on an hourly basis by NASA and other government agencies present a significant challenge for atmospheric scientists seeking to improve the understanding of the Earth atmospheric system. These challenges include effective discovery, organization, analysis and visualization of large amounts of data. This paper reports the outcomes of an NSF-funded project that developed a geospatial cyberinfrastructure -- the A2CI (Atmospheric Analysis Cyberinfrastructure) -- to support atmospheric research. We first introduce the service-oriented system framework then describe in detail the implementation of the data discovery module, data management module, data integration module, data analysis and visualization modules following the cloud computing principles-Data-as-a-Service, Software-as-a-Service, Platform-as-a-Service and Infrastructure-as-a-Service. We demonstrate the graphic user interface by performing an analysis between Sea Surface Temperature and the intensity of tropical storms in the North Atlantic and Pacific oceans. We expect this work to contribute to the technical advancement of cyberinfrastructure research as well as to the development of an online, collaborative scientific analysis system for atmospheric science.","Fri, 15 Mar 2024 08:28:38 UTC (2,731 KB)"
"147","Developing and Deploying Industry Standards for Artificial Intelligence in Education (AIED): Challenges, Strategies, and Future Directions","Richard Tong, Haoyang Li, Joleen Liang, Qingsong Wen","Computers and Society (cs.CY)","The adoption of Artificial Intelligence in Education (AIED) holds the promise of revolutionizing educational practices by offering personalized learning experiences, automating administrative and pedagogical tasks, and reducing the cost of content creation. However, the lack of standardized practices in the development and deployment of AIED solutions has led to fragmented ecosystems, which presents challenges in interoperability, scalability, and ethical governance. This article aims to address the critical need to develop and implement industry standards in AIED, offering a comprehensive analysis of the current landscape, challenges, and strategic approaches to overcome these obstacles. We begin by examining the various applications of AIED in various educational settings and identify key areas lacking in standardization, including system interoperability, ontology mapping, data integration, evaluation, and ethical governance. Then, we propose a multi-tiered framework for establishing robust industry standards for AIED. In addition, we discuss methodologies for the iterative development and deployment of standards, incorporating feedback loops from real-world applications to refine and adapt standards over time. The paper also highlights the role of emerging technologies and pedagogical theories in shaping future standards for AIED. Finally, we outline a strategic roadmap for stakeholders to implement these standards, fostering a cohesive and ethical AIED ecosystem. By establishing comprehensive industry standards, such as those by IEEE Artificial Intelligence Standards Committee (AISC) and International Organization for Standardization (ISO), we can accelerate and scale AIED solutions to improve educational outcomes, ensuring that technological advances align with the principles of inclusivity, fairness, and educational excellence.","Wed, 13 Mar 2024 22:38:08 UTC (2,156 KB)"
"148","Kernel Alignment for Unsupervised Feature Selection via Matrix Factorization","Ziyuan Lin, Deanna Needell","Machine Learning (cs.LG)","By removing irrelevant and redundant features, feature selection aims to find a good representation of the original features. With the prevalence of unlabeled data, unsupervised feature selection has been proven effective in alleviating the so-called curse of dimensionality. Most existing matrix factorization-based unsupervised feature selection methods are built upon subspace learning, but they have limitations in capturing nonlinear structural information among features. It is well-known that kernel techniques can capture nonlinear structural information. In this paper, we construct a model by integrating kernel functions and kernel alignment, which can be equivalently characterized as a matrix factorization problem. However, such an extension raises another issue: the algorithm performance heavily depends on the choice of kernel, which is often unknown a priori. Therefore, we further propose a multiple kernel-based learning method. By doing so, our model can learn both linear and nonlinear similarity information and automatically generate the most appropriate kernel. Experimental analysis on real-world data demonstrates that the two proposed methods outperform other classic and state-of-the-art unsupervised feature selection methods in terms of clustering results and redundancy reduction in almost all datasets tested.","Wed, 13 Mar 2024 20:35:44 UTC (836 KB)"
"149","Evaluating Pedagogical Incentives in Undergraduate Computing: A Mixed Methods Approach Using Learning Analytics","Laura J. Johnston, Takoua Jendoubi","Computers and Society (cs.CY)","In the context of higher education's evolving dynamics post-COVID-19, this paper assesses the impact of new pedagogical incentives implemented in a first-year undergraduate computing module at University College London. We employ a mixed methods approach, combining learning analytics with qualitative data, to evaluate the effectiveness of these incentives on increasing student engagement.
A longitudinal overview of resource interactions is mapped through Bayesian network analysis of Moodle activity logs from 204 students. This analysis identifies early resource engagement as a predictive indicator of continued engagement while also suggesting that the new incentives disproportionately benefit highly engaged students. Focus group discussions complement this analysis, providing insights into student perceptions of the pedagogical changes and the module design. These qualitative findings underscore the challenge of sustaining engagement through the new incentives and highlight the importance of communication in blended learning environments.
Our paper introduces an interpretable and actionable model for student engagement, which integrates objective, data-driven analysis with students' perspectives. This model provides educators with a tool to evaluate and improve instructional strategies. By demonstrating the effectiveness of our mixed methods approach in capturing the intricacies of student behaviour in digital learning environments, we underscore the model's potential to improve online pedagogical practices across diverse educational settings.","Wed, 13 Mar 2024 16:39:38 UTC (139 KB)"
"150","QubiCSV: An Open-Source Data Storage and Visualization Platform for Collaborative Qubit Control","Devanshu Brahmbhatt, Yilun Xu, Neel Vora, Larry Chen, Neelay Fruitwala, Gang Huang, Qing Ji, Phuc Nguyen","Quantum Physics (quant-ph)","Developing collaborative research platforms for quantum bit control is crucial for driving innovation in the field, as they enable the exchange of ideas, data, and implementation to achieve more impactful outcomes. Furthermore, considering the high costs associated with quantum experimental setups, collaborative environments are vital for maximizing resource utilization efficiently. However, the lack of dedicated data management platforms presents a significant obstacle to progress, highlighting the necessity for essential assistive tools tailored for this purpose. Current qubit control systems are unable to handle complicated management of extensive calibration data and do not support effectively visualizing intricate quantum experiment outcomes. In this paper, we introduce QubiCSV (Qubit Control Storage and Visualization), a platform specifically designed to meet the demands of quantum computing research, focusing on the storage and analysis of calibration and characterization data in qubit control systems. As an open-source tool, QubiCSV facilitates efficient data management of quantum computing, providing data versioning capabilities for data storage and allowing researchers and programmers to interact with qubits in real time. The insightful visualization are developed to interpret complex quantum experiments and optimize qubit performance. QubiCSV not only streamlines the handling of qubit control system data but also improves the user experience with intuitive visualization features, making it a valuable asset for researchers in the quantum computing domain.","Thu, 7 Mar 2024 00:49:42 UTC (19,150 KB)"
